Санкт-Петербургский государственный электротехнический университет 
им. В.И. Ульянова (Ленина) “ЛЭТИ”


На правах рукописи


Чугреев Валерий Леонидович


МОДЕЛЬ СТРУКТУРНОГО ПРЕДСТАВЛЕНИЯ 
ТЕКСТОВОЙ ИНФОРМАЦИИ И МЕТОД ЕЕ ТЕМАТИЧЕСКОГО АНАЛИЗА НА ОСНОВЕ ЧАСТОТНО-КОНТЕКСТНОЙ КЛАССИФИКАЦИИ 

Специальность: 05.13.01 – Системный анализ, управление 
и обработка информации (технические системы)


ДИССЕРТАЦИЯ
на соискание ученой степени кандидата технических наук


Научный руководитель –
д.т.н., проф. Яковлев С.А.



Санкт-Петербург – 2003
СОДЕРЖАНИЕ

ВВЕДЕНИЕ	4
1. АНАЛИЗ ПРЕДМЕТНОЙ ОБЛАСТИ И ПОСТАНОВКА ЗАДАЧ ИССЛЕДОВАНИЯ	11
1.1. Введение в информационно-поисковые системы	11
1.2. Обзор моделей поиска и методов тематического анализа текстовой информации	18
1.4. Постановка задач исследования	33
1.5. Выводы	38
2. РАЗРАБОТКА МОДЕЛИ СТРУКТУРНОГО ПРЕДСТАВЛЕНИЯ И МЕТОДА ТЕМАТИЧЕСКОГО АНАЛИЗА ТЕКСТА	39
2.1. Графовая модель структурного представления текста произвольного содержания	40
2.2. Метод частотно-контекстной классификации тематики текста	51
2.3. Алгоритм вычисления степени тематической принадлежности текста к образцу	60
2.4. Алгоритм поиска значений информационных признаков тематики текста	68
2.5. Выводы	77
3. ПРАКТИЧЕСКАЯ РЕАЛИЗАЦИЯ МОДЕЛИ СТРУКТУРНОГО ПРЕДСТАВЛЕНИЯ И МЕТОДА ТЕМАТИЧЕСКОГО АНАЛИЗА ТЕКСТА	79
3.1. Организация поиска	79
3.2. Программная реализация графовой модели структурного представления текста произвольного содержания	83
3.3. Программная реализация метода частотно-контекстной классификации тематики текста.	89
3.4. Программная реализация алгоритма вычисления степени тематической принадлежности текста к образцу.	97
3.5. Программная реализация алгоритма поиска значений информационных признаков тематики текста.	101
3.6. Выводы	104
4. ПРОВЕДЕНИЕ ЭКСПЕРИМЕНТАЛЬНЫХ ИССЛЕДОВАНИЙ	105
4.1. Планирование эксперимента	105
4.2. Результаты экспериментальных исследований метода частотно-контекстной классификации	111
4.3. Результаты экспериментальных исследований алгоритма вычисления степени тематической принадлежности текста к образцу	123
4.4. Результаты экспериментальных исследований алгоритма поиска значений информационных признаков тематики текста	127
4.5. Результаты экспериментальных исследований сравнения точности вычисления тематической близости.	132
4.5. Выводы	136
ЗАКЛЮЧЕНИЕ	137
СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ	140
ПРИЛОЖЕНИЕ	157

 
ВВЕДЕНИЕ

Накопленные к настоящему времени колоссальные объемы информации, в совокупности с непрерывно увеличивающимися темпами ее роста определяют актуальность и значимость исследований в области информационного поиска. Бурное развитие сетевых технологий, в том числе и Интернета,  способствуют значительному увеличению доступных информационных ресурсов и объемов передаваемой информации. Зачастую это разнородная, слабо структурирован¬ная и избыточная информация, обладающая высокой динамикой обновления. 
При сегодняшних объемах доступной информации решение задач информационного поиска становится не только приоритетным, но и элементарно необходимым для обеспечения своевременного доступа к интересующей информации.
Существует ряд авторитетных международных конференций, посвященных обсуждению вопросов информационного поиска [13]. Это такие известные конференции как:
TREC (Text REtrieval Conference) – цикл конференций организованный под эгидой NIST (National Institute for Standards and Technology) – одного из авторитетных органов стандартизации информационных технологий в США;
SIGIR (Special Interest Group on Information Retrieval) – цикл конференций проводимых ACM SIGIR (ACM - Association of Computing Machinery) –международной группой специалистов по информационному поиску.
WWW (World Wide Web) Conference – специально организованная конференция по решению задач, связанных с Интернет.
Высокий авторитет конференций TREC, SIGIR, WWW и  участие в них ведущих исследовательских коллективов и разработчиков технологий информационного поиска во многом определяет приоритетные направления исследований и задает общие принципы развития поисковых систем. 
Из наших отечественных конференций, посвященных вопросам информационного поиска, нужно отметить ежегодную всероссийскую конференцию “Электронные библиотеки” (RCDL) и семинар по компьютерной лингвистике “Диалог”.
Также необходимо отметить ряд отечественных научных школ:
•	SPBU IR Group – исследовательская группа в области информационного поиска (Санкт-Петербургский Государственный Университет); 
•	Исследовательский центр ИИ ИПС РАН;
•	Центр информационных исследований (НИВЦ МГУ).
Кроме того, существуют коммерческие организации, занимающиеся не только вопросами исследований, но и вопросами внедрения информационных технологий, это такие известные организации как Яндекс, Рамблер, Апорт, НейрОК, Гарант-Парк-Интернет, Галактика-Зум, ABBYY-FTR, AOT и др. 
Ряд авторитетных исследователей внесли своими научными трудами значительный вклад в развитие информационно-поисковых систем: И.С. Некрестьянов, И.E. Кураленок, В.Ю. Добрынин, Дубинский А.Г., А.Е. Ермаков, М.Р. Когаловский, А.В. Сокирко, G. Salton, A. Singhal, M. Mitra, S. Lawrence, P. Foltz, E. Fox, J. Cho, R. Baeza-Yates, K. Tajima, C. Van Rijsbergen, L. Gravano, J. Kleinberg. 
Существует широкий спектр предлагаемых решений и перспективных направлений исследований в области информационного поиска, начиная от построения глобальных распределенных информационных структур и поисковых систем, заканчивая элементарными на первый взгляд вопросами анализа документов. Все они, безусловно, важны и полезны при решении своих специфических задач. Тем не менее, именно от методов анализа во многом зависит эффективность существующих поисковых систем, т.к. они являются основой любой поисковой системы и во многом определяют возможности и ограничения этих систем.
Помимо этого существует еще один важный фактор, определяющий, на наш взгляд, эффективность любого информационного поиска – это человеческий фактор. Зачастую в большинстве исследований, относящихся к информационному поиску, этот фактор либо игнорируется, либо его значение во многом недооценивается. Но именно человек в конечном итоге пользуется разработанными информационно-поисковыми системами. Учет человеческого фактора, специфики его работы, предпочтений и ожиданий является перспективным и многообещающим направлением исследований. 
Представленные на сегодняшний день в большинстве популярных поисковых систем способы организации полнотекстового поиска и методы анализа документов не учитывают в достаточной мере как раз человеческий фактор. А именно, не учитывается тот факт, что во многом поиск определяется слабо формализуемыми и нечеткими условиями, в значительной степени зависящими от опыта и предпочтений самого человека. Далеко не всегда пользователь информационно-поисковой системы может четко и однозначно сформулировать именно тот набор ключевых слов, который и приведет его к искомому результату. Речь идет о варианте поиска на основе формирования информационных запросов, состоящих из набора ключевых слов и некоторых управляющих элементов языка запроса. Этот вариант поиска наиболее распространен и методологически проработан на сегодняшний день.
Сложность формирования информационных запросов может быть обусловлена: 
•	незнанием набора ключевых слов, однозначно определяющих искомый документ; 
•	отсутствием достаточного опыта и квалификации формирования таких запросов; 
•	отсутствием принятой и устоявшейся терминологии в интересующей области. 
Нередко человек, осуществляющий поиск, имеет самое приблизительное представление об интересующей его тематике. 
Все это обуславливает актуальность и значимость исследований, направленных на решение одной из ключевых проблем информационного поиска – проблемы адекватного отображения информационных потребностей пользователей.
Одним из вариантов решения этой проблемы является поиск документов по образцу, когда человек задает некоторый документ в качестве образца, а система, реализующая данный вариант поиска подбирает документы подобные заданному (подобные по содержанию, тематике). 
Анализ существующих исследований, посвященных решению задач поиска документов по образцу, выявил крайне незначительное число готовых и апробированных решений, что во многом связано с отсутствием достаточно проработанной теории и практики решения задач тематического анализа неструктурированной, естественно-языковой текстовой информации произвольного содержания. Эффективное решение задач такого анализа применительно к реализации поиска документов по образцу и составляет суть диссертационной работы. 
Цель работы: метод тематического анализа неструктурированной тексто¬вой информации для эффективного решения задач поиска документов по образцу.
В основе работы лежит модель структурного представления текста в виде ориентированного мультиграфа, а также способы формирования и анализа такой модели применительно к решению задач поиска документов по образцу. А именно, решению двух основных задач, позволяющих реализовать поиск документов по образцу [35]:
1. Выделение тематики документа. 
Тематика отражает содержание документа и включает в себя множество ключевых слов, находящихся в некоторой зависимости друг от друга. Один из вариантов такой зависимости - весовые коэффициенты, отражающие значимость того или иного слова  в конкретной тематике.
В работе представлен метод, реализующий автоматизированное выделение тематики как для одного документа, так и для набора близких в тематическом отношении документов, т.е. тематическое обобщение набора документов.
2. Вычисление тематической близости документов. 
Именно результат вычисления тематической близости, в конечном счете, и определяет результат поиска. Как правило, результат поиска дает множество документов, в той или иной мере удовлетворяющим условиям поиска.
Вычисляя значения тематической близости, эти документы можно проранжировать по степени значимости для пользователя. В работе представлен алгоритм вычисления тематической близости документов. 
На защиту выносятся следующие результаты:
1. Графовая модель структурного представления текста произвольного содержания.
2. Метод частотно-контекстной классификации тематики текста.
3. Алгоритм вычисления степени тематической принадлежности текста к образцу.
4. Алгоритм поиска значений информационных признаков тематики текста.
Научная новизна полученных результатов.
Основная научная новизна состоит в том, что разработанная модель, метод и алгоритмы позволяют эффективнее решать задачи поиска документов по образцу, в том числе:
1. Графовая модель структурного представления текста произвольного содержания отличается учетом связности и последовательности текста, что позволяет более полно отразить его семантическое содержание.
2. Метод частотно-контекстной классификации тематики текста отличается дополнением частотно значимых слов контекстно-связанными с ними словами, что позволяет более точно отобразить тематику текста.
3. Алгоритм вычисления степени тематической принадлежности текста к образцу отличается использованием частотных весов отдельных слов с учетом их контекстной спецификации, что позволяет более точно вычислить степень тематической принадлежности произвольного текста к тексту-образцу.
4. Алгоритм поиска значений информационных признаков тематики текста отличается минимизацией разницы экспертных и вычисленных оценок тематической принадлежности, что позволяет более точно классифицировать тематику текста и учесть субъективную составляющую при определении степени тематической принадлежности.
Практическая значимость результатов диссертационной работы состоит в использовании модели, метода и алгоритмов для решения задач поиска документов по образцу, а также для решения общих задач тематического анализа и обработки речевых высказываний. 
Модель, метод и алгоритмы, предложенные в диссертационной работе, позволяют значительно повысить точность и адекватность тематического анализа. Их реализация применительно к решению задач поиска документов по образцу позволяет повысить качество и эффективность такого поиска.
Практическая значимость диссертации подтверждается актами о внедрении результатов исследования в Администрации г. Вологды, Управлении по делам гражданской обороны и чрезвычайным ситуациям г. Вологды, ООО “Премьер-Информ”.
Диссертация состоит из введения, четырех глав, заключения, списка литературы и приложения.
В первой главе “Анализ предметной области и постановка задач исследования” выполнен анализ текущего состояния информационно-поисковых систем, перечислена основная терминология, решаемые задачи и способы их решения, показана специфика данной области и существующие в ней проблемы. Рассмотрены основные методы тематического анализа текстовой информации и проанализировано современное состояние исследований в области поиска документов по образцу. Кроме того, сформулирована цель и задачи диссертационного исследования.
Во второй главе “Разработка модели структурного представления и метода тематического анализа текста” выполнена разработка выносимых на защиту результатов диссертационной работы, а также представлено их теоретическое обоснование.
В третьей главе “Практическая реализация модели структурного представления и метода тематического анализа текста” рассмотрены вопросы организации поиска документов по образцу на основе предложенных в работе модели, метода и алгоритмов, а также приведена их конкретная реализация, в виде объектно-ориентированного программного кода на языке C#.  
В четвертой главе “Проведение экспериментальных исследований” приведены результаты экспериментальных исследований разработанного метода и алгоритмов на заданной коллекции тестовых документов, а также выполнена оценка их эффективности и корректности.
В заключении сформулированы основные выводы и результаты диссертационной работы.
 


 
1. АНАЛИЗ ПРЕДМЕТНОЙ ОБЛАСТИ И ПОСТАНОВКА ЗАДАЧ ИССЛЕДОВАНИЯ

1.1. Введение в информационно-поисковые системы 

Информационный поиск – самостоятельное направление исследований, изучающее вопросы поиска документов, обработки результатов поиска, а также целый ряд смежных вопросов: моделирования, классификации, кластеризации и фильтрации документов, проектирования архитектур поисковых систем и пользовательских интерфейсов, языки запросов, и т. д.  
Документ – это содержательно законченная единица информации, представленная на каком-либо естественном языке, которая идентифицируется уникальным образом [13]. Документ - это порция информации, которой оперируют информационно-поисковые системы.
Информационно-поисковая система – это комплекс программных средств, обеспечивающих избирательный отбор по заданным признакам документов, хранимых в оцифрованном представлении.

Способы поиска можно разделить на две большие группы.
1) Библиографический поиск или поиск “по каталогу”.
Такой вариант поиска обеспечивает нахождение документов по их выходным данным, например, по названию документа, по его тематике, по именам авторов, датам публикаций и т.д. Эти выходные данные составляют реквизиты документа.
Основой каталога является предварительно заданная модель представления реквизитов, реализованная в виде базы данных, в соответствии с которой обеспечивается запись отдельных элементов реквизитов и последующий поиск по ним. 
Основная проблема и недостаток такого варианта поиска - это необходимость выполнения значительного объема работ по предварительной организации, наполнению каталога. Как правило, это ручная классификация на основе привлечения экспертов. Учитывая колоссальные объемы информационных ресурсов, накопленных к настоящему времени, в совокупности с возрастающими темпами их роста становится понятным проблематичность структурирования и организации всего сегодняшнего информационного пространства. Подобный подход позволяет организовать лишь саму малую толику доступных информационных ресурсов. 
2) Тематический поиск или поиск “по тексту”.
Этот вариант поиска ориентирован на нахождение документов по их содержанию. Сюда же относится так называемый полнотекстовый поиск. Общая схема такого поиска заключается в формулировании некоторого запроса пользователем относительно содержания документа, и отборе из множества доступных документов, тех которые удовлетворяют запросу. Такой вариант поиска удобен, прежде всего, тем, что нет необходимости в предварительном разделении документов по различным категориям. Особенно это актуально при значительном объеме доступных документов, высокой динамики их обновления или отсутствии некоторых реквизитов, такая ситуация характерна для Интернета.
Основная проблема такого поиска – это сложность однозначной автоматической интерпретации содержания текстов документов и формулировок информационных потребностей пользователей. Сложность интерпретации затрудняет определение соответствия рассматриваемого документа информационным потребностям пользователя [13]. 
Эти проблемы обусловлены отсутствием какой-либо регулярной структуры у текстовых документов на естественном языке. Такие информационные ресурсы принято называть неструктурированными или слабоструктурированными.
Разработка методов анализа слабоструктурированных информационных ресурсов представляется весьма перспективным и многообещающим направлением исследований в области информационного поиска. 
В соответствии с вышеприведенной классификацией способов поиска принято выделять два основных класса информационно-поисковых систем: 
- Поисковые каталоги
- Поисковые системы 
Поисковые каталоги в большей степени ориентированны на структурную организацию тематических коллекций с удобной системой ссылок и иерархией документов по тематическим коллекциям. Это позволяет пользователю самостоятельно находить требуемый документ, просматривая структуру каталога, либо использовать механизмы поиска ориентированные на данный каталог. В любом случае, организация информации ее структурирование и предварительное наполнение тематического каталога является в данном варианте информационно-поисковой системы первостепенным критерием, определяющим качество и эффективность поиска. Наполнение тематического каталога документами может выполняться как в ручном, так и в автоматическом режиме. Однако наиболее качественным все же остается ручной подбор документов для таких каталогов с привлечением экспертов по конкретным тематическим разделам или полуавтоматический вариант с предварительным “грубым” поиском документов и последующей их селекцией. 
Поисковые системы ориентированны на поиск слабоструктурированной информации. Как правило, они используются для поиска документов в больших и динамичных информационных коллекциях, например, в Интернете. Особенностью таких коллекций является отсутствие четко выраженной структурной организации, позволяющей упорядочить и однозначно классифицировать хранящиеся в них документы по тематической направленности.
В рамках данной работы наибольший интерес представляют именно поисковые системы, а точнее,  используемые в них методы анализа документов. 
Процесс поиска текстовой информации, реализуемый типичной поисковой системой, включает в себя следующие этапы: 
- формализация пользователем поискового запроса (представление пользователем, в том или ином виде, своих информационных потребностей); 
- предварительный отбор документов по формальным признакам наличия интересующей информации (например, наличие в тексте документа одного из слов запроса, если запрос формулируется на естественном языке); 
- анализ отобранных документов (лингвистический, статистический); 
- оценка соответствия смыслового содержания найденной информации требованиям поискового запроса (ранжирование).

Специфика поиска в Интернете. Ранние информационно-поисковые системы и методы поиска разрабатывались и тестировались на относительно небольших, однородных коллекциях. Современные условия поиска и, соответственно, требования к информационно-поисковым системам претерпели  значительные изменения. Главным образом, эти условия и требования связаны с развитием Интернета, который имеет свои специфические черты и особенности [13, 19]. Рассмотрим эти особенности.
Размер. Одной из главных особенностей Интернета является огромный объем доступных информационных ресурсов, продолжающий, к тому же, интенсивно нарастать. По оценкам специалистов, уже сейчас в Интернете содержится более миллиарда страниц, общий размер этих страниц оценивается в терабайтах [41, 95]. В связи с этим возникают высокие требования к масштабируемости используемых алгоритмов поиска.
Динамика. Высокая степень обновления информационных ресурсов Интернета. Очень часто появляются новые и удаляются существующие страницы, меняется их местоположение. Статистика показывает, что среднее время жизни половины страниц в Интернете не превышает десяти дней, ежемесячно примерно 40% страниц подвергается изменениям, а объем всей информации в сети увеличился в два раза за последние два года [41, 87]. Данная особенность значительно затрудняет использование общих статистических характеристик коллекции.
Взаимосвязи. Одной из особенностей информационного пространства Интернета является то, что страницы взаимосвязаны между собой. Эта взаимосвязь реализуется с помощью гиперссылок, что может быть использовано при реализации некоторых методов поиска.
Свободная публикация. В Интернете возможно свободное размещение документов и их удаление из коллекции, т.к. отсутствует централизированное администрирование информационных ресурсов. Вследствие этого могут быть нарушения целостности отдельных документов коллекции и связей между ними.
Избыточность. Для Интернета характерна большая избыточность информационных ресурсов. Очень часто на разных страницах публикуется несколько копий одного и того же документа или его незначительно модифицированных версий. Исследования показывают, что около 30% информации в Интернете - это точные или приблизительные копии других документов [117]. 
Неконтролируемое качество. Возможность свободной публикации документов в Интернете, а также отсутствие какой-либо обязательной проверки  их содержания зачастую приводит к появлению недостоверной и ошибочной информации, содержащей многочисленные орфографические и грамматические ошибки, опечатки, ошибки, вызванные оцифровкой документов, и просто некорректные и непроверенные данные. 
Пользователи. Интернет объединяет многочисленные группы совершенно разных по квалификации и подготовке пользователей. Многие из них не умеют  грамотно и эффективно формулировать запросы. Статистика показывает, что более 60% поисковых запросов в Интернете состоят из 1-2 слов, для примера, в классических информационно-поисковых системах эта величина 7-9 слов [42, 85]. Зачастую это приводит к большому количеству обрабатываемых и анализируемых в результате поиска документов. Сами результаты поисков в этом случае могут быть весьма далекими от реальных информационных запросов пользователя, т.к. запрос очень короткий. 
Исследования поведения пользователей показали, что многие из них не готовы к продолжительному ожиданию результатов поиска и анализу результирующего множества для выявления необходимых документов. 58% пользователей ограничиваются изучением первого экрана результатов запроса, 67% не пытаются модифицировать свой первоначальный запрос [85].
При этом критерии качества, используемые в традиционных системах текстового поиска, становятся неадекватными, например, критерий полноты поиска, т.е. процент обнаруженных релевантных документов [53]. 
Доступ. Не всегда возможен доступ к информационным ресурсам Интернета, т.к. далеко не все сервера работают круглосуточно в течение всего года.
Многоязычность. Интернет – это многоязычная информационная среда. Особенно актуальными становятся задачи мультиязыкового и кросс-языкового поиска. Решение этих задач предполагает реализацию алгоритмов поиска, независимых от языка представления анализируемых в процессе поиска документов и языка представления информационных запросов пользователя. 

Требования к системам текстового поиска. Интернет во многом изменил условия использования систем текстового поиска и выдвинул к ним новые требования. В сжатом виде главные из этих требований можно сформулировать следующим образом [13]:
- эффективная обработка очень больших коллекций документов;
- улучшенное отображение смыслового содержания документов и пользовательских поисковых запросов;
- реализация мультимедийной обработки, т.е. совместной обработки документов разных форматов и представлений - текстовых  документов, изображений, аудио, видео и др.;
- реализация эффективных методов поиска в потоках документов (задачи фильтрации).
Отдельно стоит отметить повышение требований к поисковым системам в отношении так называемого человеческого фактора, определяющего эффективность взаимодействия человека и поисковой системы. Это касается в первую очередь проектирования пользовательских интерфейсов и организации работы человека с поисковой системой. Наметившаяся в последнее время тенденция к интеллектуализации информационных систем, ориентация систем на человека, безусловно, затрагивает и системы информационно поиска. Это развитие таких актуальных направлений исследований как:
- мультиязыковый и кросс-языковый поиск;
- фактографический поиск (реализация поисковой системой ответов на заданные пользователем вопросы);
- поиск видеоданных (по содержанию видеоданных, поиск известных объектов, задачи распознавания и т.д.);
- интерактивный поиск (реализация диалога с пользователем во время поиска, уточнение запросов и т.д.);
- поиск по документу образцу и др.
Вместе с тем существующее положение дел в области  информационного поиска не позволяет пока говорить о безусловной эффективности и качественности современных поисковых систем. Существует целый ряд противоречий и проблем, вызванных технической, методологической и организационной сложностью рассматриваемых задач. 
Вместе с тем работы в области информационного поиска успешно развиваются, накапливается необходимая теоретическая и практическая база. На сегодняшний день существуют хорошо зарекомендовавшие себя решения в области текстового поиска. Рассмотрим некоторые из них в ракурсе тематического анализа и идентификации документов.


1.2. Обзор моделей поиска и методов тематического анализа текстовой информации

1.2.1. Модели поиска

Одним из ключевых понятий, характеризующим выбор того или иного метода анализа текстовой информации, а также реализацию конкретного варианта поиска, является модель поиска [26, 46, 116, 118].
Модель поиска – это сочетание следующих составляющих [13]:
- способ представления документов;
- способ представления поисковых запросов;
- вид критерия релевантности документов.
Вариации этих составляющих определяют большое число всевозможных реализаций систем текстового поиска. Рассмотрим некоторые из них, наиболее популярные в настоящее время.
Простейшие модели поиска.  Это модели, в которых документ представляется в виде набора ассоциированных с ним внешних атрибутов. К простейшим моделям поиска относится модель дескрипторного поиска и модель, основанная на Дублинском ядре.
В простейших системах дескрипторного поиска представление документа описывается совокупностью слов или словосочетаний лексики предметной области, которые характеризуют содержание документа. Эти слова и словосочетания называются дескрипторами. Индексирование документа в таких системах реализуется назначением для него совокупности дескрипторов. При этом дескрипторы могут приписываться документу: 
1) на основе его содержания; 
2) на основе его названия. 
Эти два процесса называются соответственно индексированием по содержанию и индексированием по заголовкам документов [13]. 
В некоторых дескрипторных системах индексирование документов осуществляется вручную экспертами в предметной области системы, в других оно выполняется автоматически. Представление документа в дескрипторных системах называется поисковым образом документа.
Дескрипторные системы можно отнести к классу систем,  ориентированных на библиографический поиск или поиск “по каталогу”.
Дублинское ядро (Dublin Core) [13, 14, 61] – это набор элементов метаданных, смысл которых зафиксирован в спецификации определяющего его стандарта. В терминах значений этих элементов можно описывать содержание различного рода текстовых документов.
Первоначальная версия Дублинского ядра была предложена в 1995 году на состоявшемся в Дублине (США) симпозиуме, организованном Online Computer Library Center (OCLC) и National Center for Supercomuting Applications (NCSA) для описания информационных ресурсов библиотечных систем.
В модели поиска, основанной на Дублинском ядре, представлением k-го документа является множество пар Dk = {(Nik, Vik)}, где:
Nik – имя i-го элемента метаданных Дублинского ядра в описании содержания k-го документа;
Vik – значение этого элемента метаданных.
Представлением запроса также является множество пар некоторых элементов Дублинского ядра и их значений Q = {(Nj, Vj)}, где:
Nj – имя j-го элемента метаданных Дублинского ядра в описании пользовательского запроса;
Vj – значение этого элемента метаданных.
Критерий релевантности k – го документа выглядит следующим образом:
 .
Модели, основанные на классификаторах. Это одна из разновидностей простейших моделей поиска. Документ в данной модели представляется в виде совокупности ассоциированных с ним атрибутов.
Атрибутами являются идентификаторы классов, к которым относится данный документ. Классы формируют иерархическую структуру классификатора. 
Запрос может быть представлен двумя способами:
1) Простой вариант – запросом является идентификатор какого-либо класса из заданного классификатора. Критерий релевантности документа запросу – класс документа совпадает с классом в представлении запроса или является его подклассом. 
2) Сложный вариант – в запросе можно указать несколько классов классификатора. Критерий релевантности документа запросу – класс документа совпадает с каким-либо из указанных в запросе классов или является его подклассом. 
Модели, основанные на классификаторах, близки к булевским моделям.

Булевские модели. В булевских моделях поиска пользователь может формулировать запрос в виде булевского выражения, используя для этого операторы И, ИЛИ, НЕТ. Термы запроса зависят от конкретного варианта модели поиска. В булевской модели, ориентированной на поиск “по тексту”, термами будут слова, соответственно, критерием релевантности будет условие вхождения некоторого слова или словосочетания в текст документа. В булевской модели, ориентированной на поиск по классификаторам, термами выражения будут идентификаторы классов классификатора. В булевской модели поиска с использованием Дублинского ядра термом будет значения элементов метаданных. Документ, имеющий совпадающие значения элементов метаданных со значениями, заданными в запросе, считается релевантным. 
В общем случае критерием релевантности документа запросу в булевских моделях поиска является истинность булевского выражения, заданного в запросе.
Одним из несомненных достоинств булевской модели поиска является простота ее реализации. Главными недостатками считаются:
1) отсутствие возможности ранжирования найденные документы по степени релевантности, поскольку отсутствуют критерии ее оценки. 
2)  сложность использования – далеко не каждый пользователь может свободно оперировать булевскими операторами при формулировке своих запросов.
Стоит отметить, что предпринимались попытки усложнения булевской модели поиска для обеспечения возможности ранжирования множества выдаваемых пользователю документов. А именно, предложено несколько вариантов так называемых расширенных булевских моделей [116]. В этих моделях вводятся специальные обобщения булевских операторов, позволяющие придать повышенный вес документам, в точности удовлетворяющих булевскому выражению запроса, и пониженный вес – всем остальным документам [13].

Векторные модели. В настоящее время векторные модели являются самыми распространенными и применяемыми на практике моделями поиска. Векторные модели, в отличие от булевых, без труда позволяют ранжировать результирующее множество документов запроса.
Суть таких моделей сводится к представлению документов и запросов в виде векторов. 
Каждому терму ti в документе dj и запросе q сопоставляется некоторый неотрицательный вес wij (wi для запроса). Таким образом, каждый документ и запрос может быть представлен в виде k - мерного вектора [21]: 
 
где k- общее количество различных термов во всех документах. 
Согласно векторной модели, близость документа di к запросу q оценивается как корреляция между векторами их описаний. Эта корреляция может быть вычислена, например, как скалярное произведение соответствующих векторов описаний [8].
Существуют различные подходы к выбору указанных весов. Одним из самых простых является использование нормализованной частоты данного терма в документе: 
 , 
где nij – количество повторений данного терма в документе; Nj – общее количество всех термов в документе.
Более сложные варианты расчета весов учитывают частоту использования данного терма в других документах коллекции, т. е. учитывают дискриминационную силу терма [21]. Но эти варианты возможны только при наличии статистики использования термов в коллекции.
Вариации всевозможных способов назначения весов термов и оценки меры близости векторов определяют широкий спектр различных модификаций данной модели поиска.

Вероятностные модели. Впервые идеи таких моделей были предложены в 1960 году [100]. В их основе лежит принцип вероятностного ранжирования (Probabilistic Ranking Principle, PRP). Этот принцип заключается в следующем - наивысшая общая эффективность поиска достигается в случае, когда результирующие документы ранжируются по убыванию вероятности их релевантности запросу. Сначала для каждого для каждого документа оценивается вероятность того, что он релевантен запросу, а затем по этим оценкам выполняется ранжирование документов.
Существуют различные способы получения этих оценок, а также дополнительные предположения и гипотезы на основе априорных сведений относительно документов коллекции, которые и определяют конкретную реализацию вероятностной модели поиска.
Например, эта оценка может быть вычислена, в соответствии с теоремой Байеса, по некоторой функции вероятностей вхождения термов данного документа в релевантные и нерелевантные документы. С помощью запроса определяется вероятность вхождения заданного терма в релевантные документы, а по полной коллекции документов определяется вероятность вхождения этого терма в нерелевантные документы [13].

Сети вывода. Также, как и вероятностные модели, сети вывода основаны на принципе вероятностного ранжирования результирующих документов поиска [118, 127]. Главное их отличие от вероятностных моделей заключается в том, что используется оценка не вероятности релевантности документа запросу, а вероятности того, что он удовлетворяет информационным потребностям пользователя.
В рамках данной модели процесс поиска документов описывается как процесс рассуждений в условиях неопределенности. В процессе такого рассуждения оценивается вероятность того, что информационные потребности пользователя, выраженные с помощью одного или нескольких запросов,  удовлетворены.
Сеть вывода основана на Байесовской сети, которая включает узлы четырех видов. Узлами первого вида являются документы коллекции, изученные пользователем в процессе поиска.  Узлами второго вида являются термы, которыми описывается содержание документов. Узлами третьего вида являются запросы, состоящие из термов, которыми описывается содержание документов. Узел четвертого типа в сети только один, и он соответствует информационным потребностям пользователя, которые не известны поисковой системе. Все узлы первого и второго вида формируются заранее для заданной коллекции. Узлы третьего вида и их связи с узлами термов, описывающих документы, и узлом информационных потребностей формируются для каждого конкретного запроса.
После того, как сеть построена, осуществляется оценка документов коллекции. Это реализуется распространением по сети оценки вероятности узла конкретного документа. Результатом распространения является вычисление вероятности узла информационных потребностей. При этом оценка для каждого документа строится независимо от оценок других документов, с учетом матриц описывающих связи между узлами документов и узлами термов,  узлами термов и узлами запросов.
Процесс оценки повторяется для каждого документа, затем они ранжируются на основе вычисленных оценок вероятности узла информационных потребностей [13].
 
1.2.2. Методы тематического анализа текстовой информации

Всю совокупность представленных на сегодняшний день методов тематического анализа текста можно разделить на две большие группы:
•	лингвистический анализ;
•	статистический анализ.
Первый ориентирован на извлечении смысла текста по его семантической структуре. Второй – по частотному распределению слов в тексте. Однако, говорить о принадлежности какого либо из подходов к конкретной группе можно лишь условно, как правило, в реальных задачах обработки текста приходится использовать сочетание методик из обеих групп с тем или иным акцентом. 
Лингвистический анализ.  Лингвистический анализ можно разделить на четыре взаимодополняющих анализа.
- Лексический анализ. Заключатся в разборе текстовой информации на отдельные абзацы, предложения, слова, определении национального языка изложения, типа предложения, выявлении типа лексических выражений (бранных, жаргонных слов) и т.д. Данный вид анализа не представляет существенной сложности для реализации.
- Морфологический анализ. Сводится к автоматическому распознаванию частей речи каждого слова текста (каждому слову ставится в соответствие лексико-грамматический класс).  Часто морфологический анализ используется в статистических методах анализа при предварительной процедуре обработки документов - приведение слов к базовой форме. 
Морфологический анализ для русского языка можно реализовать практически со стопроцентной точностью благодаря его развитой морфологии. Для английского языка алгоритмы, присваивающие каждому слову в тексте наиболее вероятный для данного слова лексико-грамматический класс (синтаксическую часть речи), работают с точностью около 90%, что обусловлено лексической многозначностью английского языка. 
- Синтаксический анализ. Заключатся в автоматическом выделении семантических элементов предложения - именных групп, терминологических целых, предикативных основ. Это позволяет повысить интеллектуальность процесса обработки тестовой информации на основе обеспечения работы с более обобщенными семантическими элементами.
- Семантический анализ. Заключатся в определении информативности текстовой информации и выделении информационно-логической основы текста. Проведение автоматизированного семантического анализа текста предполагает решение задачи выявления и оценки смыслового содержания текста. Данная задача является трудно формализуемой вследствие необходимости создания совершенного аппарата экспертной оценки качества информации. 
Реализация семантического анализа текстовой информации предполагает обязательное использование экспертных систем, систем искусственного интеллекта для выявления смыслового содержания информации. В настоящее время отсутствуют сложившиеся подходы к реализации задачи семантического анализа текстовой информации, что во многом обусловлено исключительной сложностью проблемы и недостаточно полной проработкой научного направления создания систем искусственного интеллекта.

Статистический анализ. Статистический анализ – это, как правило, частотный анализ в тех или иных его вариациях. Общая суть такого анализа заключается в подсчете количества повторений слов в тексте и использовании результатов подсчета для конкретных целей. Например, вычисление весовых коэффициентов ключевых слов. 
Всевозможные варианты различных реализаций подсчета слов и последующая обработка результатов подсчета образуют широкий спектр предлагаемых в данном классе методов и алгоритмов.
Рассмотрим один из наиболее эффективных статистических подходов.

Латентно-семантический анализ. Латентно-семантический анализ (LSA - Latent Semantic Analysis) - это теория и метод для извлечения контекстно-зависимых значений слов при помощи статистической обработки больших наборов текстовых данных [21, 16, 89]. Данный метод анализа используется не только в области поиска информации [70, 62], но и в задачах фильтрации и классификации [66]. 
Основная идея латентно-семантического анализа заключается в том, что совокупность всех контекстов, в которых встречается и не встречается данное слово, задает множество обоюдных ограничений, которые позволяют определить похожесть смысловых значений слов и множеств слов между собой. 
Исходной информацией для LSA является матрица термов на документы, которая описывает используемый для обучения системы набор данных. Элементы этой матрицы содержат частоты использования каждого терма в каждом документе. 
Один из самых распространенных вариантов LSA основан на использовании разложения исходной матрицы по сингулярным значениям (SVD - Singular-Value Decomposition). Используя SVD, большая исходная матрица разлагается во множество из k, обычно от 70 до 200, ортогональных матриц, линейная комбинация которых является хорошим приближением исходной матрицы. 
Согласно теореме о сингулярном разложении, любая вещественная прямоугольная матрица X может быть разложена в произведение трех матриц: 
 ,
где матрицы U и V - ортогональные, а   - диагональная матрица, значения на диагонали которой называются сингулярными значениями матрицы X. 
Особенность такого разложения в том, что если в   оставить только k наибольших сингулярных значений, а в матрицах U и V только соответствующие этим значениям столбцы, то произведение получившихся матриц  lsa, Ulsa и Vlsa, будет наилучшим приближением исходной матрицы X матрицей ранга k. 
 .
Идея такого разложения  и суть латентно-семантического анализа заключается в том, что если в качестве X использовалась матрица термов на документ, то матрица  , содержащая только k первых линейно независимых компонент X, отражает основную структуру ассоциативных зависимостей, присутствующих в исходной матрице, и в то же время не содержит шума. 
Таким образом каждый терм и документ представляются при помощи векторов в общем, пространстве размерности k (так называемом пространстве гипотез). Близость между любой комбинацией термов или документов может быть легко вычислена при помощи скалярного произведения векторов. 
Выбор наилучшей размерности k для LSA - открытая исследовательская проблема. В идеале, k должно быть достаточно велико для отображения всей реально существующей структуры данных, но в то же время достаточно мало, чтобы не захватить случайные и маловажные зависимости. Если выбранное k слишком велико, то метод теряет свою эффективность и приближается по характеристикам к стандартным векторным методам. Слишком маленькое k не позволяет улавливать различия между похожими словами или документами. Исследования показывают, что с ростом k качество сначала возрастает, а потом начинает падать.
Одним из главных недостатков латентно-семантического анализа является то, что он рассчитан на обработку документов коллекции, т.е. документы коллекции должны быть доступны. Это в значительной мере ограничивает его применение.

1.2.4. Поиск по документу-образцу 

Одной из частных задач информационного поиска является задача поиска по документу-образцу. Именно эта задача представляет наибольший интерес в рамках данной диссертационной работы. Рассмотрим ее подробнее.
Документ-образец выступает в качестве одной из форм представления информационных потребностей пользователя. Целью поиска является, обнаружение тематически близких документов. При этом, как правило, речь идет не о поиске идентичных или синтаксически близких документов, а о поиске документов, близких по содержанию, близких по смыслу [19]. 
Самым простым подходом к решению задачи поиска документов по образцу является использование всех слов документа-образца в качестве запроса. Однако длина такого запроса может оказаться очень большой, что отрицательно скажется на качестве поиска, т.к. результатом поиска будут все документы, в которых присутствовали данные слова, и таких документов может быть очень много. Это отрицательно скажется как на самой поисковой системе – вычислительные ресурсы и трафик не безграничны, и система может оказаться перегруженной, так и на человеке – просмотр и анализ найденных документов может занять значительное время, редкий пользователь готов к этому [85].  
Приемлемым вариантом в данном случае является выделение тематики документа. Под тематикой понимается множество ключевых слов, описывающих, с некоторой степенью адекватности, содержание документа. Тематика – это приближенное представление документа. Для повышения точности и адекватности описания содержания документа ключевые слова используются с некоторыми весовыми коэффициентами, которые соотносятся с частотой повторений этих слов в тексте. Вопросы выделения тематики и вычисления тематической близости документов по их тематическому представлению во многом и определяют возможность и эффективность поиска по документу-образцу.
Отметим также, что проведенный анализ существующих к настоящему времени исследований в области информационного поиска выявил крайне незначительное число работ по данному направлению.
Несмотря на обилие различных решений, отсутствует четко проработанная методология поиска по документу-образцу. Существующие подходы не обеспечивают в полной мере решения этой задачи. В большей степени они являются смежными по отношению к рассматриваемой задаче. 
Так или иначе, существуют определенные наработки по этому вопросу, в той или иной мере его касающиеся, но при этом отсутствует достаточное количество специализированных исследований, посвященных решению именно этого вопроса. Более того, отсутствует четкая формализация постановки задач такого поиска. 
Рассмотрим разработанные к настоящему времени методы и подходы, используемые при решении задач поиска документов по образцу.
В работе [21] предлагается один из вариантов реализации поиска документов по образцу, автором предлагается следующая последовательность действий:
1) для каждого документа определяется некоторое относительно небольшое множество документов, представляющее его аппроксимированное тематическое окружение; 
2) построенные тематические окружения анализируются с целью формирования множеств ключевых слов, характеризующих тематику исходного документа относительно остальных документов коллекции;
3) полученные наборы ключевых слов используются для дальнейшего вычисления относительных оценок тематического подобия. 
В работе приводится также детальное описание каждого из действий и его конкретная реализация. Не вдаваясь в подробности, хочется отметить один важный момент, определяющий специфику и ограничения данного подхода. А именно, реализация такого варианта поиска предполагает предварительный анализ коллекции доступных документов, что во многом ограничивает применение данного подхода в коллекциях с высокой динамикой обновления и большим числом доступных документов. К таким коллекциям относится Интернет. 
Несмотря на особенности среды Интернета, или во многом благодаря таким особенностям, существуют весьма интересные и оригинальные варианты реализации поиска документов по образцу в Интернете. 
Одним из таких вариантов является использование информации о структуре ссылок. В общем случае реализация такого варианта предполагает анализ структуры графа Интернета (вершинами которого выступают страницы, а ребрами - ссылки). В качестве документа образца выступает некоторая страница, ссылки на данную страницу и ссылки с нее используются в различных алгоритмах локального анализа структуры графа Интернета. В работе [88] рассматривается один из таких алгоритмов – HITS (Hyperlink Induced Topic Search). В рамках этого алгоритма определяется два класса документов:
- “первоисточник” – документ, на который часто ссылаются в контексте некоторой тематики (чем чаще ссылаются – тем лучше “первоисточник”);
- “посредник” – документ, который ссылается на много “первоисточни-ков” (чем больше ссылок на первоисточники – тем лучше “посредник”). 
Алгоритм HITS состоит из двух шагов: 
1) выбор подмножества Интернет на основе запроса; 
2) определение лучших “первоисточников” и “посредников” по результатам анализа этого подмножества [67]. 
Подмножество строится путем расширения множества найденных по запросу пользователя страниц за счет добавления всех страниц, связанных с ними путем, состоящим из одной (иногда двух) ссылок. Далее, для каждого документа рекурсивно вычисляется его значимость как “первоисточника” и как “посредника”
Суть алгоритма HITS в том, что он пытается выделить “сообщество”, соответствующее тематике запроса, и на основе анализа этого сообщества определить наиболее авторитетные страницы [21].
Еще одним интересным вариантом решения задачи поиска документов по образцу является использование документа в дополнение к традиционному запросу [19]. Часто в процессе поиска возникает необходимость в дополнительной информации для уточнения результатов поиска, при этом может быть использована информация из изучаемого в текущий момент документа или уже изученных на данный момент документов. Запрос в этом случае формируется на основе слов или отдельных фраз, взятых из этих документов.  
В метапоисковой системе IntelliZap как раз реализован вариант такого уточнения, на основе анализа контекста, выделенного пользователем текстового фрагмента в исходном документе. Этот контекст может использоваться затем как на этапе формулировки запросов, так и на этапе ранжирования результатов, что позволяет значительно повысить точность поиска для очень коротких (1-2 слова) запросов [64].

1.4. Постановка задач исследования

Направленность данной работы – это реализация адекватного отображения информационных потребностей пользователей. Исходя из сформулированных выше требований к системам текстового поиска - это обеспечение улучшенного отображения смыслового содержания документов и пользовательских поисковых запросов, на основе представления пользовательского запроса в виде документа образца.
Общую схему поиска по документу образцу можно представить в следующем виде (рис. 1.1).
 
Рис. 1.1. Поиск документов по образцу

Существует документ-образец и некоторая коллекция доступных документов. Выполняется предварительный отбор из коллекции документов, и затем для отобранных документов вычисляется тематическая близость. Вычисленные оценки тематической близости w1, …, wn используются при ранжировании документов по тематической близости к документу образцу.
В данной работе основное внимание уделено вопросам вычисления тематической близости документов и решению связанных с ними задач. Вопросы самого поиска, т.е. предварительного отбора документов, в работе не рассматриваются. Реализация предварительного отбора документов из больших коллекций, например Интернета, вполне успешно решается существующими методами поиска. Самый простой вариант предварительного отбора документов из коллекции - по условию совпадения хотя бы одного слова из документа образца и документа, принадлежащего коллекции. Более адекватный вариант предварительного отбора – по тематике документа-образца. Собственно, выделение тематики документов и вычисление их тематической близости и являются задачами данной диссертационной работы.
Для корректной и адекватной формулировки задач и целей работы определим используемую терминологию.
В данной работе вопросы поиска документов в явном виде не рассматриваются. Рассматриваются вопросы анализа документов, а точнее,  тематического анализа текста документов, поэтому корректнее использовать термин “текст”, во всех тех случаях, когда речь идет о вопросах анализа текста. Там, где необходимо подчеркнуть поисковый аспект, будем использовать термин “документ”.
Текст – это последовательность предложений, слов, построенная согласно правилам данного языка, данной знаковой системы и образующая сообщение [25].
Тема текста – некоторое субъективное представление человека, пользователя поисковой системы, о рассматриваемой в тексте предметной области, о его основном содержании. Тема текста представляет собой основу текста, его приближенное представление, которое человек формирует для себя после чтения текста. 
Понятно, что реальная система, задачей которой является вычисление тематической близости, не может оперировать “некоторыми субъективными представлениями человека”. Необходимо машинное представление темы текста, коррелирующее с субъективными представлениями пользователя.
Такое машинное представление будем называть тематикой текста.
Тематическая близость – это мера близости текстов по их теме или тематике. 
Будем разделять тематическую близость, оцененную пользователем, и вычисленную на основе тематики.
Оцененная тематическая близость – мера близости текстов по их теме. Она может быть определена только самим пользователем на основе его субъективных представлений о теме документов.
Вычисленная тематическая близость - мера близости текстов по их тематике, полученная в результате вычислений.
Информационный запрос пользователя - представление информационных потребностей пользователя в форме, воспринимаемой программным обеспечением систем текстового поиска [13].
Теперь можно сформулировать цель работы, задачи и ограничения.

Цель работы: Метод тематического анализа текстовой информации для эффективного решения задач поиска документов по образцу.
Реализация данной цели - это вариант решения одной из ключевых проблем информационно-поисковых систем - проблемы адекватного отображения информационных потребностей пользователей. 
В данном случае решение этой проблемы основывается на представлении запроса пользователя в виде документа образца и реализации метода эффективного анализа тематики документов. В качестве критерия эффективности выступает точность. Разрабатываемый в работе метод тематического анализа должен точнее идентифицировать тематику документов.

Задачи работы. Решение задач поиска документов по образцу предполагает решение двух основных задач:
- выделение тематики документов; 
- вычисление тематической близости документов.
Обе эти задачи относятся к задачам классификации – отнесение документа по его тематическому представлению к некоторому классу и определение меры близости между различными классами документов. 
Сформулируем задачи следующим образом:
1. Тематическая классификация текстовой информации.
2. Вычисление степени тематической принадлежности текста к образцу.

Ограничения. Сформулируем основные ограничения и допущения для данной работы. 
1. Содержание текста – произвольное. 
Нет никаких априорных данных о содержании текста и его структуре. Под структурой текста здесь понимается последовательность текстовых фрагментов, описывающих отдельные, содержательно законченные элементы текста – реквизиты, введение, главы, параграфы, заключение и т.д.
2. Коллекция доступных документов  не известна.
Существуют ряд методов поиска и методов анализа текста, опирающиеся на предварительный анализ коллекции доступных документов. Главное ограничение таких методов заключается в необходимости дополнительной информации о коллекции и доступ к ее содержимому. В нашей работе будем считать доступными текст документа-образца и текст документов, анализируемых на тематическую близость. 
3. Размер текста.
Специфика используемого в работе метода тематического анализа текста, а это преимущественно статистический анализ, предполагает некоторые ограничения на размер анализируемого текстового фрагмента, т.к. статистические методы напрямую зависят от объема исследуемой выборки. На данном этапе работы сформулировать эти ограничения без учета конкретных деталей реализации метода тематической классификации не представляется возможным. К данному вопросу вернемся позже, после разработки метода тематической классификации.

1.5. Выводы

В ходе анализа предметной области в данной главе был сделан общий обзор текущего состояния информационно-поисковых систем, перечислена основная терминология, решаемые задачи и способы их решения, а также показана специфика данной области и существующие в ней проблемы. Применительно к существующим в настоящее время способам и моделям текстового поиска  были рассмотрены основные методы тематического анализа и обработки текстовой информации. Также рассмотрено современное состояние исследований в области поиска документов по образцу. 
Кроме того, в данной главе были сформулированы цели и задачи работы, определяющие основное направление и ориентиры диссертационного исследования. Они заключаются в реализации адекватного представления информационных потребностей пользователя поисковой системы на основе предъявляемого им текста образца, выступающего в качестве эталона его информационных потребностей.
Анализ существующих исследований относительно реализации поиска документов по образцу выявил крайне незначительное число готовых и апробированных решений в данном области, что во многом связано с отсутствием достаточно проработанной теории и практики решения задач тематического анализа неструктурированной естественно-языковой текстовой информации произвольного содержания. Решение задач тематического анализа востребовано и актуально не только в области информационно-поисковых систем, но и вообще в системах обработки и анализа информации. Это широкий спектр различных задач интеллектуальной обработки информации, в том числе задач извлечения, идентификации и распознавания смыслового содержания речи. Все это обуславливает актуальность и значимость исследований в области тематического анализа и обработки неструктурированной информации. 
 
2. РАЗРАБОТКА МОДЕЛИ СТРУКТУРНОГО ПРЕДСТАВЛЕНИЯ И МЕТОДА ТЕМАТИЧЕСКОГО АНАЛИЗА ТЕКСТА

Задача поиска документов по образцу предпологает решение двух основных задач:
1) тематическая классификация текстовой информации;
2) вычисление степени тематической принадлежности текста к заданному классу. 
Эти задачи связаны, прежде всего, с анализом текста, а именно, с анализом смыслового содержания текста, его тематической направленности.
Всю совокупность представленных на сегодняшний день методов анализа текста, относительно задачи анализа его содержания, можно разделить на две большие группы:
•	лингвистический анализ;
•	статистический анализ.
Первый ориентирован на извлечении смысла текста по его семантической структуре. Второй – по частотному распределению слов в тексте. 
В данной работе было принято решение использовать методы статистического анализа в силу их относительной простоты, удобства использования и языковой независимости.  Методы лингвистического анализа, хотя и позволяют точнее анализировать текст, выделяя его структурные особенности, но являются более трудоемкими и сложными в использовании. Связано это, прежде всего, с богатством семантики и морфологии естественных языков. Формальное описание правил естественного языка и их реализация – весьма трудоемкий процесс, требующий привлечения специалистов из области лингвистики. Кроме того, лингвистический анализ предполагает ориентацию на конкретный язык с его конкретными семантическими особенностями, это обуславливает его плохую межъязыковую переносимость. Работы в данном направлении идут [10, 24, 123], и существует множество практических реализаций, но на сегодняшний день лингвистический анализ по части анализа семантики весьма проблематичен. 
Все это обусловило целесообразность применения статистических методов для решения задач данной работы. Однако частотный анализ, используемый в настоящее время при определении тематики документов [120], не позволяет в полной мере учесть внутреннюю структуру текста, т.к. при таком анализе не учитывается связность и последовательность текста. Хотя именно связность текста (речевого высказывания) считается одним из важнейших условий, необходимых для понимания его смыла и содержания. Данное положение является ключевым как в психолингвистике [3, 27], так и нейропсихологии [1, 18]. 
В ряде работ [11, 28] в области информационного поиска также отмечается эта особенность. Опираясь на результаты этих исследований, а также результаты собственных исследований [29, 30, 32], автором была разработана модель структурного представления текста, учитывающая его связность [34, 35]. 

2.1. Графовая модель структурного представления текста произвольного содержания

Суть предлагаемого подхода заключается в моделировании структуры текста информационным потоком и формировании этим потоком ориентированного мультиграфа, вершинами которого являются слова, а ребрами – связи между словами в тексте. Этот мультиграф является информационной структурой текста [34, 35].
Мультиграф – это граф, который может содержать множество ребер соединяющих одну и туже пару вершин.
Информационный поток – это детерминированный поток событий, принадлежащих некоторому конечному множеству. Временной интервал между событиями нас не интересует, интересует только последовательность событий. В данном случае события – это слова, а конечное множество – это множество всех слов, присутствующих в анализируемом тексте. Информационный поток эквивалентен временному ряду номинальных (категориальных) величин.
Под информационной структурой понимается совокупность всех событий и связей между ними. Для информационной структуры текста связи между событиями – это словосочетания.  
Информационный поток, по сути, моделирует динамику некоторого процесса, в данном случае текста, а информационная структура является статическим представлением информационного потока.
Переход к модели структурного представления текста осуществляется следующим образом. 
1) Текст рассматривается в виде информационного потока, образованного информационными элементами - словами. 
Если последовательно брать слова из текста, начиная с самого первого и кончая последним, то это как раз и будет информационный поток F.
При этом набор всех слов в тексте можно выделить в конечное множество уникальных информационных элементов: 
I = {i1, i2, …, in}, 
где i – информационный элемент соответствующий определенному слову из текста. 
Информационный поток F будет представлен в виде последовательного чередования этих элементов (рис. 2.1).
 
Рис. 2.1. Информационный поток
F = (i1, i2, …, in).
Информационный поток также может быть представлен в виде набора связей:
F = (r1, r2, …, rn-1),
где: ri = (ii, ii+1) – связь между двумя информационными элементами, последовательно идущими в информационном потоке.
Далее, чтобы не перегружать рисунки избыточной информацией,  будем опускать именование связей.
Порядок чередования информационных элементов зависит от их последовательности в тексте. Информационные элементы в потоке могут повторяться. Обязательное условие – однозначное соответствие информационного элемента слову из текста. Одинаковые слова в тексте  соответствуют одному и тому же информационному элементу. 
Пример.
Фрагмент текста: “Дао, которое может быть выражено словами не есть постоянное Дао. Имя, которое может быть названо, не есть постоянное имя”.
Из данного набора слов выделяем множество уникальных информационных элементов (различия в регистре и знаки препинания не учитываются): I = {i1, i2, i3, i4, i5, i6, i7, i8, i9, i10, i11},
где:
i1 = быть,
i2 = выражено,
i3 = дао,
i4 = есть,
i5 = имя,
i6 = которое,
i7 = может,
i8 = названо,
i9 = не, 
i10 = постоянное,
i11 = словами.

Информационный поток соответствующий данному фрагменту текста (рис. 2.2) будет представлен в виде набора информационных элементов:
F = (i3, i6, i7, i1, i2, i11, i9, i4, i10, i3, i5, i6, i7, i1, i8, i9, i4, i10, i5)
 
Рис. 2.2. Информационный поток, соответствующий заданному тексту

2) Поток формирует структуру.
Если учесть, что слова в тексте повторяются, то, соответственно, можно допустить, что информационный поток будет многократно проходить через одни и те же информационные элементы, формируя, таким образом, связанную информационную структуру текста.
Для вышеприведенного фрагмента текста данная структура будет выглядеть следующим образом (рис. 2.3).
 
Рис. 2.3. Структура, формируемая информационным потоком

 Тезис о том, что информационный поток будет многократно проходить через одни и те же информационные элементы, носит принципиальный характер, при отсутствии циклов графа, образованных информационным потоком, ни о какой формируемой структуре не приходится говорить. 
На самом деле структура, представленная на рис.2.3, не отражает в полной мере информационный поток, описывающий фрагмент текста. Необходимо дополнить эту структуру информацией о прохождении потока через каждый из информационных элементов. Для каждого повторного  прохождения потока через одну и ту же пару информационных элементов необходимо формировать дополнительные связи – ребра. Тогда структура описывается в виде мультиграфа – графа, который может содержать множество ребер соединяющих одну и ту же пару вершин.
Для удобства отображения такого мультиграфа проиндексируем информационный поток и припишем каждому ребру графа, соединяющего пару вершин, множество индексов, соответствующих прохождению информационного потока через данную пару. 
Рассмотрим в качестве примера все тот же фрагмент текста, который описывается информационным потоком:
F = (i3, i6, i7, i1, i2, i11, i9, i4, i10, i3, i5, i6, i7, i1, i8, i9, i4, i10, i5).
Индексация данного информационного потока будет означать, что каждому переходу между двумя информационными элементами будет поставлен в соответствие индекс, начиная с единицы, с последовательным его инкрементом.
 
Рис. 2.4. Индексированная структура информационного потока

Информационная структура, приведенная на рис. 2.4, в полной мере отражает все особенности потока, описывающего фрагмент текста. 
Весьма показательным является приведенный выше фрагмент текста, особенность его, прежде всего, в том, что для сравнительно небольшого количества слов, входящих в данный фрагмент, существуют циклы. И информационный поток, моделирующий данный фрагмент, формирует явно выраженную структуру. Лингвистический анализ текста, его стилистические особенности и смысловая многозначность выходят за рамки диссертационной работы, но некоторая корреляция, по-видимому, существует между информативностью и структурной  насыщенностью - наличием большого числа связей между отдельными элементами. Явно выражен принцип усложнения системы за счет введения дополнительных связей между отдельными элементами.

Введем дополнительные обозначения и определим некоторые важные характеристики информационной структуры.
n(I) = | I | - количество информационных элементов множества I (количество уникальных слов в тексте).
n(F) = | F | - количество информационных элементов набора F (общее количество слов в тексте). 

M(I, R) – информационная структура (ориентированный  мультиграф). Является совокупностью I - множества информационных элементов (вершин графа) и R - набора связей между этими элементами (ребер графа).
M(I, R)   F.
R - набор связей между парами информационных элементов, может содержать повторяющиеся связи в случае многократного прохождения информационного потока F через одни и те же пары элементов.  
R = (r1, r2, …, rn-1),
где: r = (ii, ii+1) – связь между двумя информационными элементами, обозначает последовательность информационных элементов ii, ii+1 в потоке F.
 .
Для каждого информационного элемента из множества I, входящего в структуру M(I, R), существует набор пар связей, где: ri, rj – входная связь, ri+1, rj+1 – выходная связь, n – число пар связей.
Входная означает, что данная связь предшествует выходной в наборе связей, описывающих поток, проходящий через данный информационный элемент. Если проиндексировать связи в наборе, описывающие поток, то индекс входной связи будет на единицу меньше выходной.

n(R(i)) - количество пар связей в наборе R(i). 
Характеризует число связей данного информационного элемента с другими информационными элементами в структуре M(I, R). n(R(i)) равно числу повторений слова в тексте.

Обозначим количество пар связей как: 
d(i) – степень информационного элемента
d(i) = n(R(i)),
 ,  .
d(M(I, R))max – максимальная степень информационного элемента для информационной структуры M(I, R):  
d(M(I, R))max = max d(i),   .
d(M(I, R))min – минимальная степень информационного элемента для информационной структуры M(I, R):
d(M(I, R))min = min d(i),  .
r+(F, ik, ij, e), r-(F, ik, ij, e) – расстояние между двумя информационными элементами в потоке F,  , где:
e – вхождение информационного элемента ik в поток F, его порядковый номер в потоке.
r+ - означает, что расстояние измеряется по ходу информационного потока. 
r- - означает, что расстояние измеряется обратно ходу информационного потока.
Расстояние измеряется в количестве информационных элементов находящихся между ik и ij, плюс 1.
Пример:
F = (i2, i5, i1, i4, i5, i2, i3)
r+(F, i2, i3, 1) = 6
r+(F, i2, i3, 2) = 1
r-(F, i1, i2, 1) = 2
r-(F, i1, i3, 1) = 0
r+(F, i1, i3, 1) = 4
0 – означает, что результат не определен

rmin(F, ik, ij) – минимальное расстояние между двумя информационными элементами в потоке,  .  
Пример:
F = (i2, i6, i1, i4, i5, i7, i2)
rmin(F, i2, i5) = 2
rmin(F, i1, i2) = 2
rmin(F, i1, i8) = 0

Информационный поток относительно некоторого информационного элемента i можно описать как:
F(i, e, [r-, r+]),
где e – вхождение информационного элемента ik в поток F, его порядковый номер в потоке; [r-, r+] – окрестность, для которой определяется поток.
F(i, e, [r-, r+]) = (i - r-, …, i - 2, i - 1, i, i + 1, i + 2, …, i + r+),
где   - обозначает индексацию некоторого информационного элемента в наборе F относительно информационного элемента i;
i + 1 – обозначает информационный элемент, следующий сразу за i в информационном потоке F;    
i - 1 – обозначает информационный элемент, предшествующий i, в информационном потоке F.

Пример:
F = (i2, i5, i1, i4, i5, i2, i3, i8, i10, i1)
F(i4, 1, [3, 3]) = (i2, i5, i1, i4, i5, i2, i3)
F(i2, 2, [2, 4]) = (i4, i5, i2, i3, i8, i10, i1)
F(i2, 1, [2, 2]) = (0, 0, i2, i5, i1)
F(i5, 1, [2, 5]) = (0, i2, i5, i1, i4, 0, 0, 0)

Необходимо сделать одно уточнение - не всегда будет существовать поток для всей окрестности.
Такая ситуация возможна, когда заданный информационный элемент находится близко к началу или концу информационного потока, описывающего текст, т.е. элементов i - r-, …, i - 2, i - 1 и i + 1, i + 2, …, i + r+  может просто не существовать, или существовать только часть их, в зависимости от того, насколько близок элемент i к началу или концу текста.  
Также такая ситуация возможна в том случае, когда циклы, формируемые потоком, многократно проходящим через i, имеют  меньше информационных элементов, чем выбранное r. 
В таких случаях будем принимать равным 0, все элементы, которые не определены в данной окрестности.

Обозначим множество всех информационных потоков относительно информационного элемента i для всех его вхождений в поток F:
 
Пример:
F = (i2, i5, i1, i4, i5, i2, i3, i8, i5, i1), 
d(i5) = 3,
D(F, i5, [2, 2]) = ((0, i2, i5, i1, i4), (i1, i4, i5, i2, i3), (i3, i8, i5, i1, 0)).

На базе представленной модели выполним разработку метода и алгоритмов тематического анализа текста для решения двух основных задач данной работы:
1) тематической классификации текстовой информации;
2) вычисления степени тематической принадлежности текста к заданному классу.
 
2.2. Метод частотно-контекстной классификации тематики текста

Предлагаемый подход к тематической классификации текстовой информации основывается на гипотезе о том, что словарный запас и частоты использования слов зависят от темы текста [21, 120]. В настоящее время данная гипотеза активно и успешно используется в тематико-ориентированных методах поиска [72, 120, 48, 114, 115]. 
Тематическая классификация предполагает выделение множества ключевых слов, определяющих тематику текста. При этом каждому из них  приписывается вес, определяющий значимость данного слова в тематике, т.е. какие-то ключевые слова играют большую роль в определении тематики, какие-то меньшую, но именно такая совокупность слов, с такой значимостью каждого из них в тематике и определяет тематическую направленность. 
Такой подход обеспечивает снижение размерности решаемой задачи за счет перехода от основного текста к его представлению в виде множества ключевых слов, приближенно описывающих его содержание. Это необходимо, прежде всего, для последующей тематической идентификации сравниваемых текстов. Задача классификации в данном случае сводится к задаче отнесения текста к некоторому тематическому классу, описываемому множеством ключевых слов. 
Замечание: тематические классы в этом случае не определены заранее, их формирование, а также идентификация и отнесение текста к тому или иному классу происходит в процессе анализа текста.
Ключевые слова определяются по количеству их вхождений в текст, а именно – частота ключевых слов в тексте выше других слов. В рамках рассматриваемой модели структурного представления текста это будет означать, что через данные слова чаще проходит информационный поток, и информационные элементы, соответствующие этим словам, имеют большее количество связей с другими информационными элементами. 
Проблема заключается в определении порога (автоматизированном, машинном определении), который отделяет ключевые слова от всех остальных.
Очевидно, выбор пороговой величины должен зависеть от конкретного текста, от таких характеристик модели как d(M(I, R))max, d(M(I, R))min и n(I).
Однако этого не достаточно, чтобы корректно выделять тематику текста. Адекватность тематики (машинного представления темы текста, в виде множества ключевых слов) по отношению к теме, которую для себя определяет человек после чтения текста, вопрос открытый. 
Автором выдвигается гипотеза о том, что корректное и адекватное машинное представление тематики текста должно включать в себя не только ключевые слова, но и контекст этих слов, т.к. смысл любого слова определяется исключительно в контексте тех слов, которые употреблялись вместе с ним, близко, рядом по тексту. И сами по себе ключевые слова в отрыве от их контекста не отражают в полной мере тематическую направленность текста. Существующие исследования в психолингвистике [2, 3, 27] подтверждают данный тезис. 
Необходимость дополнения ключевых слов контекстом определяется также соображениями практического характера. Суть этих соображений заключается в следующем.
Особенности частотного распределение слов в тексте могут значительно затруднить выбор пороговой величины и снизить качество последующего анализа документов на тематическую близость. Например, ситуация частотного выброса одного из слов. Непонятно при этом, какой необходимо устанавливать порог отсева, если частота повторений одного слова значительно превосходит все остальные, а все остальные при этом имеют одинаковую частоту. Либо устанавливать порог для выделения одного ключевого слова, или опускать порог и брать все слова текста в качестве тематики. И тот, и другой вариант неприемлемы, в одном случае тематика текста будет представлена в виде одного слова, в другом - тематикой будут все слова. Организация последующего поиска тематически близких документов (текстов), на основе множества ключевых слов, выступающих в качестве поискового запроса, представляется в этом случае весьма проблематичной. Если поисковый запрос представлен одним словом – результат поиска может дать незначительное число тематически близких документов, если поисковый запрос представлен всеми словами документа, то результат поиска может дать слишком много “тематически далеких” документов (рассматривается вариант поиска – искать документы, содержащие хотя бы одно из слов запроса).
Дополнение ключевых слов контекстом в этом случае является вполне разумным и приемлемым вариантом решения данной проблемы.

Приступим к разработке метода тематической классификации на основе модели структурного представления текста, учитывая вышеприведенные соображения.
Общая последовательность метода будет выглядеть следующим образом.
1. Моделирование текста и формирование информационной структуры M(I, R).
2. Выделение множества всех информационных элементов, ранжированных по их степени d(i) (числу повторений в тексте). Элемент с d(M(I, R))max будет первым, и далее по убыванию.  
3. Выделение множества ключевых элементов. 
Из множества всех информационных элементов (полученных на предыдущем этапе) берем n первых (n определяется на основе пороговой величины), которые будут первичным множеством ключевых элементов Sp = {k1i1, k2i2, …, knin}. Коэффициенты k1, k2, …, kn – соответствуют степеням информационных элементов.
4. Формирование уточняющего множества Ss, на основе контекстного анализа информационных элементов множества Sp.
5. Получение общего множество ключевых элементов, определяющее тематику текста: S = Sp + Ss.

Суть метода заключается в том, чтобы выделить первичный набор ключевых элементов за счет количества их повторений в тексте и затем дополнить его контекстом, на основе анализа структурных особенностей мультиграфа. 
Первые три пункта вряд ли нуждаются в дополнительных комментариях, рассмотрим подробнее порядок формирования множества Ss.
Одним из ключевых моментов является тот факт, что через  информационный элемент поток может проходить множество раз. Тем более это справедливо для первичного множества ключевых элементов Sp, т.к. именно они выбраны из всего текста на том основании, что у них больше связей с другими информационными элементами. Окрестность информационного элемента, а это множество информационных элементов, входящих в D(F, i, [r , r+]), в этом случае является контекстом. Анализ окрестности информационного элемента для выделения контекста данного элемента будем называть контекстным анализом. 
Формирование множества Ss, на основе контекстного анализа информационных элементов множества  Sp выглядит следующим образом.
1) Выделяем в набор A(i) множество всех потоков проходящих через каждый информационный элемент  , в некоторой окрестности заданной r. 
A(i) = D(F, i, [r-, r+]), 
r- = r; r+ = r.
A(i) = D(F, i, [r, r]) .
Объединяем все наборы A(i), для каждого   в один общий набор A(Sp):
 
Обозначим его A:
A = A(Sp).
В результате мы получили общий набор A, включающий в себя все потоки, проходящие через информационные элементы множества Sp, в некоторой окрестности заданной r.
2) Исключаем все информационные элементы из A, принадлежащие Sp:
A A’,
 .
3) Теперь из набора информационных элементов A’ выделяем множество информационных элементов Ss:
A’  Ss.
При этом будем учитывать количество повторяющихся информационных элементов и для каждого элемента множества Ss запишем число их повторений в наборе A’: Ss = {k1i1, k2i2, …, knin}, коэффициенты k1, k2, …, kn перед i – это число повторений этих информационных элементов в наборе A’.

Все элементы множества Ss присутствуют в некоторой окрестности элементов множества Sp, и каждый информационный элемент   определяет центр некоторой окрестности в информационной структуре M(I, R). Окрестность задается по информационным потокам, проходящим через i.  
На рис. 2.5 приведен пример выделения окрестности информационного элемента i5 некоторой информационной структуры (на рисунке приведен ее фрагмент), при r = 1.
 
Рис. 2.5. Выделение окрестности

Для данного примера Ss = {i45, i3, i22, i10, i4, i32}, все коэффициенты равны 1.
Если рассматривать текст, то это означает, что для некоторого слова определяются все его вхождения в текст. Затем для каждого из вхождений определяются соседние с ним слова в пределах некоторого диапазона-окрестности r (вперед и назад по тексту). После этого подсчитываются повторения всех слов, которые встретились в диапазоне каждого из вхождений. Число повторений затем используется для определения весов этих слов в тематике. 
Нужно отметить одну важную деталь, а именно, окрестности ключевых элементов из Sp, могут пересекаться, если ключевые слова расположены в тексте рядом (в пределах r). Тогда при подсчете повторяющихся информационных элементов необходимо учитывать их индекс в информационном потоке и не считать повторно информационный элемент с одним и тем же индексом, чтобы веса элементов из множества Ss не превышали веса элементов множества Sp, так как мы определяем значимость данных элементов в тематике. 
В итоге мы получаем общее множество ключевых элементов определяющих тематику текста:
S = Sp + Ss,
S = {k1i1, k2i2, …, knin}.
Весовые коэффициенты k1, k2, …, kn, определяют значимость того или иного информационного элемента в данной тематике.

Размер текста. Необходимо отдельно оговорить размер анализируемых текстовых фрагментов. Существует ограничения на размер текстового фрагмента, обусловленные использованием метода частотного анализа. 
Главным образом, ограничения касаются не столько размера текстового фрагмента, сколько соотношения количества уникальных слов (множество слов, из которых сформирован данный текстовый фрагмент) к общему их количеству:  . 
Пользуясь приведенным соотношением, можно оценить адекватность анализа тематики для конкретного текстового фрагмента. Чем ближе соотношение к 1, тем менее корректно выделение тематики. Соотношение, равное 1,  означает, что тематикой будут все слова текста. 
Ключевые слова, определяющие тему документа, должны встречаться в тексте чаще других слов, только при выполнении этого условия правомерно говорить о выделении тематики. Сказать насколько чаще они должны встречаться, затруднительно в силу многообразия текстов и исключительной субъективности самого понятия темы текста. 
Эмпирический подбор коэффициента, определяющего границу, порог адекватности, возможен в рамках конкретной поисковой системы с учетом специфики анализируемых документов. Выбор конкретного порога или реализация оценки адекватности анализа того или иного текста на основе приведенного соотношения – это прерогатива разработчика поисковой системы. 
Использование описательных статистик и вероятностных распределений для анализа этой величины затруднено, так они ориентированны на порядковые переменные. Специфика статистического анализа в нашем случае такова, что анализируются  категориальные (номинальные) величины – слова, относящиеся к так называемым бедным шкалам измерений [4]. Одним из вариантов анализа в данном случае может быть анализ таблиц частот распределения этих величин и анализ экспертных оценок  эффективности выделения тематики для тех или иных соотношений  . 
Детальное рассмотрение этого вопроса требует дополнительной теоретической проработки и экспериментальных исследований, выходящих за рамки данной работы.  

Параметры. Остается отметить, что данный метод выделения тематики также зависит от двух параметров:
1) пороговой величины – определяющей ключевые слова;
2) расстояния r – задающего окрестность.
Вариации этих параметров могут в значительной мере влиять на результат выделения тематики. При этом оценить адекватность и корректность выбора той или иной комбинации параметров можно только на основе вычисления тематической близости текстов (по выделенной тематике) и оценки ее экспертом.  Более подробно этот вопрос рассмотрим далее.


 
2.3. Алгоритм вычисления степени тематической принадлежности текста к образцу

Приступим к решению второй задачи данной работы – задаче вычисления степени тематической принадлежности текста к образцу.
Есть текст-образец, и есть некоторый произвольный текст, необходимо количественно оценить, насколько близка тематика произвольного текста к тематике заданного текста образца, т.е. вычислить степень тематической принадлежности текста к образцу. Далее для краткости будем использовать термин тематическая близость. 
И произвольный текст, и текст-образец могут быть представлены в виде тематических классов, метод частотно-контекстной классификации, представленный в предыдущем параграфе позволяет это сделать. Теперь необходимо разработать алгоритм вычисления тематической близости двух произвольных тематических классов, заданных множествами ключевых элементов (слов). 
Пусть:
S – множество ключевых элементов текста образца: 
S = {k1i1, k2i2, …, knin},
где коэффициенты k1, k2, …, kn перед i – это веса информационных элементов,  определяющие значимость данного элемента в тематике текста образца.
Sf – множество ключевых элементов некоторого найденного в результате поиска текста (документа найденного информационно-поисковой системой), который нам необходимо проанализировать на тематическую близость по отношению к тексту образцу 
Sf = {kf1i1, kf2i2, …, kfnin}, 
где коэффициенты kf1, kf2, …, kfn перед i – это веса информационных элементов, определяющие значимость данного элемента в тематике найденного текста. 
При этом информационные элементы i1, i2, …, in определяющие тематику обоих множеств S и Sf соотносятся между собой, т.е. информационный элемент i1 из множества S,  идентичен информационному элементу i1 из множества Sf. 
Однако это не означает, что все информационные элементы, присутствующие в S, обязательно будут присутствовать и в Sf, часть из них может отсутствовать, если таких ключевых слов нет в анализируемом тексте. 

Сумма всех коэффициентов как для множества S, так и для множества Sf должна равняться единице.
 , 	n = | I |.
 , 	n = | If |.
Если это условие изначально не выполняется, а это может быть связано с особенностями алгоритмической реализации выделения тематики, необходимо привести эти суммы к единице (нормировать по 1).
 ,	 .
Аналогично для kfi.
После этого можно вычислять тематическую близость по каждому из информационных элементов.
Традиционно в информационно-поисковых системах, реализующих векторную модель поиска, для вычисления меры близости векторов используется косинус угла, определяемый через скалярное произведение векторов [8]:
 ,
где:  и  - сравниваемые вектора.
В нашем случае использование такого подхода неприемлемо, т.к.   определяет меру близости самих векторов, а не их отдельных элементов.

Тематическую близость   по каждому из информационных элементов будем вычислять как:
 ,
 ,
 .
Смысл этой формулы сводится к вычислению отношения между весовыми коэффициентами, которое учитывает разницу (отличие) между ними.
Использование модуля разницы | ki – kfi | в качестве оценки их отличия в данном случае не приемлемо, т.к. разница не чувствительна к малым значениям коэффициентов  kfi и ki, и отличие этих коэффициентов при их малых значениях не будет заметно. В этом случае использование отношения более корректно. В числителе этого отношения коэффициент ki min, равный ki, если ki < kfi и kfi, если kfi < ki. Соответственно в знаменателе - оставшийся коэффициент. Это необходимо для того, чтобы wi лежало в диапазоне от 0 до 1. 
Множитель ki учитывает степень значимости данной разницы по отношению к документу образцу, т.е. насколько значимо отличие коэффициентов для данного информационного элемента в тематике текста образца. 

Коэффициент общей тематической близости  для всего текста, будет вычисляться как сумма всех  :
 .
При этом   будет принимать значения в диапазоне от 0 до 1.

Вычисляя   для каждого найденного документа (текста), можно выполнить ранжирование этих документов по тематической близости.

Учет контекста. Рассмотренный выше способ расчета тематической близости необходимо дополнить одним важным соображением. 
Как уже было сказано выше, значение слова определяется по его контексту, по тем словам, которые употреблялись вместе с ним. Особенно это значимо при вычислении тематической близости.
Одно и то же слово, присутствующее в S и Sf, может нести в себе совершенно разный смысловой оттенок, смысловую нагрузку. И простого сравнения весовых коэффициентов недостаточно для корректного вычисления тематической близости.
Существует два традиционных подхода, позволяющих учесть значение контекста. Первый использует предварительно сформированные тезаурусы – словари, описывающие понятия языка и определяющие семантические отношениями между ними. В таких словарях могут задаваться тематические категории слов, их синонимы, анонимы, ассоциативные связи и др. [13, 86, 22], а также онтологии – спецификации предметной области [69]. Второй подход предполагает анализ коллекции доступных документов и уточнение метрик близости с учетом реального содержимого коллекций [104, 112, 129, 113].
В данной работе предлагается способ учета контекста на базе самого текста без дополнительного анализа документов коллекции и без использования словарей.
 Исходя из предложенной модели структурной организации текста, при вычислении тематической близости необходимо выделять для каждого ключевого слова (множество ключевых слов, определяющих тематику, уже определено к этому моменту) контекст, т.е. слова входящие в окрестность данного слова. И затем учитывать контекст при сравнении ключевых слов различных текстов, т.е. сравнивать контекст, в котором это слово использовалось в тексте-образце и тексте, анализируемом на тематическую близость. 
Приступим к разработке способа вычисления контекстной близости.
Контекстной близостью будем называть коэффициент, учитывающий отличие контекстов некоторого заданного слова для двух разных текстов.
Определение контекста, как было уже сказано выше,  выполняется относительно некоторого информационного элемента i, являющегося ключевым элементом текста образца и текста, анализируемого на тематическую близость  .
S – множество ключевых элементов текста образца; 
Sf - множество ключевых элементов анализируемого текста; 
F – информационный поток, описывающий текст образец;
Ff – информационный поток, описывающий анализируемый на тематическую близость некоторый найденный текст (документ).

1. Для i выделяем множество информационных элементов, входящих в его окрестность (отдельно для F и Ff).
Это выполняется следующим образом:
Выделяем множество всех потоков, проходящих через информационный элемент   в некоторой окрестности заданной r. 
A = D(F, i, [r-, r+]), 
r- = r; r+ = r.
A = D(F, i, [r, r]). 
Теперь из набора информационных элементов A выделяем множество информационных элементов I:
A   I,
I = {i1, i2, …, in}.
Потом, все то же самое для потока Ff:
A = D(Ff, i, [r, r]), 
A   If,
If = {i1, i2, …, in}.
В итоге имеем два множества I и If, определяющих соответственно окрестность информационного элемента i текста образца и текста, анализируемого на тематическую близость.
Приведенный выше порядок выделения окрестности идентичен, по сути, рассмотренному выше контекстному анализу (параграф 2.2.). За тем лишь исключением, что в данном случае нас не интересует количество повторений информационных элементов в наборе A. Нас интересуют только сам факт наличия или отсутствия информационных элементов в окрестности элемента i.

2. Сравниваем окрестности и вычисляем коэффициент контекстной близости.
Обозначим коэффициент контекстной близости -  :
 
Очевидно, что   лежит в диапазоне от 0 до 1. 
1 – наибольшая и 0 – наименьшая степень близости.

Вычисление тематической близости с учетом контекста перепишем в следующем виде:
 
Учитывая все вышеприведенные соображения относительно контекста, кратко сформулируем основные пункты рассмотренного выше алгоритма.

1. Приведение суммы весов S и Sf  к единице.
S – множество ключевых элементов текста образца;
Sf – множество ключевых элементов текста анализируемого на тематическую близость.

2. Вычисление тематической близости по весовым коэффициентам: 
 ,
 ,
 ,
 .
3. Вычисление контекстной близости по каждому ключевому элементу множества S: 
 ,
где:
I – множество информационных элементов входящих в окрестность информационного элемента i текста образца;
If – множество информационных элементов входящих в окрестность информационного элемента i анализируемого текста.

4. Вычисление общей тематической близости по всему тексту:
 .
 
2.4. Алгоритм поиска значений информационных признаков тематики текста

Вычисление тематической близости текстов предполагает предварительное выделение ключевых слов этих текстов с некоторыми весами и последующее их сравнение между собой, т.е. вычисление меры их близости. Сами тексты при этом не сравниваются, речь идет о переносе оценки тематической близости ключевых слов на весь текст. Эта традиционный, общепринятый подход, применяемый в подавляющем большинстве поисковых систем. 
Сравниваются не сами тексты, а их приближенное представление в виде тематики. Очевидна при этом условность такого сравнения, и значительное влияние на результат сравнения параметров, используемых при выделении тематики. Соответственно, получаемые значения тематической близости могут в значительной мере отличаться. 
Кроме того, необходимо отметить исключительную субъективность самого понятия тематической близости текстов. Это понятие предполагает значительную роль и участие человека в оценке тематической близости текстов. У человека есть некоторые ожидания относительно искомых текстов (документов) и их соответствия тексту-образцу. Предполагаемая человеком оценка может в значительной мере отличаться от вычисленной оценки приближенного представления текстов. 
Для корректного вычисления тематической близости необходимо учитывать как параметры, использованные при выделении тематики, так и субъективную составляющую. Это предполагает реализацию некоторого варианта предварительной настройки для того, чтобы получаемые в результате вычислений значения соответствовали ожиданиям пользователя. 
Традиционно, реализация такой настройки осуществляется на основе информации обратной связи [36, 39], получаемой от пользователя. 
Использование обратной связи для настройки некоторых параметров методов тематического анализа или уточнения пользовательского запроса не является чем-то принципиально новым, однако реализация подобной идеи применительно к решению задачи подбора оптимальных параметров для выделения тематики текста, с учетом экспертных оценок, автору не встречалась. Отсутствие каких либо доступных способов решения этой задачи обуславливает необходимость их разработки.
Приступим к разработке алгоритма поиска оптимальных параметров выделения тематики. Эти параметры назовем информационными признаками тематики.

Обозначим: 
Т – текст;
S – тематика текста (множество ключевых слов);
F - функция используемая для перехода от T к S (метод частотно-контекстной классификации). На рис. 2.5. приведена общая схема тематического представления текста.
 
Рис. 2.5. Тематическое представление документов
 ,
где: param1, param2 – параметры, используемые при выделении тематики.
1) param1 - порог, используемый для выделения первичного множества ключевых слов.
2) param2 - расстояние r, задающее окрестность, в пределах которой анализируются информационные потоки.
Задача состоит в том, чтобы определить оптимальные величины этих параметров, позволяющие получить вычисленную оценку тематической близости (на основе выделения тематики с данными параметрами), наиболее близкую к оцененной тематической близости, т.е. найти значения информационных признаков тематики. 
Очевидно, что определить эти параметры можно только на основе экспертных оценок тематической близости самих текстов, т.е. учитывая субъективную составляющую, учитывая ожидания эксперта. В данном контексте эксперт – это пользователь поисковой системы. Совсем не обязательно при этом, что он имеет какие-то априорные знания по теме искомых текстов (документов).  Эта оценка необходима, чтобы учесть его ожидания, учесть его критерии оценки тематической близости.

Обозначим: 
L – функция определяющая тематическую близость;
Le(T1, T2) – функция реализуемая самим человеком, при определении тематической близости двух текстов;
Lс(S1, S2) – функция реализуемая поисковый системой при вычислении тематической близости двух множеств ключевых слов определяющих тематику текстов.
Допустим, что результатом вычисления этих функций являются два коэффициента тематической близости:
Le(T1, T2) = ke,
Lс(S1, S2) = kc.
ke и kc лежат в диапазоне от 0 до 1.

Погрешность оценки тематической близости p, полученная в результате вычислений, по отношению к экспертной оценке может быть записана как  разница коэффициентов:
p = | ke - kc |.
В процентах:
 .
Смысл этого выражения в том, чтобы определить, на сколько отличается коэффициент тематической близости, полученный в результате вычислений от оценки эксперта. Оценка эксперта в данном случае выступает в качестве эталона.
Теперь приступим к разработке алгоритма поиска значений информационных признаков тематики.
Пусть существует три разных текста:
T1 – текст образец;
T2, T3 – тексты анализируемые на тематическую близость к T1.
Для каждого из этих текстов существует их приближенное представление в виде набора ключевых слов: 
 ,
 ,
 .
S1, S2, S3 – тематические представления текстов T1, T2, T3, полученные при некоторых идентичных параметрах функции F.  
Пусть имеются оценки тематической близости:
Le(T1, T2) = ke1,
Le(T1, T3) = ke2,
Lc(S1, S2) = kc1,
Lc(S1, S3) = kc2,
Тогда, для оптимальных параметров F, будет выполняться условие:
 ,
diff = 0.
Для того, чтобы подобрать оптимальные параметры, необходимо для каждой комбинации параметров получить свои S1, S2, S3, затем вычислить для них тематическую близость kc1 и kc2, подставить в diff и вычислить его значение.
Минимальное абсолютное значение diff, полученное для некоторой комбинации параметров, будет соответствовать наиболее оптимальным параметрам (optimal) для данного метода тематической классификации:
 
(2.1)
			 
(2.2)
	
Самый простой вариант подбора параметров – это перебор всех возможных комбинаций параметров и нахождение минимального diff. Разумным вариантом представляется использование одного из метода прямого поиска минимума функций, например метода Хука-Дживса, позволяющего значительно сократить вычислительные ресурсы и время поиска.
Смысл условия (2.2) состоит в том, что для метода выделения тематики текста подбираются такие параметры, которые позволяют затем получать, оценки наиболее близкие к оценкам, ожидаемым экспертом, а точнее, получать близкие соотношения оценок по некоторым заданным текстам. 
Чтобы привести вычисленную оценку к оценочной шкале эксперта, необходимо ввести масштабирующий коэффициент:
 
(2.3)

Коэффициент вычисляется как среднее арифметическое по двум отношениям, т.к. пользователь дважды оценивал тексты.
Этот коэффициент учитывает соотношение между оценкой эксперта и вычисленной оценкой при оптимально подобранных параметрах.
Тогда приведенная оценка будет вычисляться как:
 .
Используя обозначение коэффициента тематической близости (параграф 2.3), приведенную оценку можно записать через  :
 .
Необходимо отметить один важный момент: корректно говорить о подборе оптимальных параметров можно лишь для некоторого множества текстов, в нашем случае это T1, T2, T3. 
Гарантировать оптимальность найденных параметров для всех последующих текстов, сравниваемых с текстом-образцом, невозможно. Подобранные параметры и масштабирующий коэффициент будут давать гарантированный результат (с некоторой ошибкой,  определяемой diff) только для проверенных текстов. Относительно других текстов, которые будут затем анализироваться в автоматическом режиме, без экспертной оценки их тематической близости можно лишь предположить, что найденные параметры и масштабирующий коэффициент будут давать близкие результаты к ранее найденным соотношениям. Если пользователь в процессе работы изменит свои субъективные критерии тематической близости, то система (реализующая данный алгоритм) должна пересчитать параметры и масштабирующий коэффициент, т.е. по ходу поиска, в случае несоответствия ожидаемой оценки – вычисленной оценке, пользователь должен уточнить свои экспертные оценки относительно вновь просматриваемых текстов.
Существует также возможность экспертной оценки по некоторому произвольному числу текстов с подбором оптимальных параметров для серии оцененных пользователем документов. Детальное рассмотрение этого вопроса требует дополнительной теоретической проработки и экспериментальных исследований.  
Кроме того, необходимо отметить зависимость получаемых результатов от адекватности и последовательности выставляемых экспертом оценок. Если эксперт оценивает совершенно идентичные тексты по-разному, произвольно меняя свои критерии оценки, то система, реализующая данный алгоритм, не сможет корректно отработать эти оценки, т.е. найти оптимальные параметры для выделения тематики и масштабирующий коэффициент, удовлетворяющий заданным соотношениям. Результат в этом случае не определен.

Кратко сформулируем основные пункты рассмотренного выше алгоритма.
Существует три разных текста:
T1 – текст образец
T2, T3 – тексты анализируемые на тематическую близость к T1.
Существует экспертная оценка тематической близости этих текстов:
Le(T1, T2) = ke1,
Le(T1, T3) = ke2.
Существует множество комбинаций параметров используемых при выделении, их тематики:
PARAM = {(param1, param2)1, …, (param1, param2)n},
где: n – число комбинаций параметров
1. Для каждого текста выделить тематику с идентично заданными параметрами:
 ,
 ,
 .
2. Вычислить тематическую близость:
Lc(S1, S2) = kc1,
Lc(S1, S3) = kc2.
3. Вычислить разницу отношений между экспертными и вычисленными оценками:
 
4. Повторяя пункты 1,2,3, определить минимальную разницу diff, для некоторой комбинации параметров, которая и будет оптимальной.
 .
5. Вычислить масштабирующий коэффициент:
 
 
2.5. Выводы

В данной главе были разработаны:
1) графовая модель структурного представления текста произвольного содержания;
2) метод частотно-контекстной классификации тематики текста;
3) алгоритм вычисления степени тематической принадлежности текста к образцу;
4) алгоритм поиска значений информационных признаков тематики текста.

1) Графовая модель структурного представления текста произвольного содержания позволяет отобразить семантическую связность и последовательность текста в виде структуры.
Достоинства структурного представления:
- позволяет наглядно представить и выявить некоторые нетривиальные зависимости и закономерности в тексте; 
- значительно сокращает вычислительные ресурсы на поиск таких закономерностей;
- позволяет организовывать анализируемые тексты в единую, целостную информационную структуру, обеспечивая последующий анализ совокупности документов и выделение из них общих тематических кластеров.
2) Метод частотно-контекстной классификации тематики текста, позволяет выделять тематику текста в виде множества ключевых слов с весами, характеризующими значимость данных слов в тематике. 
Достоинством метода является меньшая чувствительность к частотным выбросам частотно-значимых слов, т.к. выделение тематики не ограничивается одним лишь выделением этих слов. Преимущество метода – в дополнении первичного набора ключевых элементов (сформированных на основе частотно-значимых слов) контекстом, что позволяет точнее отобразить тематику текста.
3) Алгоритм вычисления степени тематической принадлежности текста к образцу позволяет получать количественную оценку тематической близости текстов. Достоинством алгоритма является использование контекстного  анализа при вычислении тематической близости совпадающих ключевых слов различных текстов. Такой анализ позволяет учесть системную организацию текста, учесть не только ключевые слова текста, определяющие его тематику, но и их совокупную связь с другими словами, формирующими контекст этих слов. Это позволяет учесть значение слова в контексте всего текста, сравнивая ключевые слова (двух разных текстов) не только по их весам, но и по их контексту, учитывая смысловые отличия одних и тех же слов для разных текстов.
4)  Алгоритм поиска значений информационных признаков тематики текста позволяет учесть субъективный характер оценки тематической близости текста и настроить систему, реализующую поиск текстов по образцу под конкретного пользователя, учесть его ожидания и представления относительно тематической близости текстов. 

Перспективным направлением исследований представляется поиск тематически близких документов на основе подобия их структуры, т.е. выявлении общих структурных особенностей текстов, удовлетворяющих информационным потребностям пользователя. Сейчас выделение тематики предполагает анализ структуры текста и оформление результатов анализа в виде векторной модели для последующего поиска документов на основе этой модели.  
 
3. ПРАКТИЧЕСКАЯ РЕАЛИЗАЦИЯ МОДЕЛИ СТРУКТУРНОГО ПРЕДСТАВЛЕНИЯ И МЕТОДА ТЕМАТИЧЕСКОГО АНАЛИЗА ТЕКСТА 

3.1. Организация поиска 

Организация поиска и использование представленной в работе модели, метода и алгоритмов зависит, прежде всего, от конкретных целей и задач, решаемых реальной поисковой системой и особенностей ее архитектуры. Разработка такой системы выходит за рамки диссертационной работы, и вопросы реализации тех или иных аспектов поиска в рамках предлагаемого подхода остаются предметом отдельного обсуждения. Однако некоторые наиболее общие задачи, характерные для большинства поисковых систем, решаемые в рамках данного подхода применительно к поиску документов по образцу,  заслуживают внимания. 

3.1.1. Тематическая классификация

Существует как минимум два варианта тематической классификации:
1) для одного текста; 
2) для нескольких текстов.

И первый, и второй вариант предполагают выделение тематики на основе структуры M(I, R). Подробно данный метод рассмотрен в параграфе 2.2. 
Отличие второго варианта от первого в том, что тематическая классификация и последующее вычисление тематической близости выполняется по отношению к множеству текстов, объединенных общей тематикой. 
Это множество неизбежно появляется по ходу поиска документов на некоторую заданную тему. Человек, осуществляющий поиск, находит документы, в той или иной мере удовлетворяющие его ожиданиям. При этом появляется возможность организовать последующий поиск на основе нескольких, уже найденных к этому моменту, документов. Реализуется это простой конкатенацией текстовых фрагментов, т.е. один текст добавляется к другому, информационный поток в этом случае описывает уже не один, а несколько текстов. Последующее выделение тематики осуществляется на основе анализа такого обобщенного текста.
Принятие решения о том, какие тексты следует объединять для организации последующего поиска, может осуществляться как самим человеком, так и системой, например, в зависимости от вычисленных к этому моменту величин тематической близости для множества проанализированных текстов (найденных документов). 
Кроме того, возможен вариант расширения тематики на основе уточнения множества ключевых слов самим человеком. 
Уточнение тематики может осуществляться человеком произвольно, а может на основе контекстного анализа обобщенной информационной структуры (обобщенного множества текстов). Преимущество контекстного анализа по некоторому заданному набору ключевых слов для обобщенной информационной структуры в том, что обобщенное множество текстов формирует единое понятийное поле. 
Обобщенное множество текстов позволяет организовать всю терминологическую базу, используемую в найденных документах, в связанную структуру. И эту структуру можно использовать для дополнения произвольно заданного набора ключевых слов. 

3.1.2. Поиск

Поиск можно выполнять с помощью стандартных, отработанных методов, реализуемых в настоящее время поисковыми системами. В частности, это вариант векторной модели поиска или взвешенной булевой. Такой вариант поиска предполагает формирование поискового запроса, состоящего из множества ключевых слов. Это множество получается с помощью приведенного в работе метода частотно-контекстной классификации. На его основе формируется поисковый запрос, который отрабатывает поисковая система. Это может быть уже существующая поисковая система, с которой интегрируется предложенный метод и алгоритмы, или уникальная реализация под конкретную задачу.
По результату поиска получается множество документов. Используя алгоритм вычисления степени тематической принадлежности текста к образцу, эти документы анализируются, вычисляется их тематическая близость по отношению к документу образцу, и затем они ранжируются по величине близости.
Кроме того, как было уже сказано выше, возможен вариант поиска на основе обобщенного множества тематически близких документов.

3.1.3 Предварительная обработка текстов

Перед тем, как анализировать тексты в соответствии с представленной в работе моделью необходимо выполнить их предварительную обработку. 
Предварительная обработка текстов предполагает лексический и морфологический  анализ, а также исключение часто используемых слов  (союзов, местоимений и т.д.). 
Рассмотрим подробнее этапы предварительной обработки текста:
1) Лексический анализ.
Заключается в разборе текста на отдельные абзацы, предложения, слова, определении национального языка изложения.
На этом этапе выделяются отдельные слова из текста.
2) Исключение часто используемых слов. 
В любом тексте существует большое количество слов, используемых в качестве союзов, предлогов, местоимений и т.д., так называемые “стоп-слова”, (“stop-words”). Такие слова традиционно исключаются поисковыми системами при анализе документов. 
Как правило, эти слова не определяют тематику текста, но при этом являются частотно-значимыми. Это  затрудняет выделение тематики на основе анализа статистики слов. Такие слова необходимо исключать из текста. 
Данная процедура выполняется на основе предварительно составленного списка наиболее часто встречающихся слов в документах – списока игнорируемых слов. 
3) Морфологический анализ.
Морфологический анализ сводится к автоматическому распознаванию частей речи каждого слова текста.
На этом этапе слова приводятся к базовой форме. 
Например, слова: компьютеры, компьютером, компьютера, компьютеру и т.д., заменяются на слово компьютер. 

После предварительной подготовки текста, выполняется его обработка и тематический анализ по приведенным ранее модели, методу и алгоритмам.
 
3.2. Программная реализация графовой модели структурного представления текста произвольного содержания

Разработанная выше модель структурного представления текста, а также метод и алгоритмы тематического анализа реализованы в программном исполнении в виде объектно-ориентированной библиотеки классов на C#. 
Объектно-ориентированная реализация библиотеки на основе языкового стандарта С++ (C# по своим языковым конструкциям очень близок к С++),  является востребованной и приемлемой в современных условиях разработки программного обеспечения [31]. Использование конкретного языка C# для этих целей было обусловлено удобством использования памяти (автоматическое освобождение неиспользуемой памяти – “сборка мусора”), а также объектной ориентацией данного языка. 
Библиотека включает в себя следующие основные классы:
InfoAnalyzer - основной класс, отвечающий за обработку информационной структуры;
InfoElement	  - класс, отвечающий за представление и хранение информационных элементов;
InfoConverter - класс, преобразующий текст в набор связанных информационных элементов (формирование информационной структуры);
InfoDocument - класс для загрузки документов различных форматов и преобразования их в текст;
InfoSearcher - класс, отвечающий за контекстный анализ.
InfoSettings	 - класс, отвечающий за настройки, в том числе за организацию списка игнорируемых слов;
Morpho - класс, отвечающий за морфологический анализ (приведение слов к базовой форме).

Общая структура библиотеки приведена на рис. 3.1.

 
Рис. 3.1. Библиотека классов

Взаимодействие этих классов, а также ряда вспомогательных, позволяет преобразовывать текст в информационную структуру и затем анализировать ее с помощью представленного в работе метода и алгоритмов тематического анализа.  Отдельные ее фрагменты, описывающие конкретную реализацию того или иного метода и алгоритма, приводятся далее. Каждому основному классу соответствует свой модуль.

Программный код, реализующий модель структурного представления текста. Модуль InfoElement.

// Класс для хранения и обработки пар вход-выход
public class InOut
{
	private InfoElement inIE;
	private InfoElement outIE;

	public InOut(InfoElement inIE_rq, InfoElement outIE_rq)
	{
		inIE = inIE_rq;
		outIE = outIE_rq;
	}

	public InfoElement InIE
	{
		get {return inIE;}
	}

	public InfoElement OutIE
	{
		get {return outIE;}
	}
}

// Класс InfoElement - информационный элемент, формирующий инф. структуру
public class InfoElement
{
	// Key - index, value - InOut
	public SortedList InOut = new SortedList();
	private string name;	// имя инф. элемента

	public InfoElement(string name_rq)
	{
		name = name_rq;
	}

  public string Name
	{
		get {return name;}
	}

	public bool ContainsInOut(InOut in_out)
	{
		foreach (InOut v in InOut.Values)
		{
			if (v.InIE == in_out.InIE)
			if (v.OutIE == in_out.OutIE) return true;
		}
		return false;
	}
}

Класс InOut реализует хранение двух ссылок, на предшествующий и последующий информационный элемент, относительно некоторого информационного элемента в потоке. Далее экземпляр класса InOut будем называть парой In-Out (т.к. данный класс хранит входной и выходной информационный элемент). 
Класс InfoElement – базовый элемент формируемой информационной структуры. Коллекция SortedList (стандартный тип С#) реализует хранение отсортированного списка пар – (Key, Value). 
Key – уникальный идентификатор данной пары (по которому происходит сортировка), при формировании информационной структуры этот идентификатор инициализируется текущим индексом потока (порядковым номером слова в тексте). 
Value – хранимое значение, в данном случае используется для хранения ссылки на экземпляр класса InOut, т.е. экземпляр класса InfoElement организует хранение списка экземпляров класса InOut.

Модуль InfoConverter.

// text - текст, который необходимо преобразовать в инф. структуру
// allIE - список всех существующих инф. элементов
// ignor - список игнорируемых слов
public InfoConverter(string text, SortedList allIE, SortedList ignor, ref int index)
{
	ArrayList al = ConvertToArray(text, ignor);
		
	if (al.Count < 2) return;

	InfoElement ie_prev = null;
	InfoElement ie = CreateIE((string)al[0], allIE);
	InfoElement ie_next = CreateIE((string)al[1], allIE);

	ie.InOut.Add(index++, new InOut(ie_prev, ie_next));

	for (int i = 1; i < al.Count - 2; i++)
	{
		ie_prev = ie;
		ie = ie_next;
		ie_next = CreateIE((string)al[i + 1], allIE);

		ie.InOut.Add(index++, new InOut(ie_prev, ie_next));
	}
	// Последний инф. эл. в тексте
	ie_next.InOut.Add(index++, new InOut(ie, null));
}


// name - имя инф. элемента
// listIE - список сущ. инф. элементов
private InfoElement CreateIE(string name, SortedList allIE)
{
	InfoElement ie = null;
	if (!allIE.Contains(name))
	{
		ie = new InfoElement(name);
		allIE.Add(name, ie);
	}
	else ie = (InfoElement)allIE[name];
	return ie;
}

Из данного модуля приведены две главные процедуры.
InfoConverter – конструктор класса InfoConverter. Создание экземпляра данного класса реализует преобразование текста в информационную структуру.
Входные параметры конструктора:
text – преобразовываемый текст.
allIE – указатель на список всех информационных элементов существующих на текущий момент, если необходимо достроить уже существующую информационную структуру (обобщенная информационная структура), в этом списке необходимо задать уже существующие информационные элементы.
ignor – указатель на список игнорируемых слов (союзы, местоимения и т.д.).
index – текущий индекс информационного потока. Если идет моделирование нового информационного потока, то индекс равен 0 (и список существующих информационных элементов пустой). По окончанию формирования информационной структуры, в данной переменной возвращается текущее значение индекса информационного потока, это значение может потребоваться для достройки инф. структуры.
Далее по ходу текста процедуры отметим некоторые важные моменты.  
ArrayList al = ConvertToArray(text, ignor);
ConvrtToArray - вспомогательная процедура, конвертирует текст (заданный строкой) в массив-список отдельных слов (ArrayList тип C#, подобен SortedList, вместо сортировки - последовательная индексация элементов). Данная процедура выделяет отдельные слова текста и организует их хранение в виде списка слов, порядок слов в списке такой же, как и в тексте.
ignor – ссылка на список игнорируемых слов.
Далее идет формирование информационных элементов и информационной структуры.
InfoElement ie = CreateIE((string)al[0], allIE);
Создание информационного элемента путем вызова процедуры CreateIE. В данном случае первым параметром этой процедуры является первое слово в предварительно подготовленном массиве-списке, вторым - список всех существующих к настоящему времени информационных элементов. Процедура CreateIE создает информационный элемент или возвращает указатель на существующий, если уже есть информационный элемент с таким именем. 
ie.InOut.Add(index++, new InOut(ie_prev, ie_next));
Добавить к списку пар In-Out, данного информационного элемента ie, новую пару In-Out – предшествующий ему информационный элемент ie_prev и следующий за ним информационный элемент ie_next.
Последующий цикл реализует проход по всем словам текста и формирование на их основе информационной структуры.

 
3.3. Программная реализация метода частотно-контекстной классификации тематики текста.

Модуль InfoAnalyzer.

// Получить общий набор ключевых элементов, с нормировкой по 1
public SortedList GetKey(int threshold, int range, int screen)
{
	ArrayList key = GetPrimaryKey(threshold);
	key = GetExpandPrimary(key, range, screen);
	SortedList key_sl = ConvertToSortedList(key);
	Reduction(key_sl);
	return key_sl;
}

// Получить набор первичных ключевых элементов
// threshold - порог 
public ArrayList GetPrimaryKey(int threshold)
{
	int max = GetMaxInOut();
	int val = (int)((max / 100.0) * threshold);
	ArrayList result = new ArrayList();
	foreach (InfoElement ie in allIE.Values)
	{
		if (ie.InOut.Count >= val)
		{
			result.Add(new IE_Count(ie, ie.InOut.Count));
		}
	}
	SortArrayList sort = new SortArrayList(result);	
	return result;
}

// Максимальное количество пар in-out, для отдельного инф. элемента
private int GetMaxInOut()
{
	int max = 0;
	foreach (InfoElement ie in allIE.Values)
	{
		if (max < ie.InOut.Count) max = ie.InOut.Count;
	}
	return max;
}


// Расширить набор первичных ключевых элементов
public ArrayList GetExpandPrimary(ArrayList primary, int range, int screen)
{
	InfoSearcher search = new InfoSearcher();
	ArrayList result = search.SearchContext(ConvertToSortedListSimple(primary), range, screen);
	return result;
}

static public SortedList ConvertToSortedList(ArrayList al)
{
	if (al == null) return null;
	SortedList result = new SortedList();
	foreach (IE_Count ie_count in al)
	{
		result.Add(ie_count.IE.Name, new IE_Value(ie_count.IE, ie_count.Count));
	}
	return result;
}

// Приведение к единице суммы всех коэффициентов
static public void Reduction(SortedList sl)
{
	// общая сумма
	double sum = 0;
	foreach (IE_Value ie_value in  sl.Values) sum += ie_value.Value;
		foreach (IE_Value ie_value in  sl.Values)
		{
			double k = ie_value.Value / sum;
			ie_value.Value = k;
		}
}

// Вспомогательный класс для организации хранения найденных
// информационных элементов вместе с некоторыми величинами 
// (типа int)
public class IE_Count
{
	public InfoElement IE;
	public int Count;
	public IE_Count(InfoElement ie, int count)
	{
		IE = ie;
		Count = count;
	}
}

// Вспомогательный класс для организации хранения найденных
// информационных элементов вместе с некоторыми величинами 
// (типа double)
public class IE_Value
{
	public InfoElement IE;
	public double Value;
	public IE_Value(InfoElement ie, double val)
	{
		IE = ie;
		Value = val;
	}
}

Процедура GetKey возвращает список ключевых элементов. 
Входные параметры:
threshold – порог в процентах, необходимый для определения первичного множества ключевых элементов;
range – окрестность, в пределах которой осуществляется контекстный анализ;
screen – параметр отсечки, используется для исключения из множества ключевых элементов тех элементов, количество повторений которых меньше или равно screen.
Данная процедура осуществляет переадресацию вызова двум другим процедурам: GetPrimaryKey и GetExpandPrimary, реализующим соответственно получение первичного множества ключевых элементов и расширение этого множества контекстом.
Затем: 
SortedList key_sl = ConvertToSortedList(key) – вспомогательная процедура конвертирования коллекции из одного формата в другой;
Reduction(key_sl) – приведение к единице.
Порядок выполнения GetPrimaryKey. 
int max = GetMaxInOut() – получить максимальное количество пар In-Out (определить значение d(M(I, R))max). GetMaxInOut реализует это перебором всех информационных элементов и определением максимального числа пар In-Out для некоторого из них.
В классе InfoAnalyzer определен атрибут allIE – список всех информационных элементов.

public class InfoAnalyzer
{
	// список всех инф. элем.
	private SortedList allIE = new SortedList();
	...	

Все перечисленные выше процедуры – методы класса InfoAnalyzer, которые имеет доступ к переменной allIE – атрибуту класса InfoAnalyzer.
foreach (InfoElement ie in allIE.Values) – реализует перебор всех элементов коллекции allIE (в данном случае сортированного списка), foreach – это один из  циклов реализованных в C#. При перебое переменной ie последовательно присваиваться ссылка на каждый информационный элемент.
Результатом процедуры является список частотно-значимых информационных элементов, упорядоченных по числу их повторений в тексте.  SortArrayList – вспомогательный класс, реализующий сортировку коллекции ArrayList, элементами которой являются экземпляры класса IE_Count  (использование SortedList – встроенного типа C#, в данном конкретном случае, не совсем удобно). 
Теперь перейдем к процедуре GetExpandPrimary, она переадресует вызов методу SearchContext, класса InfoSearch. Данный метод реализует контекстный анализ и дополнение первичного множества ключевых элементов. Рассмотрим его подробнее. Модуль InfoSearch.

// Искать контекст (контекстный анализ)
// выходная информация ArrayList (value - IE_Count)
// элементы отсортированны по степени их значимости для данной тематики
// range – диапазон анализируемой окрестности
// screen - порог (в выходном списке будут присутствовать 
// только те элементы, которые встретились screen и более раз 
public ArrayList SearchContext(SortedList subject, int range, int screen)
{
	if (subject == null) return null;
	SortedList candidate = new SortedList();
	foreach (InfoElement ie in subject.Values)
	{
		// Перебираем все инф. потоки проходящие через данный инф.
		// элемент
		for (int i = 0; i < ie.InOut.Count; i++)	
		{
			int startIndex = (int)ie.InOut.GetKey(i);
			// Проверяем вперед по инф. потоку
			InfoElement ie_next = ie;
			for (int index = startIndex; index < startIndex + range; index++)
			{
				InfoElement ie_v = ((InOut)ie_next.InOut[index]).OutIE;
				if (ie_v == null) break;
				int index_v = index + 1;
				CandidateTest(ie_v, index_v, subject, candidate);
				ie_next = ie_v;
			}
			// Проверяем назад по инф. потоку
			InfoElement ie_prev = ie;
			for (int index = startIndex; index > startIndex - range; index--)
			{
				InfoElement ie_v = ((InOut)ie_prev.InOut[index]).InIE;
				if (ie_v == null) break;
				int index_v = index - 1;
				CandidateTest(ie_v, index_v, subject, candidate);
				ie_prev = ie_v;
			}
		}
	}
	// Копируем в выходной массив только те инф. элементы,
	// которые встречались screen и более раз
	ArrayList result = new ArrayList();
	for (int i = 0; i < candidate.Count; i++)
	{
		IE_Index ie_index = (IE_Index)candidate.GetByIndex(i);
		if (ie_index.Index.Count >= screen)
		result.Add(new IE_Count(ie_index.IE, ie_index.Index.Count));
	}
	// Копируем в выходной массив множество первичных инф. элементов
	for (int i = 0; i < subject.Count; i++)
	{
		InfoElement ie = (InfoElement)subject.GetByIndex(i);
		result.Add(new IE_Count(ie, ie.InOut.Count));
	}
	// Соритировка по количеству повторений (по IE_Count.Count)
	SortArrayList sort = new SortArrayList(result);	
	return result;
}

private void CandidateTest(InfoElement ie, int index, SortedList subject, SortedList candidate)
{
	if (subject.Contains(ie.Name)) return;
	if (!candidate.Contains(ie.Name)) 
	{
		// Если ie еще нет в списке кандидатов
		IE_Index ie_index = new IE_Index(ie);
		ie_index.Index.Add(index, 0);
		candidate.Add(ie.Name, ie_index);
	}
	else
	{
		// Если ie уже существует в списке кандидатов
		IE_Index ie_index = ((IE_Index)candidate[ie.Name]);
		// Проверяем не было ли ie с таким же инексом 
		// (т.е. не встречали ли мы его в данном индексе потока)
		if (!ie_index.Index.Contains(index)) 
				ie_index.Index.Add(index, 0);
	}
}

Входными параметрами процедуры являются:
subject - список ключевых элементов образующих тематику текста, этот список соответствует первичному множеству ключевых элементов;
range – окрестность в которой выполняется контекстный анализ;
screen – порог, который определяет число повторений информационного элемента в процессе анализа контекста, для включения в результирующий список (обычно эта величина 2, т.е. включать в результирующий список все те элементы которые встречались 2 и более раза).

Для каждого информационного элемента ie входящего в subject, выполняется контекстный анализ, который заключается в следующем:
1) Перебираются все пары In-Out, которые соответствуют прохождениям информационного потока через данный элемент:
for (int i = 0; i < ie.InOut.Count; i++). 
2) Определяется индекс пары:
int startIndex = (int)ie.InOut.GetKey(i). Используя этот индекс осуществляется проход вперед и назад по информационному потоку:
for (int index = startIndex; index < startIndex + range; index++),
for (int index = startIndex; index > startIndex - range; index--).
В процессе прохода инициализируется переменная ie_v – текущий проверяемый инф. элемент (этот элемент входит в окрестность ie).
3) Выполняется проверка:
CandidateTest(ie_v, index_v, subject, candidate). 
На вход этой процедуры передается текущий проверяемый инф. элемент ie_v и его индекс в потоке. 
Эта процедура проверяет, существует ли текущий проверяемый информационный элемент в списке “кандидатов”. Если нет, то он добавляется, если существует, то выполняется дополнительная проверка – “элемент с таким индексом уже находили?” Ситуация повторного нахождения одного и того же информационного с одним и тем же индексом в информационном потоке возможна в случае пересечения окрестностей информационных элементов входящих в subject (первичное множество ключевых элементов). Подсчитывать количество повторений в этом случае нельзя, т.к. число повторений некоторого информационного элемента входящего в окрестность может превысить число повторений информационного элемента входящего в subject.
Вспомогательный класс IE_Index необходим как раз для реализации такой проверки. 
// Вспомогательный класс для организации контекстного анализа
public class IE_Index
{
	public InfoElement IE;
	public SortedList Index = new SortedList();
	public IE_Index(InfoElement ie)
	{
		IE = ie;
	}
}
4) В результирующий список копируются найденные информационные элементы из списка candidate, удовлетворяющие условию – число повторений больше или равно screen, также в результирующий список копируются все информационные элементы, входящие в subject. 
5) Выполняется сортировка результирующего списка (сортировка по количеству их повторений).


 
 3.4. Программная реализация алгоритма вычисления степени тематической принадлежности текста к образцу.

Модуль InfoAnalyzer.

// Вычислить тематическую близость
// standard - множество инф. эл. определяющих тематику текста
// образца
// verifiable - множество инф. эл. определяющих тематику сравноваемого текста 
static public SortedList CalculateNearness(SortedList standard, SortedList verifiable, int range, ref double total)
{
	total = 0;
	SortedList result = new SortedList();
	for (int i = 0; i < standard.Count; i++)
	{
		string ie = (string)standard.GetKey(i);
		if (verifiable.Contains(ie))
		{
			// Вычисляем близость коэф.
			double k1 = ((IE_Value)standard.GetByIndex(i)).Value;
			double k2 = ((IE_Value)verifiable[ie]).Value;
			double w = Nearness(k1, k2);
			
			// Учет контекста ---------------------------------
			SortedList subject = new SortedList();
			InfoSearcher search = new InfoSearcher();

			// Выделяем окружение (контекст) для текущего проверяемого
			// информационного элемента 
			// из списка ключевых элементов текста образца
			subject.Add(ie, ((IE_Value)standard.GetByIndex(i)).IE);
			ArrayList environment1 = search.SearchContext(subject, range, 0);
			SortedList environment1_sl = ConvertToSortedList(environment1);

			// Выделяем окружение для текущего проверяемого
			// информационного элемента
			// из списка ключевых элементов проверяемого текста
			subject.Clear();
			subject.Add(ie, ((IE_Value)verifiable[ie]).IE);
			ArrayList environment2 = search.SearchContext(subject, range, 0);
			SortedList environment2_sl = ConvertToSortedList(environment2);

			double context = CompareEnvironment(environment1_sl, environment2_sl);
			w *= context;
			// ----------------------------------------------
			result.Add(ie, w);
			total += w;
		}
		else result.Add(ie, (double)0);
	}
	return result;
}


// Вычислить близость двух инф. элементов
// standard - вес элемента из документа образца
// verifiable - вес элемента из анализируемого документа
static private double Nearness(double standard, double verifiable)
{
	double k_max = standard;
	double k_min = verifiable;
	if (standard < verifiable)
	{
		k_max = verifiable;
		k_min = standard; 
	}
	double w = (k_min / k_max) * standard;
	return w;
}

// Сравнение контекстов
private static double CompareEnvironment(SortedList environment1, SortedList environment2)
{
		// Выполнить пересечение двух множеств
		int intersection = 0;
		foreach (string ie in environment1.Keys)
		{
			if (environment2.Contains(ie)) intersection++;
		}
		double result = (double)(intersection * 2) / (double)(environment1.Count + environment2.Count);
		return result;
}

Процедура CalculateNearness реализует вычисление тематической близости. Входные параметры:
standard – список ключевых элементов текста образца, хранимые пары значений: key типа string  - имя информационного элемента и value типа IE_Value;
verifiable – список ключевых элементов анализируемого на тематическую близость текста;
range – окрестность, в которой будет учитываться контекст.
Выходные параметры:
total – значение тематической близости;
список ключевых элементов (SortedList) с отдельно вычисленной тематической близостью по каждому информационному элементу. 
Порядок работы процедуры.
1) Проход по всем информационным элементам standard
for (int i = 0; i < standard.Count; i++),
string ie = (string)standard.GetKey(i).
2) Проверка существования информационного элемента ie в списке verifiable: if (verifiable.Contains(ie))
3) При наличии такого элемента в verifiable - вычисление тематической близости для данного информационного элемента.
double w = Nearness(k1, k2). 
4) Учет контекста. 
ArrayList environment1 = search.SearchContext(subject, range, 0),
ArrayList environment2 = search.SearchContext(subject, range, 0).
И затем вызов процедуры CompareEnvironment, которая возвращает коэффициент контекстной близости  , учитывающий идентичность  контекстов. Процедура CompareEnvironment реализует вычисление по формуле:
  

5) Вычисление общей тематической близости: total += w.
И формирование выходного списка ключевых элементов с отдельно вычисленными значениями тематической близости по каждому из инф. элементов: result.Add(ie, w). Формирование данного списка не обязательно, если требуется получить только значение общей тематической близости по всему тексту. При тестировании библиотеки, с помощью этого списка удобно контролировать промежуточные расчеты. 


 

 
3.5. Программная реализация алгоритма поиска значений информационных признаков тематики текста.

// Поиск параметров тематики
public double FindParamSubject(string text_v1, string text_v2, 
								double expert_v1, double expert_v2, 
								ref int threshold, ref int range, ref double scale)
{
	double[,] array_v1 = null;		
	CalculateNearnessParam(text_v1, ref array_v1);

	double[,] array_v2 = null;		
	CalculateNearnessParam(text_v2, ref array_v2);

	double diff = MinimizationDiff(expert_v1, expert_v2, array_v1, array_v2, ref threshold, ref range, ref scale);

	return diff;
}

// textVerifiable - ализируемый на тематическую близость
// текст
public void CalculateNearnessParam(string textVerifiable, ref double[,] array) 
{
	// Подготавливаем информационную структуру анализируемого текста
	InfoAnalyzer ia_verifiable = CreateAnalyzer(textVerifiable);
	array = new double[param_range.Length, param_threshold.Length];
	for (int k = 0; k < param_threshold.Length; k++)
	{
		int threshold = param_threshold[k];
		for (int i = 0; i < param_range.Length; i++)
		{
			int range = param_range[i];

			SortedList standard = null;
			SortedList verifiable = null;

			// Выделяем наборы ключевых элементов
			standard = GetKey(threshold, range, 1);
			verifiable = ia_verifiable.GetKey(threshold, range, 1);

			// Вычисляем тематическую близость
			double nearness = 0;
			CalculateNearness(standard, verifiable, range, ref nearness);
			array[i, k] = nearness;
		}
	}
}

// Создать экземпляр InfoAnalyzer для некоторого текста 
private InfoAnalyzer CreateAnalyzer(string text)
{
	InfoAnalyzer ia = new InfoAnalyzer(ignor);
	ia.Convert(text);
	return ia;
}

// Конвертировать текст в информационный поток
public void Convert(string text)
{
	InfoConverter converter = new InfoConverter(text, allIE, ignor, ref index);
	index++;
}

// Минимизация diff и поиск оптимальных парметров выделения 
// тематики
public double MinimizationDiff(double expert_v1, double expert_v2,
								double[,] array_v1, double[,] array_v2, 
								ref int threshold, ref int range, ref double scale)
{
	int countT = param_threshold.Length;
	int countR = param_range.Length;
	double diff_min = double.MaxValue;
	threshold = 0;
	range = 0;
	double calc_v1 = 0;
	double calc_v2 = 0;
	double diff_expert = expert_v2 / expert_v1;

	for (int k = 0; k < countT; k++)
	{
		for (int i = 0; i < countR; i++)
		{
			double diff_calc = array_v2[i, k] / array_v1[i, k];
      double diff = Math.Abs(diff_expert - diff_calc);
			if (diff < diff_min)
			{
				diff_min = diff;
				threshold = param_threshold[k];
				range = param_range[i];
				calc_v2 = array_v2[i, k];
				calc_v1 = array_v1[i, k];
			}
		}
	}
	scale = ((expert_v1 / calc_v1) + (expert_v2 / calc_v2)) / 2.0;
	return diff_min;
}

Процедура FindParamSubject реализует поиск параметров тематики (значений информационных признаков тематики текста). 
Входные параметры:
text_v1 – текст 1 оцененный экспертом на тематиче6скую близость по отношению к тексту образцу. В качестве текста образца выступает уже сформированная к настоящему времени информационная структура. Все перечисленные выше процедуры – методы класса InfoAnalyzer, соответственно они имеют доступ к информационной структуре, связанной с данным классом,  через атрибут класса allIE (список всех инф. элементов). 
text_v2 – текст 2 оцененный экспертном.
expert_v1 – оценка тематической близости текста 1 по отношению к тексту образцу. 
expert_v2 – оценка тематической близости текста 2.
Выходные параметры:
threshold – порог в процентах, необходимый для выделения первичного множества ключевых элементов;
range – окрестность, необходимая для контекстного анализа;
scale – масштабирующий коэффициент.
Процедура FindParamSubject реализует вызов процедуры CalculateNearnessParam для текста 1 и 2, эта процедура вычисляет массивы значений (для каждого из текстов) тематической близости с различными комбинациями параметров использованных при выделении тематики.  
Комбинируются параметры на основе массивов заданных значений: param_threshold и param_range.
Эти массивы определены как атрибуты класса InfoAnalyzer.
public class InfoAnalyzer
{
	... 
	public int[] param_threshold = new int[] {90, 80, 70, 60, 50,
	40, 30, 20, 10};
	public int[] param_range = new int[] {0, 1, 2, 3, 4, 5, 6, 7, 8,
	9, 10, 11, 12};
	...

Результат работы процедуры CalculateNearnessParam для двух текстов – массивы array_v1 и array_v2. Эти массивы используются процедурой MinimizationDiff, которая осуществляет поиск оптимальных параметров на основе ранее вычисленных значений тематической близости (array_v1, array_v2). Поиск реализуется простым перебором.


3.6. Выводы

В данной главе рассмотрены практические вопросы организации поиска документов по образцу на основе предложенной в работе модели, метода и алгоритмов, а также приведена их конкретная реализация в виде объектно-ориентированного программного кода на языке C#. 
Представленные фрагменты кода позволяют детальнее рассмотреть практические аспекты реализации и использования предложенных в работе результатов. 
 
4. ПРОВЕДЕНИЕ ЭКСПЕРИМЕНТАЛЬНЫХ ИССЛЕДОВАНИЙ

4.1. Планирование эксперимента

Необходимо провести экспериментальное исследование адекватности и корректности представленного в работе метода и алгоритмов тематического анализа. Для каждого из них существуют свои особенности и условия, определяющие ход проведения эксперимента. Рассмотрим их подробнее.
1) Метод частотно-контекстной классификации тематики текста.
Само понятие тематики заведомо предполагает субъективный характер оценки получаемых результатов. Только человек может оценить, насколько тематика (машинное представление темы текста) адекватна теме текста (субъективному представлению пользователя о содержании текста). Также необходимо учитывать сильную зависимость от текста, адекватность и корректность выделения тематики можно оценить только по реальному тексту. Все это обуславливает характер и особенности экспериментальных исследований метода частотно-контекстной классификации тематики текста. 
Единственно возможный способ прямой оценки результатов использования метода – это приведение примеров выделения тематики некоторых текстов с различными параметрами, используемыми при выделении тематики.
Кроме этого существует возможность косвенной оценки метода частотно-контекстной классификации на основе экспериментальных исследований алгоритма вычисления степени тематической принадлежности текста к образцу. Очевидно, что корректность вычисления тематической близости зависит от корректности выделения тематики. Рассмотрим один из вариантов оценки результатов вычисления тематической близости.

2) Алгоритм вычисления степени тематической принадлежности текста к образцу.
Корректность и адекватность данного алгоритма, а вместе с ним  метода частотно-контекстной классификации тематики текста можно оценить по сходимости следующего условия:
 ,
(4.1)
w3 стремится к 1, тогда и только тогда, когда модуль разницы w1 и w2 стремится к 0, где: w1, w2, w3 – тематическая близость между текстами T1, T2, T3. 

На рис. 4.1 обозначено, каким парам текстов соответствует каждое w.
 
Рис. 4.1. Соответствие текстов и коэффициентов тематической близости 

Смысл этого условия заключается в том, что тематически близкие тексты T3 и T2, будут одинаково тематически близки по отношению к T1. Точнее сказать, чем выше тематическая близости текстов T3 и T2, тем меньше разница тематической близости этих текстов по отношению к T1. 1 в нашем случае соответствует максимальному значению тематической близости.

На рис. 4.2 приведен график, соответствующий условию (4.1).
 
Рис. 4.2. График распределения величин тематической близости 

Вычисляя w1, w2, w3 для некоторой комбинации из трех документов, будем формировать распределение полученных величин в соответствии с осями графика (рис. 4.2). Результат сходимости идеального графика с графиком, полученным в результате экспериментальных исследований, будет характеризовать корректность предложенного в данной работе алгоритма вычисления степени тематической принадлежности текста к образцу, а вместе с ним и метода частотно-контекстной классификации тематики текста. 
Вместе с тем, говорить о полной корректности и адекватности указанного выше метода и алгоритма по сходимости условия (4.1), безусловно, не правомерно, это всего лишь один из критериев. Критерий весьма показательный и наглядный, но, тем не менее, недостаточный. Дальнейшую проверку необходимо выполнять на основе конкретных величин, сравнивая вычисленные оценки тематической близости с экспертными оценками по некоторой заданной коллекции текстов. Такая проверка уместна и адекватна только в контексте проверки алгоритма поиска значений информационных признаков тематики текста, т.е. алгоритм вычисления степени тематической принадлежности текста к образцу и алгоритм поиска значений информационных признаков тематики текста необходимо оценивать вместе, одновременно. Сами по себе вычисленные значения тематической близости ни о чем не говорят, их необходимо сравнивать с экспертными оценками и на основе сравнения делать выводы о корректности представленного метода и алгоритмов.

3) Алгоритм поиска значений информационных признаков тематики текста.
Проверку данного алгоритма осуществим путем проведения нескольких серий экспериментов. Для каждой серии будут заданы экспертные оценки тематической близости некоторых текстов, по этим оценкам будет осуществлен подбор оптимальных параметров и последующее вычисление тематической близости текстов. После этого проанализируем полученные результаты.

4) Сравнение точности вычисления тематической близости.
Помимо проверки корректности и адекватности указанного выше метода и алгоритмов необходимо оценить их эффективность в сравнении с уже существующими подходами. Однако здесь существует ряд сложностей.
Сравнение алгоритма поиска значений информационных признаков тематики текста с аналогичным ему стандартным алгоритмом не представляется возможным в ввиду отсутствия последнего. 
Сравнение эффективности выделения тематики также представляется затруднительным по уже перечисленным выше соображениям относительно исключительной субъективности самого понятия тематики.
Единственно приемлемым вариантом какой-то сравнительной оценки эффективности предложенного в данной работе метода и алгоритмов тематического анализа  является сравнение точности вычислений тематической близости предложенным в работе алгоритмом с точностью вычислений, полученных стандартным способом. 
Экспериментальные исследования будем проводить на заданной коллекции текстов, содержание текстов приводится в приложении.
Тексты именуются следующим образом:
n_m
n – номер тематической группы 
m – номер в подгруппе
В тестовой коллекции выделены следующие тематические группы:
1) Пушкин - Любовь 		1_1, 1_2, 1_3
2) Пушкин - Свобода 		2_1, 2_2, 2_3
3) Пушкин - Природа 		3_1, 3_2, 3_3
4) Генетические алгоритмы	4_1, 4_2, 4_3
Первые три группы тематически близки, объединяет их анализ творчества Александра Сергеевича Пушкина. Каждая отдельная группа имеет свою характерную тематическую направленность. Это необходимо, чтобы точнее оценить корректность вычисления тематической близости текстов.
Тексты 1,2,3-й группы сформированы на основе школьных сочинений по анализу творчества поэта. Тексты 4-й группы сформированы на основе обзорных статей по генетическим алгоритмам.
Характеристики текстов						Таблица 4.1
	1_1	1_2	1_3	2_1	2_2	2_3	3_1	3_2	3_3	4_1	4_2	4_3
n(I)	246	203	146	275	250	195	327	315	361	192	363	206
n(F)	385	299	175	327	329	248	459	482	456	352	707	361
n(I)/n(F)	0.64	0.68	0.83	0.84	0.76	0.79	0.71	0.65	0.79	0.55	0.51	0.57

n(I) – количество уникальных слов текста;
n(F) – количество слов в тексте; 
n(I) / n(F) – соотношение характеризующее адекватность тематической классификации;
n(I) и  n(F) приводятся с учетом предварительной подготовки текстов (с учетом исключения “стоп-слов” – союзов, местоимений и т.д.).

 
4.2. Результаты экспериментальных исследований метода частотно-контекстной классификации

4.2.1. Автоматизированное выделение тематики

Проведем серию экспериментальных исследований программной реализации представленного ранее метода частотно-контекстной классификации для случая, когда выделение тематики осуществляется системой самостоятельно (в отличие от режима дополнения множества ключевых слов заданных пользователем). 
Далее в таблице приводятся списки слов и их веса (определяющие значимость данных слов в тематике), полученных в результате выделения тематики. Каждая таблица разделена на четыре столбца, в заголовке каждого из них параметры, использованные при выделении тематики.
Первый параметр соответствует порогу, используемому для выделения первичного набора ключевых элементов. Порог задается в процентах от максимально возможной частоты некоторого слова данного текста. Все информационные элементы, частота которых равна или превышает порог, входят в результирующую выборку. 
Второй параметр – это окрестность, в которой происходит анализ контекста. На основе этой величины формируется набор уточняющих информационных элементов. В таблице приводится общее множество ключевых элементов, сформированное из первичного множества и уточняющего множества.
Пример задания параметров:
80, 0.
80 – процент от максимальной частоты, определяющий порог.
0 – окрестность.
Данный пример – это вариант стандартного выделения тематики, без учета уточняющего множества (т.к. окрестность равна 0).
Примечания: 
- первое слово в списке соответствует наиболее часто встречающемуся слову в тексте, и его частота – соответствует максимальной частоте (относительно которой задается порог);
- особенность данной алгоритмической реализации предполагает исключение слов из результирующей выборки, если количество их повторений не превышало единицу.

Результат анализа текста  4_1.				
								Таблица 4.2
80, 0	80, 1	80, 5	80, 10
популяция	11	популяция	11	популяция	11	популяция	11
особь	11	особь	11	особь	11	особь	11
га	10	га	10	га	10	га	10
оператор	9	оператор	9	оператор	9	оператор	9
		скрещивание	5	приспособленность	7	приспособленность	7
		селекция	4	скрещивание	6	мутация	7
		приспособленный	3	алгоритм	6	хромосома	6
		алгоритм	3	хромосома	5	скрещивание	6
		хромосома	2	селекция	5	отбор	6
		приводить	2	рулетка	5	алгоритм	6
		приспособленность	2	мутация	5	селекция	5
		одноточечный	2	решение	4	рулетка	5
				поколение	4	ген	5
				отбор	4	решение	4
				генетический	4	поколение	4
				турнир	3	генетический	4
				приспособленный	3	точка	3
				одноточечный	3	турнир	3
				метод	3	сектор	3
				задача	3	соответствующий	3
				ген	3	приспособленный	3
				вероятность	3	одноточечный	3
				selection	3	метод	3
				характеристика	2	изменение	3
				следующий	2	задача	3
				сектор	2	вероятность	3
				соответствующий	2	выбираться	3
				потомок	2	selection	3
				пропорциональный	2	эволюция	2
				приводить	2	характеристика	2
				осуществлять	2	турнирный	2
				оптимальный	2	сегмент	2
				кроссовер	2	стохастический	2
				колесо	2	следующий	2
				выбираться	2	разрыв	2
						приводить	2
						потомок	2
						пропорциональный	2
						оценка	2
						осуществлять	2
						оптимальный	2
						кроссовер	2
						комбинация	2
						колесо	2

Результат анализа текста 4_1.
									Таблица 4.3
60, 0	60, 1	60, 5	60, 10
популяция	11	популяция	11	популяция	11	популяция	11
особь	11	особь	11	особь	11	особь	11
га	10	га	10	га	10	га	10
оператор	9	оператор	9	оператор	9	оператор	9
хромосома	7	хромосома	7	хромосома	7	хромосома	7
приспособленность	7	приспособленность	7	приспособленность	7	приспособленность	7
мутация	7	мутация	7	мутация	7	мутация	7
скрещивание	6	скрещивание	6	скрещивание	6	скрещивание	6
отбор	6	отбор	6	отбор	6	отбор	6
алгоритм	6	алгоритм	6	алгоритм	6	алгоритм	6
		селекция	5	селекция	5	селекция	5
		генетический	4	рулетка	5	рулетка	5
		приспособленный	3	ген	5	ген	5
		турнирный	2	решение	4	решение	4
		приводить	2	поколение	4	поколение	4
		одноточечный	2	генетический	4	генетический	4
		ген	2	турнир	3	турнир	3
		вероятность	2	сектор	3	точка	3
				приспособленный	3	соответствовать	3
				одноточечный	3	соответствующий	3
				метод	3	сектор	3
				задача	3	приспособленный	3
				вероятность	3	одноточечный	3
				selection	3	метод	3
				эволюция	2	комбинация	3
				характеристика	2	изменение	3
				турнирный	2	задача	3
				соответствовать	2	гиперкуб	3
				следующий	2	выбираться	3
				стохастический	2	вероятность	3
				соответствующий	2	selection	3
				приводить	2	эволюция	2
				пропорциональный	2	характеристика	2
				потомок	2	турнирный	2
				оптимальный	2	строка	2
				оценка	2	сегмент	2
				осуществлять	2	следующий	2
				кроссовер	2	стохастический	2
				комбинация	2	разбиение	2
				колесо	2	разрыв	2
				изменение	2	приводить	2
				выбираться	2	потомок	2
						пропорциональный	2
						оценка	2
						оптимальный	2
						осуществлять	2
						колесо	2
						кроссовер	2
						двоичный	2
						бинарный	2


Результат анализа текста  4_1.				
									Таблица 4.4
40, 0	40, 1	40, 5	40, 10
популяция	11	популяция	11	популяция	11	популяция	11
особь	11	особь	11	особь	11	особь	11
га	10	га	10	га	10	га	10
оператор	9	оператор	9	оператор	9	оператор	9
хромосома	7	хромосома	7	хромосома	7	хромосома	7
приспособленность	7	приспособленность	7	приспособленность	7	приспособленность	7
мутация	7	мутация	7	мутация	7	мутация	7
скрещивание	6	скрещивание	6	скрещивание	6	скрещивание	6
отбор	6	отбор	6	отбор	6	отбор	6
алгоритм	6	алгоритм	6	алгоритм	6	алгоритм	6
селекция	5	селекция	5	селекция	5	селекция	5
рулетка	5	рулетка	5	рулетка	5	рулетка	5
ген	5	ген	5	ген	5	ген	5
точка	4	точка	4	точка	4	точка	4
строка	4	строка	4	строка	4	строка	4
решение	4	решение	4	решение	4	решение	4
поколение	4	поколение	4	поколение	4	поколение	4
задача	4	задача	4	задача	4	задача	4
генетический	4	генетический	4	генетический	4	генетический	4
		разрыв	3	турнир	3	турнир	3
		приспособленный	3	соответствующий	3	соответствующий	3
		турнирный	2	сектор	3	сектор	3
		турнир	2	соответствовать	3	соответствовать	3
		сектор	2	разрыв	3	разрыв	3
		соответствующий	2	приспособленный	3	приспособленный	3
		приводить	2	одноточечный	3	одноточечный	3
		одноточечный	2	метод	3	метод	3
		колесо	2	кодировка	3	кодировка	3
		возможный	2	гиперкуб	3	комбинация	3
		выбираться	2	вероятность	3	изменение	3
		вероятность	2	возможный	3	гиперкуб	3
		бинарный	2	выбираться	3	вероятность	3
				selection	3	выбираться	3
				эволюция	2	возможный	3
				характеристика	2	бинарный	3
				турнирный	2	selection	3
				стохастический	2	эволюция	2
				сегмент	2	характеристика	2
				следующий	2	турнирный	2
				разбиение	2	стохастический	2
				пропорциональный	2	следующий	2
				потомок	2	сегмент	2
				приводить	2	разбиение	2
				оценка	2	приводить	2
				осуществлять	2	потомок	2
				оптимальный	2	пропорциональный	2
				комбинация	2	оценка	2
				колесо	2	осуществлять	2
				кроссовер	2	оптимальный	2
				изменение	2	колесо	2
				двоичный	2	кроссовер	2
				бит	2	код	2
				бинарный	2	двоичный	2
						бит	2


Результат анализа текста 1_1.					
Таблица 4.5
80, 0	80, 1	80, 5	80, 10
пушкин	20	пушкин	20	пушкин	20	Пушкин	20
поэт	17	поэт	17	поэт	17	поэт	17
стихотворение	16	стихотворение	16	стихотворение	16	стихотворение	16
		лирик	6	лирик	10	лирик	12
		творчество	5	любовный	9	любовный	10
		холм	2	творчество	6	творчество	6
		период	2	переживание	4	поэзия	4
		оживать	2	тема	3	переживание	4
		любовный	2	романтический	3	южный	3
		возвышенный	2	поэзия	3	тема	3
				оживать	3	романтический	3
				любимая	3	период	3
				говориться	3	оживать	3
				возлюбленный	3	обращаться	3
				возвышенный	3	нежный	3
				альбом	3	любимая	3
				яркий	2	герой	3
				южный	2	говориться	3
				чудной	2	возвышенный	3
				холм	2	возлюбленный	3
				утаить	2	альбом	3
				табак	2	яркий	2
				трагичный	2	шутка	2
				ссылка	2	чудной	2
				стих	2	холм	2
				связать	2	утаить	2
				ранний	2	табак	2
				предмет	2	трагичный	2
				период	2	ссылка	2
				образ	2	сердечный	2
				обращаться	2	стих	2
				отечество	2	связать	2
				нюхать	2	ранний	2
				нежный	2	предмет	2
				мгновение	2	отечество	2
				легкий	2	образ	2
				красавица	2	нюхать	2
				красота	2	мечта	2
				идеал	2	мгновение	2
				источник	2	легкий	2
				жанр	2	красавица	2
				глубокий	2	красота	2
				грузия	2	источник	2
				герой	2	идеал	2
				грустный	2	жанр	2
				вечный	2	грузия	2
				воспоминание	2	грустный	2
						глубокий	2
						вечный	2
						весна	2
						воспоминание	2

Результат анализа текста 1_1.
							Таблица 4.6
60, 0	60, 1	60, 5	60, 10
пушкин	20	пушкин	20	пушкин	20	пушкин	20
поэт	17	поэт	17	поэт	17	поэт	17
стихотворение	16	стихотворение	16	стихотворение	16	стихотворение	16
лирик	12	лирик	12	лирик	12	лирик	12
		любовный	8	любовный	10	любовный	10
		творчество	6	творчество	6	творчество	6
		холм	2	переживание	4	поэзия	4
		стих	2	южный	3	переживание	4
		период	2	тема	3	южный	3
		переживание	2	романтический	3	тема	3
		оживать	2	период	3	романтический	3
		возвышенный	2	поэзия	3	период	3
				оживать	3	оживать	3
				любимая	3	обращаться	3
				говориться	3	нежный	3
				возлюбленный	3	любимая	3
				возвышенный	3	герой	3
				альбом	3	говориться	3
				яркий	2	возвышенный	3
				чудной	2	возлюбленный	3
				холм	2	альбом	3
				утаить	2	яркий	2
				трагичный	2	шутка	2
				табак	2	чудной	2
				ссылка	2	холм	2
				стих	2	утаить	2
				связать	2	табак	2
				ранний	2	трагичный	2
				петербургский	2	ссылка	2
				предмет	2	сердечный	2
				обращаться	2	стих	2
				образ	2	связать	2
				отечество	2	ранний	2
				нюхать	2	предмет	2
				нежный	2	петербургский	2
				мгновение	2	отечество	2
				легкий	2	образ	2
				красавица	2	нюхать	2
				красота	2	мечта	2
				идеал	2	мгновение	2
				источник	2	легкий	2
				жанр	2	красавица	2
				грустный	2	красота	2
				грузия	2	источник	2
				герой	2	идеал	2
				глубокий	2	жанр	2
				вечный	2	грузия	2
				весна	2	грустный	2
				воспоминание	2	глубокий	2
						вечный	2
						весна	2
						воспоминание	2

Результат анализа текста 1_1.
							Таблица 4.7
40, 0	40, 1	40, 5	40, 10
пушкин	20	пушкин	20	пушкин	20	пушкин	20
поэт	17	поэт	17	поэт	17	поэт	17
стихотворение	16	стихотворение	16	стихотворение	16	стихотворение	16
лирик	12	лирик	12	лирик	12	лирик	12
любовный	10	любовный	10	любовный	10	любовный	10
		творчество	6	творчество	6	творчество	6
		переживание	3	переживание	4	поэзия	4
		холм	2	южный	3	переживание	4
		стих	2	тема	3	южный	3
		предмет	2	романтический	3	тема	3
		период	2	период	3	романтический	3
		оживать	2	поэзия	3	период	3
		говориться	2	оживать	3	оживать	3
		весна	2	любимая	3	обращаться	3
		возвышенный	2	говориться	3	нежный	3
				возлюбленный	3	любимая	3
				возвышенный	3	герой	3
				альбом	3	говориться	3
				яркий	2	возвышенный	3
				чудной	2	возлюбленный	3
				холм	2	альбом	3
				утаить	2	яркий	2
				трагичный	2	шутка	2
				табак	2	чудной	2
				ссылка	2	холм	2
				стих	2	утаить	2
				связать	2	табак	2
				ранний	2	трагичный	2
				петербургский	2	ссылка	2
				предмет	2	сердечный	2
				обращаться	2	стих	2
				образ	2	связать	2
				отечество	2	ранний	2
				нюхать	2	предмет	2
				нежный	2	петербургский	2
				мгновение	2	отечество	2
				легкий	2	образ	2
				красавица	2	нюхать	2
				красота	2	мечта	2
				идеал	2	мгновение	2
				источник	2	легкий	2
				жанр	2	красавица	2
				грустный	2	красота	2
				грузия	2	источник	2
				герой	2	идеал	2
				глубокий	2	жанр	2
				вечный	2	грузия	2
				весна	2	грустный	2
				воспоминание	2	глубокий	2
						вечный	2
						весна	2
						воспоминание	2


4.2.2. Выделение тематики расширением первичного набора ключевых слов, задаваемых пользователем.

Данный вариант предполагает задание пользователем некоторого набора ключевых слов и расширение этого набора системой за счет контекстного анализа.
Вариант предусматривает работу как с отдельным документом, так и с обобщенным множеством тематически близких текстов. В  этом случае каждый текст дополняет общую структурную модель M(I, R). Совокупность текстов образует общую структуру, и контекстный анализ осуществляется уже на основе общей информационной структуры.
В таблице приводятся списки ключевых слов, заданных пользователем, и списки, полученные в результате контекстного анализа обобщенного множества текстов.
Список ключевых слов, полученных в результате работы программы, вместе с их весами приводится справа от списка, заданного пользователем.

Результат анализа текстов:  4_1, 4_2, 4_3. 
						Таблица 4.8
популяция	популяция	21	отбор	отбор	17
хромосома	хромосома	18	мутация	мутация	13
	особь	7		скрещивание	6
	отбор	5		популяция	6
	индивидуум	5		приспособленность	5
	скрещивание	4		кроссовер	5
	набор	4		естественный	5
	мутация	4		алгоритм	5
	генетический	4		ген	4
	следующий	3		эволюция	3
	случайный	3		хромосома	3
	поколение	3		селекция	3
	кроссовер	3		поколение	3
	ген	3		оператор	3
	эволюция	2		изменение	3
	частями	2		генетический	3
	свойство	2		турнирный	2
	сектор	2		реализовать	2
	решение	2		особь	2
	приспособленный	2		наследование	2
	приспособленность	2		метод	2
	объесть	2		механизм	2
	осуществлять	2		индивидуум	2
	одноточечный	2		га	2
	изменение	2		вероятность	2
	задача	2		selection	2
	генерация	2			
	вложение	2			
	вектор	2			
	вероятность	2			
	алгоритм	2			

Результат анализа текстов: 1_1, 1_2, 1_3, 2_1, 2_2, 2_3, 3_1, 3_2, 3_3.
				Таблица 4.9
осень	осень	17	свобода	свобода	14
поэзия	поэзия	11	царь	царь	9
	пушкин	10		рабство	4
	красота	6		пушкин	4
	стихотворение	4		поэт	4
	поэт	4		стихотворение	3
	любимый	4		учиться	2
	посвященный	3		темница	2
	описание	3		рухнуть	2
	зима	3		примета	2
	фрагмент	2		просвещение	2
	творчество	2		падший	2
	мотив	2		просвещенный	2
	лирик	2		пасть	2
	лета	2		отдать	2
	легкий	2		отечество	2
	автор	2		награда	2
				наказание	2
				мания	2
				личной	2
				кров	2
				днесь	2
				взойти	2


4.3. Результаты экспериментальных исследований алгоритма вычисления степени тематической принадлежности текста к образцу   

Как было уже сказано выше, корректность вычисления тематической близости будем оценивать по сходимости  условия 4.1. 
В качестве тестовых текстов возьмем тексты групп 1, 2, 3. Кроме того, сформируем дополнительное множество тематически близких им текстов на основе конкатенации текстов из указанных групп (в результате получится множество тематически близких текстов). Это необходимо для получения достаточного количества комбинаций из трех текстов, позволяющих построить распределение вычисленных значений тематической близости. 
Результаты распределения вычисленных значений приводятся ниже. 
Также приводятся значения информационных признаков тематики – параметров, использованных при выделении тематики: p – порог (используемый при выделении ключевых слов), r – окрестность (на основе которой выполняется дополнение первичного множества ключевых слов).  
По оси абсцисс будем  откладывать  , по оси ординат  .
p = 80%, r = 5
 
Рис. 3.4. Распределение значений тематической близости

p = 70%, r = 10
 
Рис. 3.5. Распределение значений тематической близости


p = 60%, r = 5
 
Рис. 3.6. Распределение значений тематической близости

p = 60%, r = 0
 
Рис. 3.7. Распределение значений тематической близости

p = 60%, r = 20
 
Рис. 3.8. Распределение значений тематической близости

Как видно из полученных результатов, условие (4.1) действительно выполняется.
 
4.4. Результаты экспериментальных исследований алгоритма поиска значений информационных признаков тематики текста

Проведем N серий экспериментов программной реализации алгоритма поиска значений информационных признаков тематики текста.
В каждой серии зададим некоторые экспертные оценки, и затем на основе найденных значений вычислим тематическую близость документов.
В таблице 4.10 приведены экспертные оценки для каждой серии экспериментов.
В таблице 4.11 приведены результаты вычисленных оценок тематической близости.
percent – порог; 
range – окрестность;
scale – масштабирующий коэффициент;
diff – разница соотношений оценок при оптимальных параметрах (вычисленная по формуле 2.1).

Экспертные оценки				Таблица 4.10
N	Документ образец	Анализируемый документ 1	Экспертная оценка	Анализируемый документ 2	Экспертная оценка
1	1_2	1_1	0.6	1_3	0.6
2	1_2	2_3	0.2	3_1	0.46
3	1_1	1_2	0.6	2_1	0.2
4	1_1	2_2	0.42	3_2	0.3
5	2_1	2_2	0.6	2_3	0.6
6	2_1	1_1	0.43	3_3	0.15
7	3_1	3_2	0.6	2_1	0.2
8	3_1	1_1	0.64	1_3	0.22


Вычисленные оценки					Таблица 4.11
N	percent	range	scale	diff		1_1	1_2	1_3	2_1	2_2	2_3	3_1	3_2	3_3
1	90	1	8.69	0.01	1_2	0.6	1	0.6	0.12	0.06	0.2	0.46	0.53	0.21
2	90	1	8.76	0.00	1_2	0.61	1	0.6	0.12	0.06	0.2	0.46	0.53	0.21
3	80	9	16.59	0.02	1_1	1	0.6	0.21	0.2	0.42	0.14	0.56	0.3	0.25
4	80	9	16.54	0.00	1_1	1	0.6	0.21	0.2	0.42	0.14	0.56	0.3	0.25
5	80	2	18.03	0.01	2_1	0.43	0.13	0.24	1	0.6	0.6	0.45	0.08	0.15
6	80	2	18.03	0.07	2_1	0.43	0.13	0.24	1	0.6	0.6	0.45	0.08	0.15
7	90	12	17.57	0.04	3_1	0.64	0.38	0.22	0.2	0.21	0.24	1	0.6	0.35
8	90	12	17.69	0.00	3_1	0.64	0.38	0.22	0.2	0.21	0.24	1	0.61	0.35


В таблице 4.11 приведены результаты экспериментальных исследований.
Для каждой серии определены оптимальные параметры (значения информационных признаков тематики текста) и на основе этих параметров, выполнено выделение тематики и расчет тематической близости (с учетом масштабирующего коэффициента). 
Для каждой серии определен текст-образец, относительно которого выполняется вычисление тематической близости. Для серии 1, 2 – это 1_2, для серии 3,4 – это 1_1, для серии 5,6 – это 2_1, для серии 7,8 – это 3_1. Таблицы 4.10 и 4.11 соотносятся между собой.
В заголовке таблице 4.11 по горизонтали перечислены тексты, анализируемые на тематическую близость с текстом образцом. На пересечении ячеек текста образца и текста, анализируемого на тематическую близость, – вычисленная оценка тематической близости.
Можно обратить внимание, что вычисленная оценка практически идентична оценке, заданной экспертом, diff определяет ошибку, чем меньше diff, тем меньше разница между вычисленными оценками и оценками, заданными экспертом. Величина diff характеризует точность подбора параметров, и, соответственно, характеризует все последующие вычисления по заданным параметрам. 
Качество и корректность тематического анализа, можно определить на основе анализа таблицы 4.11. 
Рассмотрим следующие характерные закономерности, присутствующие в приведенных результатах:
1) Сходимость оценок на произвольных текстах.
Оценки тематической близости сходятся не только для тех текстов, которые предварительно использовались для задания экспертной оценки, но и на произвольных текстах, которые впоследствии анализировались на тематическую близость с текстом образцом.
Рассмотрим подробнее серию 1 и 2.
Для серии 1 первоначально были заданы экспертные оценки между текстами 1_2, 1_1, 1_3.
Соответственно экспертная оценка близости для 1_2 - 1_1 равнялась 0.6 и 1_2  - 1_3 равнялась 0.6.
Вычисленная оценка для тех же самых документов идентична экспертной оценке, но данный критерий еще не является показателем качества и корректности, интересно проследить, как будут себя вести вычисленные оценки для других документов. Рассмотрим внимательно остальные оценки данной серии. Сказать что-то относительно правильности их значений затруднительно, так как сложно оценить с такой точностью представленные тексты и сказать, насколько корректны вычисленные результаты. Можно лишь с некоторой степенью достоверности предположить, что оценки близки к ожидаемым. Существует другой способ оценки корректности. 
В приведенной серии экспертные оценки выполнены для текстов из одной тематической подгруппы. Эксперт, по сути, задает меру тематической близости, и остальные оценки из других тематических подгрупп, по отношению к 1_2 отражают мнение эксперта. Проведем обратный эксперимент. Выберем в качестве экспертных оценок вычисленные значения, определим оптимальные параметры и получим уже вычисленные оценки для текстов ранее оцениваемых экспертом. По их разнице можно определить корректность алгоритма. Серия 2, по сути, отражает такой эксперимент. 
В качестве экспертных оценок данной серии выбраны ранее вычисленные значения, затем определены оптимальные параметры и вычислены оценки для всей серии.
Также организованны и другие серии.
Можно видеть, что оценки практически идентичны. Это является одним из косвенных свидетельств корректности разработанного в работе метода и алгоритмов тематического анализа.
 
2) Сходимость оценок в различных сериях.
Из таблицы 4.11 выделен фрагмент, рассмотрим его подробнее:

N		1_1	1_2	2_1	3_1
1	1_2	0.6	1	0.12	0.46
3	1_1	1	0.6	0.2	0.56
5	2_1	0.43	0.13	1	0.45
7	3_1	0.64	0.38	0.2	1


В серии 1 существует вычисленная оценка для 1_2 – 2_1, она равна 0.12
В серии 5 существует вычисленная оценка 2_1 – 1_2, она равна 0.13
Для этих двух серий существует совершенно независимые оценки тематической близости этих текстов, как видно, они практически совпадают.
Вычислим ошибку:
m = | 0.12 – 0.13 | = 0.01

Рассмотрим другие независимые оценки:
1_2 – 1_3 и 3_1 – 1_2
m = | 0.46 – 0.38 | = 0.08

1_1 – 3_1 и 3_1 – 1_1
m = | 0.56 – 0.64 | = 0.08

Полученная ошибка не превышает 0.08, если принять за 1 максимально возможную погрешность, то ошибка составляет 8% - это очень точный и качественный результат для подобного рода вычислений.
В совокупности по рассмотренным выше закономерностям можно сделать вывод о корректности и  высокой точности, разработанного в работе метода и алгоритмов тематического анализа.


 
4.5. Результаты экспериментальных исследований сравнения точности вычисления тематической близости.

Проведем серию вычислений тематической близости предложенным в данной работе алгоритмом вычисления тематической близости и сравним полученную точность с точностью вычислений, полученных одним из традиционных способов. 
В большинстве информационно-поисковых систем традиционным способом вычисления меры близости векторов является использование косинуса угла, определяемого через скалярное произведение векторов [8]:
 ,
где  и  - сравниваемые вектора.
После нормировки   и  по единице выражение можно переписать в виде  .

При сравнении точности будем руководствоваться следующими соображениями. 
Существует объективная сложность оценки точности вычислений тематической близости, т.к. отсутствуют эталонная мера тематической близости, с которой можно было бы сравнить вычисленные значения. Тем не менее, существует задача оценки точности вычислений, полученных одним способом вычислений в сравнении с другим. Было принято решение использовать косвенную оценку точности вычислений по чувствительности алгоритма расчета тематической близости. В данном контексте чувствительность – мера изменения тематической близости произвольного текста по отношению к тексту-образцу, при внесении в произвольный текст некоторого изменения.
Допустим, у нас есть оценка тематической близости произвольного текста к тексту-образцу, пусть сравниваемые тексты одинаковы, тогда оценка тематической близости текста по отношению к самому себе равна 1. Теперь внесем изменение в текст, сохранив предварительно его оригинал,  например, исключим из текста каждое n-е слово. После такого изменения снова вычислим тематическую близость полученного в результате изменения текста по отношению к тексту-оригиналу, выступающему в качестве образца. В результате вычисления мы получим некоторое новое значение тематической близости w, очевидно, что это новое значение будет меньше 1, т.к. тематика изменилась (или равно 1, если данный способ вычисления не чувствителен к данному изменению). Отношение w / 1 или просто w, определяет величину чувствительности. Обозначим ее S, и запишем как:
  ,  ,
(4.2)

Чувствительность тем больше, чем меньше величина тематической близости после некоторого изменения текста. Очевидна, в этом случае зависимость чувствительности от изменения, вносимого в текст. Сама по себе эта величина не представляет интереса, т.к. она зависит от текста и от изменений вносимых в него. Однако ее можно сравнивать с чувствительностью, полученной для другого способа вычисления тематической близости при тех же условиях – на том же тексте,  с тем же изменением.
Величину сравниваемой чувствительности можно записать как:
 ,
(4.3)

где: S и S’ – чувствительности, полученные разными способами вычисления тематической близости. Величина  показывает, на сколько чувствительность способа используемого при вычислении S больше чувствительности способа используемого при вычислении S’. Подставляя в формулу (4.3), формулу (4.2), запишем:
 ,
 .
Проведем серию вычислений  при различных изменениях вносимых в текст, среднее   будет характеризовать точность одного способа в сравнении с другим. 
Далее приводятся результаты вычислений для нескольких текстов. Обозначения:
w – величина тематической близости полученная предложенным в данной работе алгоритмом вычисления тематической близости;
w’ – величина тематической близости полученная в результате вычисления скалярного произведения векторов,  .

Текст 1_1.
Параметры, использованные при выделении тематики:
p = 50%, r = 0.
Численные значения 2, 3, …, 10 характеризуют изменения, вносимые в текст. Число соответствует исключению из текста каждого n – го слова. 
					Таблица 4.12
	2	3	4	5	6	7	8	9	10
w	0.36	0.6	0.57	0.7	0.62	0.76	0.65	0.86	0.84
w’	0.95	1	0.91	1	0.91	1	0.91	1	1
 	0.59	0.4	0.34	0.3	0.29	0.24	0.26	0.14	0.16

Текст 3_2.
p = 30%, r = 0.
						Таблица 4.13
	2	3	4	5	6	7	8	9	10
w	0.45	0.33	0.73	0.69	0.72	0.68	0.82	0.76	0.78
w’	0.91	0.51	0.96	0.9	0.97	1	0.92	0.88	1
 	0.46	0.18	0.23	0.21	0.25	0.32	0.1	0.12	0.22

Текст 3_1.
p = 30%, r = 0.
						Таблица 4.14	
	2	3	4	5	6	7	8	9	10
w	0.35	0.42	0.57	0.7	0.75	0.8	0.77	0.86	0.82
w’	0.86	0.65	0.84	0.92	0.94	1	0.93	1	1
 	0.51	0.23	0.27	0.22	0.19	0.2	0.16	0.14	0.18

Теперь можно подсчитать среднее   по всем текстам. При этом стоит учитывать один момент. Все  , рассчитанные при w’ = 1, не достаточно корректно отражают измерение чувствительности, т.к. 1 означает, что данный способ не смог зафиксировать изменение тематики (при данной модификации текста). Сравнение с ним чувствительности другого способа, в этом случае, не корректно. При вычислении среднего   будем учитывать только те измерения, когда w’ < 1.
Полученное среднее значение   = 0.28, если принять за 1 максимально возможное  , то  % = 28%.
Таким образом, косвенная оценка представленного в данной работе алгоритма вычисления тематической близости по сравнению со стандартным способом расчета, характеризует повышение точности приблизительно на 28%. 
 
4.5. Выводы

Результаты экспериментальных исследований успешно подтвердили выдвинутые ранее теоретические положения. Тестирование программной реализации разработанного метода и алгоритмов показало высокую точность и корректность полученных значений.
Вместе с тем, стоит отметить сложность оценки полученных результатов, и значительное влияние субъективной составляющей, присутствующей при оценке. Отчасти это вызвано характером и особенностью решаемых в данной работе задач, отчасти отсутствием формализованных методик оценки подобных исследований. Разработка таких методик может значительно упростить анализ результатов и однозначно определить их корректность и точность.
 
ЗАКЛЮЧЕНИЕ

В работе рассмотрены теоретические и практические вопросы решения задач поиска документов по образцу. Разработаны: модель структурного представления текстовой информации, метод и алгоритмы ее тематического анализа, позволяющие реализовать тематическую классификацию и вычисление степени тематической принадлежности текста к образцу. Предложенная модель, метод и алгоритмы могут использоваться как для решения конкретных задач поиска документов по образцу, так и для решения общих задач тематического анализа и обработки речевых высказываний. 
Также в диссертации заложен базис для дальнейшей теоретической и практической проработки методик экспериментальной оценки корректности и эффективности методов и алгоритмов тематического анализа. 
Можно выделить следующие основные результаты, полученные в диссертации:
1. Анализ текущего состояния информационно-поисковых систем, современного состояния исследований в области поиска документов по образцу и существующих методов тематического анализа.  
2. Графовая модель структурного представления текста произвольного содержания, позволяющая отобразить семантическую связность и последовательность текста в виде структуры. 
3. Метод частотно-контекстной классификации тематики текста, позволяющий выделять тематику текста в виде множества ключевых слов с весами, характеризующими значимость данных слов в тематике. 
4. Алгоритм вычисления степени тематической принадлежности текста к образцу, позволяющий получать количественную оценку тематической близости текстов. 
5. Алгоритм поиска значений информационных признаков тематики текста, позволяющий учесть субъективный характер оценки тематической близости текстов, и настроить систему, реализующую поиск документов по образцу под конкретного пользователя.
6. Программная реализация модели структурного представления текстовой информации и методов ее тематического анализа. 
7. Экспериментальная оценка корректности и эффективности выносимых на защиту результатов.
Разработанная модель, метод и алгоритмы позволяют значительно повысить точность и адекватность тематического анализа. Их реализация применительно к решению задач поиска документов по образцу позволяет значительно повысить качество и эффективность такого поиска. 
Программное обеспечение, разработанное в рамках диссертационной работы, нашло свое применение в ряде инженерных проектов, ориентированных на решение задач документооборота и информационно-справочного обеспечения.
Практическая значимость диссертации подтверждается актами о внедрении результатов исследования в Управлении по делам гражданской обороны и чрезвычайным ситуациям г. Вологды, Администрации г. Вологды, ООО “Премьер-Информ”. 
Основные положения и отдельные результаты работы докладывались и обсуждались на следующих конференциях и семинарах:
- на общероссийской научно-технической конференции  “Вузовская наука – региону”, (Вологда 2003 г.);
-  на международной научно-технической конференции “Информатизация процессов формирования открытых систем на основе САПР, АСНИ, СУБД и систем искусственного интеллекта (ИНФОС - 2003)”, (Вологда 2003 г.).
В качестве направлений дальнейших исследований можно выделить:
•	разработка методологии оценки качества и эффективности тематического анализа;
•	разработка алгоритма поиска значений информационных признаков тематики текста для произвольного числа оцениваемых экспертом текстов;
•	разработка модели поиска на основе структурного представления текста.
 
СПИСОК ИСПОЛЬЗОВАННОЙ ЛИТЕРАТУРЫ 

1.	Адарюков В.И. Исследование и разработка машинно-ориентированного метода инфологического моделирования информационно-поисковых систем фактографического типа: Диссертационная работа к.т.н.: 05.13.06 / Ленинградский электротехнический институт им В.И. Ульянова (Ленина). – СПб., 1988. – 256 с.

2.	Ахутина Т. В. Порождение речи. Нейро-лингвистический анализ синтаксиса - М.: МГУ, 1989. – 215 с.

3.	Белянин В.П. Введение в психолингвистику. – Изд. 2-е, испр. и доп., – М.: ЧеРо, 2000. – 128 с.

4.	Боровиков В. STATISTICA. Искусство анализа данных на компьютере: Для профессионалов. 2-е изд. – СПб.: Питер, 2003. – 688 с.

5.	Добрынин В.Ю., Некрестьянов И.С., Задача выбора тематических коллекций, релевантных запросу. // Труды Всероссийской научно-методической конференции “Интернет и современное сообщество”, Санкт-Петербург, декабрь 1998.

6.	Дубинский А.Г. Разработка моделей и совершенствование структуры систем информационного поиска в глобальной компьютерной сети:  Диссертационная работа к.т.н.: 05.13.06 / Днепропетровский национальный университет. – Днепропетровск, 2002. 

7.	Дубинский А.Г. Проблема автоматизации поиска информации в глобальной сети // Проблемы автоматизации информационных технологий. – Днепропетровск, 1999. - С. 40-48.

8.	Дубинский А.Г. Некоторые вопросы применения векторной модели представления документов в информационном поиске // Управляющие системы и машины. - 2001. - №4. - С. 77-83. 

9.	Ермаков А.Е. Полнотекстовый поиск: проблемы и их решение // Мир ПК. – 2000. - N5.

10.	Ермаков А.Е. Неполный синтаксический анализ текста в информационно-поисковых системах // Компьютерная лингвистика и интеллектуальные технологии: Труды Международного семинара Диалог’2002. В двух томах. Т.2. “Прикладные проблемы”. – Москва, 2002. - С. 180-185.

11.	Ермаков А.Е., Плешко В.В. Ассоциативная модель порождения текста в задаче классификации // Информационные технологии. - 2000. - N 12.

12.	Иванов В., Некрестьянов И., Пантелеева Н. Расширение представления документов при поиске в Веб // Труды четвертой всероссийской конференция RCDL'2002. В двух томах. Т.2. - Дубна, 2002. - C. 55-68.

13.	Когаловский М. Р. Перспективные технологии информационных систем. – М.: ДМК Пресс; М.: Компания АйТи, 2003. – 288 с.

14.	Когаловский М.Р. Энциклопедия технологий бах данных. – М.: Финансы и статистика, 2002. – 800 с.

15.	Кураленок И.Е., Некрестьянов И.С. Оценка систем текстового поиска // Программирование. – 2002. – N4. – С. 226-242.

16.	Кураленок И.Е., Некрестьянов И.С. Автоматическая классификация документов на основе латентно-семантического анализа // Труды первой всероссийской научно-методической конференции “Электронные библиотеки: перспективные методы и технологии, электронные коллекции”. – СПб., 1999. - C. 89-96.

17.	Лаищев И.В. Исследование и разработка моделей и методов организации информационно-поисковых систем фактографического типа с семантической надстройкой: Диссертационная работа к.т.н.: 05.13.06 / Ленинградский электротехнический институт им В.И. Ульянова (Ленина). – СПб., 1990. – 242 с.

18.	Лурия А.Р. Основы нейропсихологии - М.: МГУ, 1973. – 374 с.

19.	Некрестьянов И., Пантелеева Н. Системы текстового поиска для Веб //  Программирование. –  2002. – N4.

20.	Некрестьянов И.С., Добрынин В.Ю., Клюев В.В. Оценка тематического подобия текстовых документов // Труды второй всероссийской научной конференции “Электронные библиотеки”. – Протвино, 2000. – С. 204-210. 

21.	Некрестьянов И.C. Тематико-ориентированные методы информационного поиска: Диссертационная работа к.т.н.: 05.13.11 / Санкт-Петербургский государственный университет – СПб., 2000. – 80 c.

22.	Николаевская С.Г. Исследование и разработка машинно-ориентированного метода логического проектирования информационно-поисковых систем: Диссертационная работа к.т.н.: 05.13.06 / Ташкентский политехнический институт им А.Г. Беруни. – Ташкент, 1990. – 148 с.

23.	Романова Е.В., Романов М.В., Некрестьянов И.С.. Использование интелектуальных сетевых роботов для построения тематических коллекций // Программирование. – 2000. – N3. – C. 63-71. 
24.	Семенова С.Ю.  Поиск параметрической информации в тексте: алгоритмический    и    лексикографический   аспекты   //   Труды Международного семинара Диалог'96 по компьютерной  лингвистике  и приложениям. - М., 1996. – С. 227-230.

25.	Советский энциклопедический словарь / Научно-редакционный совет: А.М. Прохоров (пред.). – М.: “Советская энциклопедия”, 1981. – 1600 с.

26.	Сэлтон Г. Автоматическая обработка, хранение и поиск информации: Пер. с англ. / Под ред. А.И. Китова. – М.: Советское радио, 1973. – 560 c.

27.	Фрумкина Р.М. Психолингвистика: Учебник для студентов высших учебных заведений. – М.: Издательский центр “Академия”, 2001. – 320 с.

28.	Харламов А.А., Ермаков А.Е., Кузнецов Д.М. Технология обработки текстовой информации с опорой на семантическое представление на основе иерархических структур из динамических нейронных сетей, управляемых механизмом внимания // Информационные технологии. - 1998. - N 2. - С. 26-32.

29.	Чугреев В.Л., Моделирование систем искусственного интеллекта. // Перспективные технологии автоматизации: Тезисы докладов международной электронной научно-технической конференции. – Вологда: ВоГТУ, 1999. -  C. 151-152.

30.	Чугреев В.Л., Моделирование систем искусственного интеллекта. // Молодые исследователи – региону: Тезисы докладов Второй областной межвузовской студенческой научной конференции. – Вологда: ВоГТУ, 2000. – C. 5-6.

31.	Чугреев В.Л., Объектно-ориентированное программирование – перспективы развития. // Современные проблемы информатизации в технике и технологиях: Труды 5-й Международной электронной научной конференции. – Воронеж: ЦЧКИ, 2000. – C. 99-100.

32.	Чугреев В.Л., Расширение искусственных нейронных сетей применительно к задачам прогнозирования. // Молодые исследователи – региону: Материалы межрегиональной научной конференции студентов и аспирантов. – Вологда: ВоГТУ, 2002. – C. 231-232.

33.	Чугреев В.Л., Яковлев С.А., Выделение критериев поиска текста на основе подобия значимых  документов. // ВУЗОВСКАЯ НАУКА – РЕГИОНУ: Материалы 1-й Общероссийской нучн.-техн. конф. – Вологда: ВоГТУ, 2003. – C. 200-202.

34.	Чугреев В.Л., Яковлев С.А., Анализ структуры текста и прогнозирование нечисловых величин. // ВУЗОВСКАЯ НАУКА – РЕГИОНУ: Материалы 1-й Общероссийской нучн.-техн. конф. – Вологда: ВоГТУ, 2003. – C. 202-204.

35.	Чугреев В.Л., Яковлев С.А., Анализ текста, применительно к решению задач поиска документов по образцу. // Информатизация процессов формирования открытых систем на основе САПР, АСНИ, СУБД и систем искусственного интеллекта (ИНФОС - 2003): Материалы 2-й Межд. науч.-техн. конф. – Вологда: ВоГТУ, 2003. – C. 49-52.

36.	Aalbersberg I.J. Incremental relevance feedback. In Proceedings of the Fifteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 11-22, 1992.

37.	Aggarwal C. C., Al-Garawi F., Yu P. S. Intelligent crawling on the world wide web with arbitrary predicates. In Proc. of the WWW10, pp. 96-105, May 2001. 

38.	Agichtein E., Lawrence S., Gravano L. Learning search engine specific query transformations for question answering. In Proc. of the WWW10, pp. 169-178, 2001. 

39.	Allan J. Incremental relevance feedback. In Proceedings of the 19th International Conference on Research and Development in Information Retrieval (SIGIR '96), pages 298-306, April 1996.

40.	Amento B., Terveen L., Hill W. Does “authority” mean quality? Predicting expert quality ratings of web documents. In Proc. of the SIGIR'00, pp. 296-303, 2000. 

41.	Arasu A., Cho J., Garcia-Molina H., Paepcke A., Raghavan S. Searching the web. ACM Transactions on Internet Technology, 1(1):2-43, Aug. 2001. 

42.	Baeza-Yates R., Ribeiro-Neto B. Modern Information Retrieval. ACM Press, 1999. 

43.	Baker D. and McCallum A. Distributional clustering of words for text classification. In Proceedings of the SIGIR'98, pages 96-103, 1998.

44.	Bharat K., Broder A. A technique for measuring the relative size and overlap of public Web search engines. In Proc. of the WWW7, 1998. 

45.	Bharat K., Broder A. Z., Dean J., Henzinger M. R. A Comparison of Techniques to Find Mirrored Hosts on the WWW. IEEE Data Engineering Bulletin, 23(4):21-26, 2000. 

46.	Brown E.W. Execution Perfomance Issue in Full-Text Information Retrieval. Dissertation. University of Massachusetts. Departament of Computer Science. February 1996.


47.	Callan J. Learning while filtering documents. In Proc. of SIGIR'98, pages 224-231, Melbourne, Australia, 1998.

48.	Chakrabarti S., Berg M., Dom B. Focused Crawling: A New Approach to Topic-Specific Web Resource Discovery. In Proc. of the WWW8, May 1999. 

49.	Chang H., Cohn D., McCallum A. K. Learning to Create Customized Authority Lists. In Proc. of the ICML'00, pp. 127-134, 2000. 

50.	Cho J., Garcia-Molina H. The Evolution of the Web and Implications for an Incremental Crawler. The VLDB Journal, pp. 200-209, 2000. 

51.	Cho J., Shivakumar N., Garcia-Molina H. Finding replicated Web collections. In Proc. of the SIGMOD'00, pp. 355-366, 2000. 

52.	Cohn D., Chang H. Learning to Probabilistically Identify Authoritative Documents. In Proc. of the ICML'00, pp. 167-174, 2000. 

53.	Craswell N., Bailey P. Is it fair to evaluate Web systems using TREC ad hoc methods? In Proc. of the SIGIR'99, 1999. 

54.	Craswell N., Hawking D., Robertson S. Effective site finding using link anchor information. In Proc. of the SIGIR'01, 2001. 

55.	Cruz I. F., Borisov S., Marks M. A., Webb T. R. Measuring Structural Similarity Among Web Documents: Preliminary Results. In Proc. of the EP'98, pp. 513-524, 1998. 

56.	Czumaj A., Finch I., Gasieniec L., Gibbons A., Leng P., Rytter W., Zito M. Efficient Web Searching Using Temporal Factors. In Proc. of the WADS'99, pp. 294-305, 1999. 

57.	Davison B. D. Topical locality in the Web. In Proc. of the SIGIR'00, pp. 272-279, 2000. 

58.	Dean J., Henzinger M. Finding Related Pages in the World Wide Web. In Proc. of the WWW8, 1999. 

59.	Ding L., Shivakumar N. Computing Geographical Scopes of Web Resources. In Proc. of the VLDB'00, Sep 2000. 

60.	Dreilinger D., Howe A. E. Experiences with Selecting Search Engines Using Metasearch. ACM Transactions on Information Systems, 15(3):195-222, 1997. 

61.	Dublin Core Metadata Element Set Reference Description, Version 1.1, 1999-07-02. http:/purl.org/dc/documents/proposed_recommendations/pr-dces-19990702.html.

62.	Dumais S. Latent semantic indexing: TREC-3 report. In Proc. of the Third Text REtrieval Conference, 1995.

63.	Edwards J., McCurley K., Tomlin J. An adaptive model for optimizing performance of an incremental web crawler. In Proc. of the WWW10, pp. 106-113, May 2001. 

64.	Finkelstein L., Gabrilovich E., Matias Y., Rivlin E., Solan Z., Wolfman G., Ruppin E. Placing search in context: the concept revisited. In Proc. of the WWW10, pp. 406-414, 2001. 

65.	Flake G., Lawrence S., Giles C. L. Efficient Identification of Web Communities. In Proc. of the SIGKDD'00, pp. 150-160, Aug. 2000. 

66.	Foltz P.W. Using latent semantic indexing for information filtering. In ACM Conference on Office Information Systems (COIS), pages 40-47, 1990.

67.	Gibson D., Kleinberg J. M., Raghavan P. Inferring web communities from link topology. In Proc. of the UK Conference on Hypertext, pp. 225-234, 1998.

68.	Gravano L. Querying Multiple Document Collections Accross the Internet. PhD thesis, Stanford University, Aug 1997. 

69.	Gruber T. A translation approach to portable ontology specifications. Knowledge Acquisition, 5(2), 1993, pp. 199-220.

70.	Harman D. Latent semantic indexing (LSI) and TREC-2. In Proc. of the Second Text REtrieval Conference, 1994.

71.	Hatano K., Sano R., Duan Y., Tanaka K. An Interactive Classification of Web Documents by Self-Organizing Maps and Search Engines. In Proc. of the DASFAA'99, pp. 35-42, 1999. 

72.	Hatzivassiloglou V., Gravano L., and Maganti A. An investigation of linguistic features and clustering algorithms for topical document clustering. In Proc. of the SIGIR'2000, 2000.

73.	Haveliwala T. Efficient computation of PageRank. Technical report, Stanford Database Group, Oct. 1999. 

74.	Hawking D., Craswell N. Which Search Engine is best at finding Online Services? In Proc. of the WWW10, 2001. 

75.	Hawking D., Craswell N., Bailey P., Griffiths K. Measuring Search Engine Quality. Information Retieval, 4(1):33-59, 2001. 

76.	Hawking D., Craswell N., Thistlewaite P. B., Harman D. Results and Challenges in Web Search Evaluation. In Proc. of the WWW8, pp. 243-252, 1999. 

77.	Henzinger M., Heydon A., Mitzenmacher M., Najork M. Measuring Index Quality Using Random Walks on the Web. In Proc. of the WWW8, 1999. 

78.	Henzinger M., Heydon A., Mitzenmacher M., Najork M. On Near-Uniform URL Sampling. In Proc. of the WWW9, 2000. 

79.	Heydon A., Najork M. Mercator: A Scalable, Extensible Web Crawler. World Wide Web, 2(4):219-229, 1999. 

80.	Hirai J., Raghavan S., Garcia-Molina H., Paepcke A. WebBase: A repository of web pages. In Proc. of the WWW9, 1999. 

81.	Howe A. E., Dreilinger D. SavvySearch: A Metasearch Engine That Learns Which Search Engines to Query. AI Magazine, 18(2):19-25, 1997. 

82.	Huang L., Hemmje M., Neuhold E. J. ADMIRE: An Adaptive Data Model for Meta Search Engines. In Proc. of the WWW9, pp. 165-174, 2000. 

83.	Ipeirotis P., Gravano L., Sahami M. Probe, Count, and Classify: Categorizing Hidden-Web Databases. In Proc. of SIGMOD'01, 2001. 

84.	Jansen B. J., Spink A., Saracevic T. The Use of Relevance Feedback on the Web: Implications for Web IR System Design. In Proc. of the WebNet'99, pp. 550-555, 1999. 

85.	Jansen B. J., Spink A., Saracevic T. Real life, real users, and real needs: a study and analysis of user queries on the web. Information Processing and Management, 36(2):207-227, 2000. 

86.	Jing Y., Croft W.B. An Association Thesaurus for Informationa Retrieval. Department of Computer Science, University of Massachusetts at Amherst, 1994.

87.	Kahle B. Preserving the Internet. Scientific American, pp. 82-83, Mar. 1997. 

88.	Kleinberg J. M. Authoritative sources in a hyperlinked environment. 
Journal of the ACM, 46(5):604-632, 1999.

89.	Landauer T., Foltz P., and Laham D. An introduction to latent semantic analysis. Discourse Processes, 25:259-284.

90.	Lawrence S. Context in Web Search. IEEE Data Engineering Bulletin, 23(3):25-32, 2000. 

91.	Lawrence S., Bollacker K., Giles C. L. Indexing and Retrieval of Scientific Literature. In Proc of the CIKM'99, pp. 139-146, Nov. 1999. 

92.	Lawrence S., Giles C. L. Inquirus, The NECI Meta Search Engine. In Proc. of the WWW7, pp. 95-105, 1998. 

93.	Lawrence S., Giles C. L. Searching the World Wide Web. Science, 280(4):98-100, 1998. 

94.	Lawrence S., Giles C. L. Searching the Web: General and Scientific Information Access. IEEE Communications, 37(1):116-122, 1999. 

95.	Lawrence S., Giles C. L. G. Accessibility of information on the web. Nature, 400:107-109, 1999.

96.	Lempel R., Moran S. The stochastic approach for link-structure analysis and the TKC effect. In Proc. of the WWW9, 2000. 

97.	Lifantsev M. Voting Model for Ranking Web Pages. In Proc. of the IC'00, pp. 143-148, 2000.

98.	Liu K.-L., Meng W., Yu C. T., Rishe N. R. Discovery of Similarity Computations of Search Engines. In Proc. of the CIKM'00, pp. 290-297, 2000. 

99.	Mark M., Cornelis J. v. R. The potential and actual effectiveness of interactive query expansion. In Proc. of the SIGIR'97, pp. 324-332, 1997. 

100.	Maron M.E., Kuhns J.L. On relevance, probabilistic indexing and information retrieval. Jornal of the ACM, No. 7, 1960, pp. 216-244.

101.	McCurley K. S. Geospatial Mapping and Navigation of the Web. In Proc. of the WWW10, 2001.

102.	Melnik S., Raghavan S., Yang B., Garcia-Molina H. Building a distributed full-text index for the web. In Proc. of the WWW10, pp. 396-405, May 2001. 

103.	Meng W., Liu K.-L., Yu C. T., Wu W., Naphtali R. Estimating the Usefulness of Search Engines. In Proc. of the ICDE'99, pp. 146-153, 1999. 

104.	Merkl D. A Handbook of Natural Language Processing: Techniques and Applications for the Processing of Language as Text, chapter Text data mining. Marcel Dekker, New York, 1998.

105.	Najork M., Wiener J. L. Breadth-first search crawler yields high-quality pages. In Proc. of the WWW10, pp. 114-118, May 2001. 

106.	Patel A., Petrosjan L., Rosenstiel W., editors. OASIS: Distributed Search System in the Internet. St. Petersburg State University Published Press, St. Petersburg, 1999. 

107.	Qui Y. and Frei H. Concept based query expansion. In Proc. of the SIGIR'93, pages 160-169, Pitsburgh, USA, 1993.

108.	Raghavan S., Garcia-Molina H. Crawling the hidden web. In Proc. of the VLDB'01, Sept. 2001.

109.	Randall K., Stata R., Wickremesinghe R., Wiener J. The link database: Fast access to graphs of the web. Technical Report 175, COMPAQ SRC, Nov. 2001. 

110.	Rochio J. J. Relevance Feedback in Information Retrieval. Prentice-Hall Inc., 1971.

111.	Salton G., Buckley C. Improving retrieval performance by relevance feedback. Journal of the American Society of Information Science, 41(4):288-297, 1990. 

112.	Salton G., Buckley C. Term-weighting approaches in automatic text retrieval. Information Processing and Management, 24:513-523, 1988.

113.	Salton G., McGill M. J. Introduction to modern Information Retrieval. McGraw-Hill Computer Science Series. McGraw-Hill, New York, 1983. 

114.	Salton G., Allan J., and Singhal A. Automatic text decomposition and structuring. Information Processing & Management, 32(2):127-138, 1996.

115.	Salton G., Singhal A., Mitra M., and Buckley C. Automatic text decomposition and summarization. Information Processing & Management, 33(2):193-208, 1997.

116.	Salton G., Fox E., and Wu H. Extended Boolean information retrieval. Communications of the ACM, Vol. 26, No. 4, December 2001, pp. 35-43.

117.	Shivakumar N., Garcia-Molina H. Finding Near-Replicas of Documents on the Web. In Proc. of the WebDB'99, 1999. 

118.	Singhal A. Modern Information Retrieval: A Brief Overview. Data Enginering Bulletin, IEEE Computer Society, Vol. 24, No. 4, December 2001, pp. 35-43.

119.	Singhal A., Kaszkiel M. A case study in web search using TREC algorithms. In Proc. of the WWW10, pp. 708-716, 2001. 

120.	Singhal A., Mitra M., and Buckley C. Learning routing queries in a query zone. In Proc. of the SIGIR'97, pages 25-32, July 1997.

121.	Stata R., Bharat K., and Maghoul F. The term vector database: fast access to indexing terms for web pages. In Proc. of the WWW-9, May 2000.

122.	Stephen D., Ravi K., Kevin M., Sridhar R., Sivakumar D., Andrew T. Self-similarity in the Web. In Proc. of the VLDB'01, Sept. 2001. 

123.	Stephen B. Hunter-Gatherer: Applying  Constraint Satisfaction, Branch-and-Bound and Solution Synthesis to Natural Language Semantics NMSU CRL Technical Report. MCCS-96-292.

124.	Tajima K., Hatano K., Matsukura T., Sano R., Tanaka K. Discovery and Retrieval of Logical Information Units in Web. In Proc.of the WOWS'99, Aug. 1999. 

125.	Tajima K., Mizuuchi Y., Kitagawa M., Tanaka K. Cut as a Querying Unit for WWW, Netnews, and E-mail. In Proc. of Hypertext'98, pp. 235-244, June 1998. 

126.	The 25th ACM SIGIR 2002 Conference, 11-15 August 2002, Tampere, Finland. http://www.sigir2002.org/html/aresofinterest.htm.

127.	Turtle H. R. Inference Networks for Document Retrieval. Dissertation. University of Massachusetts. Department of Computer and Information Science. February 1991.

128.	Voorhees E., Harman D. Overview of the ninth text retrieval conference. In Proc. of the TREC9, pp. 1-15, 2000.  
129.	Yang Y., Pederson J. Feature selection in statistical learning of text categorization. In Proc. of the ICML'97, pages 412-420, 1997.

130.	Zeinalipour-Yazti D., Dikaiakos M. High-Performance Crawling and Filtering in Java. In Proc. of the 8th Panhellenic Conference on Informatics, volume 2, pp. 377-386, Nov. 2001. 

131.	Zhang D., Dong Y. An efficient algorithm to rank web resources. In Proc. of the WWW9, pp. 449-455, 2000. 

132.	Zhu X., Gauch S. Incorporating quality metrics in centralized/distributed information retrieval on the World Wide Web. In Proc. of the SIGIR'00, pp. 288-295, 2000. 

133.	Zonghuan W., Weiyi M., Clement Y., Zhuogang L. Towards a highly-scalable and effective metasearch engine. In Proc. of the WWW10, 2001.


















ПРИЛОЖЕНИЕ
 
1_1 Любовная лирика А.С.Пушкина
Любовная лирика А.С.Пушкина. А.С.Пушкин - прежде всего поэт - лирик. В своем творчестве он обращался к темам, которые больше всего волновали его: к темам любви, свободы, дружбы, творчества. В стихотворениях поэт выражал свое видение мира, свои переживания. Лирика дает наиболее полное представление об идеалах и жизненных ценностях поэта. В стихотворениях все значимо: каждый образ, каждая художественная деталь, ибо только с помощью таких приемов можно выразить все богатство и разнообразие переживаний. Любовь для Пушкина - спутница юности. Но она сопровождает поэта всю жизнь. В своем творчестве поэт неоднократно возвращается к теме любви. В ранний период творчества Пушкин пишет о дружеских пирушках, о радостях и разочарованиях любви. Юного поэта интересовали любовные забавы. Почти все стихотворения этого периода игривы. Ах! Если превращенный в прах, И в табакерке, в заточенье, Я в персты нежные твои попасться мог, Тогда в сердечном восхищенье, Рассыпался на грудь под шелковый платок И даже может быть ("Красавице, которая нюхала табак") Так, в стихотворениях "Красавице, которая нюхала табак", "Монах", "К Наташе" все обращается в шутку, в игру. Настоящего, возвышенного душевного единства нет. Для раннего творчества Пушкина характерен жанр "легкой поэзии". Считается, что Пушкин был последователем Анакреона - греческого лирика, автора легкой и эротической поэзии. Еще в Лицее Пушкин начинает писать в особом жанре любовной лирики - стихах в альбом. Интересно то, что поэт, не питавший обычно глубоких чувств к владелице альбома, должен был написать ей признание в любви. Пушкин обычно писал шутки в виде какого-либо парадоксального утверждения. Отечество почти я ненавидел - Но я вчера Голицину увидел И примирен с отечеством моим. ("В альбом Голициной") В петербургский период Пушкин пишет любовные стихи, подобные лицейским. ("О.Массон", "Как сладостно!.. Но боги, как опасноЕ"). Но появляется и нечто новое. Впервые появляется то, к чему впоследствии очень часто будет обращаться поэт: возвышенный идеал. "Где женщина не с хладной красотой, но с пламенной, возвышенной, живой?" Почти одновременно с этим Пушкин пишет оду "Вольность". В первых же ее строчках он изгоняет "царицу Цитеры" - богиню любви Афродиту, а "изнеженную лиру" собирается "разбить", чтобы "воспеть свободу". В петербургский период происходит постепенный переход от лицейской лирики к той новой, которая появится в южной ссылке. Все Дориды, Лиды и Темиры для Пушкины на Юге уже в прошлом. Сам он пишет о том, что было предметом его любовной лирики, как о прошлом, от которого настоящее уже далеко: Мне вас не жаль, года весны моей, Протекшие в мечтах любви напрасной  Где прежний жар и слезы вдохновенья? Придите вновь, года моей весны! В любовной лирике южного периода мы не найдем ничего, кроме грустного, даже трагичного. Это связано с тем, что в этот период почти все творчество поэта подчиняется законам такого литературного направления, как романтизм. Более того, подобно Байрону, Пушкин стремится сократить расстояние между собой и своим романтическим героем. Романтический герой - это беглец из несвободного и не понимающего его мира. Он изгнанник, оставивший в том мире свою любовь. Как уже говорилось, любовные стихотворения этого периода трагичны: Все кончено: меж нами связи нет В последний раз твой образ милый Дерзаю мысленно ласкать, Будить мечту сердечной силой И с негой робкой и унылой Твою любовь воспоминать. ("Прощанье") Считается, что все эти грустные мысли навевала Пушкину некая "утаенная любовь". "Утаенная любовь" подходила романтическому герою соответствовала его образу. Однако, по словам М.Н.Волконской, поэт обожал только свою музу и поэтизировал все, что видел. Но в любовной лирике Пушкин не новатор. Он романтик. Так, в стихотворении "Я помню чудное мгновенье" он говорит о нежном голосе, милых чертах, мятежном порыве. Литературоведы считают, что в стихах Пушкина прослеживается унынье, тоска, но есть "чудные мгновенья", которые связаны с любовью. В период южной ссылки поэт пережил много глубоких увлечений: любовь в Собаньской, любовь к Ризнич и Воронцовой. Любовь заполняет короткое время пребывания в Одессе. В многочисленных стихотворениях, посвященных возлюбленным, созданы яркие образы любимых женщин. Однако любовь рассматривалась как чувство преходящее. Пушкин не искал вечной любви, вечной для него была только потребность любить. Любовную лирику Пушкина после 1824 года не следует рассматривать как поэтический анализ его "донжуанского списка". В стихотворениях "На холмах Грузии", "Я вас любил" говорится именно о чувствах поэта, а не об отношениях, связывающих его с возлюбленными. В этих стихотворениях не стоит искать ответа на вопрос, кого имеет в виду поэт, признаваясь в искренней, нежной любви, говоря: "печаль моя полна тобою, тобой, одной тобой". В стихотворениях нет портрета возлюбленной. Любимых женщин Пушкин часто видит сквозь дымку воспоминаний и снов. В стихотворениях отражены не только любовные переживания о Женщине как об источнике красоты, гармонии, неизъяснимых наслаждений. В лирике Пушкина оживают его "любви пленительные сны". Это стихотворения - воспоминания. В стихотворении "Я вас любил" все чувства уже в прошлом, вернее, поэт пишет о том моменте, когда чувство уже угасает, но еще "угасло не совсем". В его душе оживает любовь-воспоминание. То же самое происходит в душе поэта в стихотворении "На холмах Грузии" Однако любовь оживает не только потому, что поэт вспоминает о любимой. В ней источник новых ярких переживаний. И сердце вновь горит и любит оттого, Что не любить оно не может. В этом стихотворении говорится о той любви, которая вдохновляла поэта. Любовь для Пушкина-лирика становится предметом высокой поэзии. Она словно выведена за пределы быта, житейской "прозы". "Стихотворения, коих цель горячить воображение любострастными описаниями, унижают поэзию" - говорит Пушкин.

1_2 Любовная лирика Пушкина
Любовная лирика Пушкина Любовь - самое дорогое, необходимое каждому человеку чувство; именно оно наполняет нашу жизнь смыслом, делает ее яркой, красочной. Отношение Пушкина к любви менялось на протяжении всей его жизни. В юности Пушкин в любви был язычником, но с возрастом отношение к любви становилось более серьезным. Примером этого может служить стихотворение "Я помню чудное мгновенье…" (1825 г), посвященное первой встрече в доме Олениных с Керн Анной Петровной. Пушкин передает ей это стихотворение в 1825 году, в то время, когда Керн собирается уехать в Ригу. Из этого стихотворения мы можем понять, что любовь для Пушкина является не просто источником наслаждения и радости, но и источником вдохновенья, творческой и жизненной энергии, так как, когда возлюбленная покидает поэта, жизнь его теряет смысл, из нее исчезают краски, запахи, звуки, она становится унылой: В глуши, во мраке заточенья Тянулись тихо дни мои Без божества, без вдохновенья, Без слез, без жизни, без любви. И лишь только любимая появляется вновь, к Пушкину возвращается вдохновение: И сердце бьется в упоенье, И для него воскресли вновь И божество, и вдохновенье, И жизнь, и слезы, и любовь. В дальнейшем любовь становится очень дорога поэту, даже любовь безответная. Пушкин благодарен женщине за то светлое чувство, которым она озарила его душу. Это хорошо видно из стихотворения "Я вас любил…" (1829 г). Впервые в русской литературе возлюбленный выступает как альтруист, готовый отказаться от своего счастья ради спокойствия возлюбленной, ведь любовь для Пушкина - это прежде всего любовь к своей избраннице, а не к самому себе и своему чувству. Пушкин благословляет имя той, которая внушила ему любовь, и надеется, что она когда-нибудь встретит человека, который будет любить ее так же сильно, как поэт ("…я вас любил так искренно, так нежно, как дай вам бог любимой быть другим"), и она сможет ему ответить взаимностью. Другие стихотворения, относящиеся к любовной лирике, - "Талисман", "Храни меня, мой талисман" и "Сожженное письмо" - посвящены Елизавете Ксаверьевне Воронцовой, женщине, с которой Пушкин познакомился во время южной ссылки. Эта женщина отличалась не только необыкновенной красотой, но и прекрасным образованием, воспитанием, умением тонко чувствовать. Пушкин полюбил ее, но Воронцова была замужем, и они были вынуждены расстаться. На прощание Воронцова дарит поэту перстень с изображением кабалистических знаков, точно такой же перстень она оставляет у себя. Именно этому перстню Пушкин и посвятил стихотворения "Талисман" и "Храни меня, мой талисман". В "Талисмане" (1827 г) П говорит о том, что получил в подарок талисман, который должен будет спасать его только от несчастной любви. Нельзя не отметить, что Пушкин с некоторой иронией говорит об этом талисмане: …в бурю, в грозный ураган, Головы твоей, мой милый, Не спасет мой талисман. В стихотворении "Храни меня, мой талисман" (1825 г) Пушкин показывает более серьезное отношение к талисману: Храни меня, мой талисман, Храни меня во дни гоненья, Во дни раскаянья, волненья: Ты в день печали был мне дан. Ведь талисман был подарен любимым человеком. Позже П в Михайловском часто получал письма, запечатанные таким же перстнем, как у него. Одно из таких писем Елизавета Ксаверьевна попросила поэта сжечь. Поэт долго не может решиться сделать этого, так как письма возлюбленной - это единственное, что у него осталось, но просьба Воронцовой все-таки была выполнена. Это событие Пушкин описывает в стихотворении "Сожженное письмо" (1825 г): Уж перстня верного утрате впечатленье, Растопленный сургуч кипит… О провиденье! Свершилось! Темные свернулися листы; На легком пепле их заветные черты Белеют… Грудь моя стеснилась. В конце жизни отношение Пушкина к любви стало совершенно одухотворенным, это особенно ярко видно из стихотворения "Мадона" (1830 г), посвященного будущей жене поэта - Гончаровой. Однажды Пушкин в антикварной лавке увидел картину кисти старинного итальянского мастера. На этой картине была изображена Мадона с младенцем, очень похожая на Гончарову. Пушкин захотел приобрести эту картину, но средств не хватило. Этому событию он и посвятил одно из своих замечательнейших стихотворений. Теперь женщина для него - "чистейшей прелести чистейший образец", Пушкин сравнивает ее с Богородицей. Женщина является хранительницей домашнего очага, символом материнства. Таким образом, мы видим, что, несмотря на то, что отношение Пушкина к любви менялось на протяжении всей его жизни, одно оставалось неизменным - его способность любить и быть благодарным за любовь. Пушкин с благоговением относится к жизни, воспринимая ее как удивительный божественный дар, а любовь - как своего рода концентрированное, обостренное ощущение жизни. Так же, как жизнь движется по своим законам, так и любовь возникает, расцветает и исчезает. Поэт не видит в этом трагедии, он благодарен судьбе за то, что это прекрасное чувство было в его жизни, потому что его могло и не быть. Яркий пример такого взгляда на любовь - стихотворение "На холмах Грузии лежит ночная мгла…" (1829 г): …и сердце вновь горит и любит - оттого, Что не любить оно не может. А это именно потому, что любовь является для Пушкина источником вдохновения, она помогает ему создавать необыкновенные по своей силе и лиричности произведения.

1_3 "Я вас любил" (лирика А.С.Пушкина)
"Я вас любил..." ( лирика А.С.Пушкина) ...Но чтоб продлилась жизнь моя, Я утром должен быть уверен, Что с вами днем увижусь я... А.С.Пушкин. У каждого человека, наверное, есть книги, к которым хочется возвращаться вновь и вновь. Для меня такими являются томики стихов Александра Сергеевича Пушкина. Как все, я вначале познакомился с его сказками (еще в раннем детстве мне читала их мама). Потом, с первого класса, в школе изучала его стихи. Когда же в мою жизнь вольно или невольно стали вторгаться светлые чувства любви, я поняла, что так проникновенно, страстно писать о любви мог только человек, сам испытавший эти высокие чувства. С удивлением я прочла, однако, в одной из книг о Пушкине, что директор лицея, где он учился, отзывался о нем, как о человеке, "оскверненном всеми эротическими произведениями французской литературы". Некоторые современники порицали в молодом Пушкине его любовные приключения как распутство. Да, конечно, у Пушкина немало стихов, которые можно назвать эротическими. Дотошные литературоведы подсчитали, что он посвящал свои стихи ста тридцати семи женщинам. Они только не понимают, что гению позволено больше порою, чем другим, что без вдохновения, созданного любовью, не будет прекрасных произведений о любви. А.Пушкин свою поэтическую энергию черпал именно в ней: Пройдет любовь, умрут желанья; Разлучит нас холодный свет; Кто вспомнит тайные свиданья, Мечты, восторги прежних лет? ( "В альбом", 1817 г.) Но самое для меня дорогое и удивительное не в том, что у поэта было много увлечений, а в том, что после женитьбы на Наталье Пушкин любил уже исключительно только жену и посвящал стихи только ей. Поэт сам отвечает на вопрос, изменял ли он жене: Нет, нет, не должен я, не смею, не могу Волнениям любви безумно предаваться; Спокойствие мое я строго берегу  и сердцу не даю пылать и забываться... ( "К...", 1832 г.) Когда они встретились впервые, ей едва минуло 16 лет. Она была в белом воздушном платье, с золотом на голове. Александр Сергеевич не мог отвести от нее глаз. Подъезжая под Ижоры, Я взглянул на небеса и вспомнил ваши взоры, Ваши синие глаза,- писал он ей. А когда вопрос окончательно решится, он напишет: Исполнились мои желания. Творец тебя мне ниспослал, Тебя, моя Мадонна, Чистейшей прелести чистейший образец. ("Мадонна", 1830 г.) Трудно быть женой гения, особенно, если ты при этом молода и очень красива. В их семейной жизни было всякое: радости, высокая любовь, четверо детей, но и, конечно, недомолвки, ссоры. А еще разлуки. Исследователи подсчитали, что за семнадцать месяцев, что Пушкин не виделся с женой, он написал ей 78 писем, больше, чем кому-либо в жизни. Мне грустно и легко; печаль моя светла; Печаль моя полна тобою, Тобой, одной тобой... Унынья моего Ничто не мучит, не тревожит, И сердце вновь горит и любит- оттого, Что не любить оно не может. ( "На холмах Грузии...") Не любить Наталью Николаевну сердце Пушкина, действительно, не могло. Поэтому и решился поэт на поединок с Дантесом - вступился за честь жены и свою собственную. После роковой дуэли, два дня борясь со смертью, о чем он думал? Может быть, вспомнил свои строчки, отнеся их теперь, как завещание, к Наталье: Я вас любил так искренно, так нежно, Как дай вам бог любимой быть другим. ("Я вас любил...") Листая стихи поэта, я порой думаю, какие удивительные люди жили в прошлом веке, как они умели любить. Встречу ли я в жизни хоть что-то похожее? 

2_1 Вольнолюбивая лирика А. С. Пушкина
ВОЛЬНОЛЮБИВАЯ ЛИРИКА А. С. ПУШКИНА Отдавая дань предшественникам, Александр никогда не забывал поклониться тени Андрея Шенье, - Окончив в 1817 году лицей и определившись на службу в Коллегию иностранных дел, Пушкин поселяется в Петербурге и «жадно предается светским развлечениям», что не мешает ему активно включиться в литературную и общественную жизнь столицы. А между тем над Россией «сгущаются сумерки» политической реакции. В противовес ей создаются первые тайные общества. Бесконечно веселые стихи А. С. Пушкина этой поры, развивающие традиции его лицейской анакреонтики, где поэт славил радости земного бытия, Вакха и Киприду, были проявлением избытка молодости, кипящих жизненных сил, но и своеобразной формой протеста против тех настроений ханжества и мистицизма, которыми были охвачены круги высшего придворного общества во главе с Александром I. Все чаще в стихах Пушкина в одном ряду со словами «Вакх», «Амур», «Венера» появляется и слово «свобода». Причем в устах поэта оно приобретает многозначность. Здесь звучит и личная независимость, дружеская непринужденность, свободный образ мыслей — «вольнолюбие», и свобода народа — порабощенного крестьянства. В их круге светлая свобода Прияла праздничный венок. Но двинулись толпы народа... Он приближается... Вот он, вот сильный бог! («Торжество Вакха») Пушкинский стих бунтует, ищет выхода своей кипучей энергии, желает найти справедливость в окружающем мире, нащупывает свой путь в литературе. До этого был период ученичества, когда поэт впитывал все накопленное в литературе до него. Теперь пришло время выплескивать из своей души превосходные стихи, блестящие по форме и глубокие по содержанию: Лемносский бог тебя сковал Для рук бессмертной Немезиды, Свободы тайный страж, карающий кинжал, Последний судия позора и обиды. («Кинжал») Поэзия — это своеобразный дневник автора. По лирике А. С. Пушкина можно судить о его пристрастиях, занятиях в то время. А вот в оде «Вольность» - проглядывают мотивы радищевской «Вольности»: та же Я примирюсь с силами зла, желание идти в борьбу против и до конца. Поэт бесстрашно бросает вызов сильным мира сего, он азартен до безрассудства. Увы! куда ни брошу взор — Везде бичи, везде железы, Законов гибельный позор, Неволи немощные слезы... И днесь учитесь, о цари: Ни наказанья, ни награды, Ни кров темниц, ни алтари Ни верные для вас ограды. Склонитесь первые главой Под сень надежную Закона, И станут вечной стражей трона Народов вольность и покой. Но сам автор не верит, что тираны «склонятся» к справедливости. Эта же мысль продолжена в произведении «Анчар» — историко-философской думе о суровых, непокорных человеку силах природы и бездне, открывающейся в душе самой личности. Зло, вероятно, неистребимо, если заложено в природе. В пустыне чахлой и скупой. На почве, зноем раскаленной, Анчар, как грозный часовой, Стоит — один во всей вселенной. Природа жаждущих степей Его в день гнева породила, И зелень мертвую ветвей И корни ядом напоила. Интересно, что автор не берется судить Творца, его не интересует цель создания «древа смерти» — порождения «гнева», но в жизни ничего не бывает случайно, если есть яд, обязательно найдутся люди, пожелавшие им воспользоваться. Причем Пушкин, сопоставляя человека с животным миром, показывает коварство первого. Ибо никому не нужен анчар, кроме людей. л нему и птица не летит, И тигр нейдет — лишь вихорь черный На древо смерти набежит — Умчится прочь, уже тлетворный. И есть тиран, пытающийся завладеть чужими землями, душами, жизнями. Они сродни — тиран и анчар, потому что несут гибель окружающим. Но человека человек Послал к анчару властным взглядом, И тот послушно в путь потек И к утру возвратился с ядом. Поэт и здесь продолжает радищевскую мысль о «зверообраз. ном самовластии», когда «человек повелевает человеком». Пушкину чужды оба образа: и «послушного раба», и «непобедимого владыки». Автору ненавистна сама действительность, при которой существуют рабы и владыки, но он ничего не может противопоставить взамен и поэтому тон стихотворения приобретает большую силу протеста из-за безысходности. И почти в то же время написаны «Стансы», в которых поэт верит в великое предназначение России. Он взывает к образу Петра I, желает быть ему подстать, зовет за собой поколение, обязанное не уронить былой славы отчизны. В надежде славы и добра Гляжу вперед я без боязни: Начало славных дней Петра Мрачили мятежи и казни, Но правдой он привлек сердца, Но нравы укротил наукой...

2_2 Вольнолюбивая лирика А. С. Пушкина
ВОЛЬНОЛЮБИВАЯ ЛИРИКА А. С. ПУШКИНА Пушкин ставил на первое место среди своих заслуг прославление свободы. Свобода останется темой его творчества на всю жизнь. Свобода для Пушкина — это прежде всего личная свобода и независимость. Это свобода выбора профессии, занятий, свобода от разного рода предрассудков. Это и свобода мысли: в отношении к искусству, к религиозным убеждениям, к взаимоотношениям с людьми. Поэт всегда отстаивал свободу творчества. Он не мог писать в угоду. В “Песни о вещем Олеге” Пушкин говорит о независимости и правдивости подлинной поэзии. Волхвы не боятся могучих владык, А княжеский дар им не нужен; Правдив и свободен их вещий язык И с волей небесною дружен. Пушкин мечтал об освобождении России от гнета самодержавия и крепостного права, все ужасы которого он показал в стихотворении “Деревня”: Здесь барство дикое, без чувства, без закона Присвоило себе насильственной лозой И труд, и собственность, и время земледельца. Склонясь на чуждый плуг, покорствуя бичам, Здесь рабство тощее влачится по браздам Неумолимого владельца. Здесь тягостный ярем до гроба все влекут. Стихотворение заканчивается призывом к царю уничтожить рабство и дать русскому народу свободу и просвещение: Увижу ль, о друзья! народ неугнетенный И Рабство, падшее по манию царя, И над отечеством Свободы просвещенной Взойдет ли наконец прекрасная заря? Поэт верит, что мечты его сбудутся. Об этом свидетельствуют строки из стихотворения “К Чаадаеву”: Товарищ, верь: взойдет она, Звезда пленительного счастья, Россия воспрянет ото сна, И на обломках самовластья Напишут наши имена! Поэт размышляет о путях и средствах достижения свободы: революционным путем, ценою крови или каким-либо иным? Революционные взгляды формировались у поэта под влиянием близких друзей: Чаадаева, Давыдова, Раевского, Пестеля. У Пушкина много стихотворений, в которых он рассказывает о движении декабристов и их судьбе, а также о своем участии в этом движении. В стихотворении “В Сибирь” он выражает надежду на скорое освобождение своих друзей-декабристов, говорит им, что не напрасны были их деяния, что их работа сыграет свою роль в освобождении народа: Хранит 1000 е гордое терпенье, Не пропадет ваш скорбный труд И дум высокое стремленье. Оковы тяжкие падут, Темницы рухнут — и свобода Вас примет радостно у входа, И братья меч вам отдадут. А в стихотворении “Арион” Пушкин заявляет, что после разгрома декабристов (“вдруг лоно волн приял с налету вихорь шумный. Погиб и кормщик и пловец!”) и спасения самого поэта он не отрекся от своих убеждений: Я гимны прежние пою... Он считал, что власть самодержавия — власть роковая, осужденная судьбой. Поэт мечтает о просвещенной монархии. В стихотворении “Стансы” он предлагает царю целую программу действий: заботиться о просвещении народа, покровительствовать науке, уважать и любить свою страну и постоянно трудиться для ее блага. Николаю он ставит в пример Петра: Но правдой он привлек сердца, Но нравы укротил наукой, Самодержавною рукой Он смело сеял просвещенье, Не презирал страны родной: Он знал ее предназначенье. Пушкин говорит, что свобода, “вольность” возможны и в монархическом государстве, если и царь, и народ строго соблюдают законы. Нарушение законов народом влечет за собой рабство, нарушение законов царем — грозит тирану гибелью. Владыки! вам венец и трон Дает Закон — а не природа; Стоите выше вы народа, Но вечный выше вас закон. И днесь учитесь, о цари: Ни наказанья, ни награды, Ни кров темниц, ни алтари Не верные для вас ограды. Склонитесь первые главой Под сень надежную Закона, И станут вечной стражей трона Народов вольность и покой. В стихотворении “Анчар” поэт показывает дисгармонию человеческого общества, где один человек имеет неограниченную власть над другими, на фоне гармонии природы. Поэт говорит, что тирания гибельна, опасна и для соседних стран: А царь тем ядом напитал Свои послушливые стрелы И с ними гибель разослал К соседям в чуждые пределы. В стихотворении “Я памятник себе воздвиг нерукотворный...” Пушкин как бы подводит итог своему творчеству. Он заслужил право на бессмертие и любовь народа тем, что поэзия его поднимает в людях все самое лучшее, что есть в их душе, и тем, что он “восславил свободу” и не переставал побуждать Николая I оказать “милость падшим”, вернуть сосланных декабристов. И долго буду тем любезен я народу, Что чувства добрые я лирой пробуждал, Что в мой жестокий век восславил я Свободу И милость к падшим призывал.

2_3 Тема вольности и протеста в стихах А. С. Пушкина
ТЕМА ВОЛЬНОСТИ И ПРОТЕСТА В СТИХАХ А. С. ПУШКИНА Бич жандармов, бог студентов, Желчь мужей, услада жен — Пушкин — в роли монумента? Гостя каменного? — он, Скалозубый, нагловзорый Пушкин — в роли Командора?.. М. Цветаева По-моему, очень точно схвачен Мариной Цветаевой образ поэта-мятежника, поэта-свободолюбца, поэта пламенного гражданского темперамента. Началось все с лицея. Для Пушкина лицей был не только источником дорогих воспоминаний, но и местом на земле, которое определило его мировоззрение и убеждения. Одной из задач преподавателей лицея было воспитание в молодых людях чувства чести и гражданского долга. Лицей дал России целую плеяду революционеров и прекрасных поэтов. В лицее Пушкин впервые начал задумываться о цели и смысле своей жизни. Надо сказать, что, учась в лицее, трудно было не стать вольнолюбивым поэтом, потому что почти все его педагоги были люди, близкие по своим взглядам к революционным дворянским обществам. Там же друзьями будущего великого поэта стали будущие Декабристы и будущие известные поэты. Среди них — Пущин, Кюхельбекер, Дельвиг. Атмосфера в лицее была весьма свободной, и поэтическое братство вырастало гармонично. Особенно напряженной творческой и политической жизнью отмечены петербургские дни поэта. Там Пушкин близко сходится с декабристами — М. Луниным, М. Орловым, И. Якушкиным. Тогда же укрепляется дружба поэта с Чаадаевым. Но, симпатизируя декабристам, Пушкин, на мой взгляд, придерживался несколько иных взглядов. Как сейчас принято говорить, Пушкин, несмотря на все свое вольнодумие, оставался законопослушным гражданином. Он не представлял себе революцию как хаотическую борьбу со всем старым. По его разумению, все должно было происходить в законных границах. Увижу ль, о друзья, народ неугнетенный И Рабство, падшее по мании царя, И над отечеством Свободы просвещенной Взойдет ли наконец прекрасная заря? Как видим, поэт считал, что процесс освобождения должен исходить от верхов, а не от низов. Я понимаю это как цивилизованные формы внедрения общественных и политических свобод, без кровопролития. Сейчас трудно сказать, кто был больше прав, но и Пушкин, и декабристы, и каждый прогрессивно мыслящий человек того времени сделали для России великое дело: приблизили ее к цивилизованному миру. После подавления восстания декабристов Пушкин не отрекается от своих друзей и единомышленников. Он поддерживает связь со ссыльными. Пишет им в Сибирь письма со стихами. Поддерживает их дух: Оковы тяжкие падут, Темницы рухнут — и свобода Вас примет радостно у входа, И братья меч вам отдадут. Но Пушкин был потрясен, узнав о казни пятерых декабристов. Рисунок виселицы стал часто появляться в его черновиках. Поэт явно не ожидал от царя такого поступка. Видимо, с той поры царь перестал быть для него запретной для критики фигурой. Он желает краха самовластью: Товарищ, верь: взойдет она, Звезда пленительного счастья, Россия воспрянет ото сна, И на обломках самовластья Напишут наши имена! Это не замедлило сказаться на отношении к поэту государственных чиновников и царя. Началась травля гения бездарностями от власти. Как мы знаем, отношениям этим никогда больше не суждено было потеплеть. Они грубым образом вторглись и в личную жизнь поэта, разметав его человеческий дом, лишив покоя на родной земле и в конце концов поставив великого поэта под дуло пистолета. Очевидцы свидетельствуют, что на смертном одре последние прощальные слова Пушкина были обращены к книгам, но, мне кажется, это было более прощание с Отечеством, лучшие образцы мыслей и духа которого были хранимы этими книгами. Друзья стояли рядом. Никто не обиделся и не удивился. Пушкин заслужил право и на эту последнюю для него на земле вольность.

3_1 Природная лирика Пушкина
Природная лирика Пушкина. " Унылая пора! Очей очарованье! Приятна мне твоя прощальная краса" Давно сказано и много раз повторено: природа безучастна. Но тогда почему же она так дивно соединяется с человеческим сердцем, и той возвышенной страстной силой его, которую издавна называют поэзией? Почему так глубоко волнуют и заставляют трепетать душу каждого картины природы, связанные с детством, пылкой отроческой любовью, первыми прозрениями и привязанностями или с теми святынями, что могут озарить всю жизнь не меркнущим светом? Почему в соприкосновении с природой не тускнет смысл, казалось бы, привычных и даже расхожих эпитетов" близкое ", " заветное ", " родное "? И почему понятия Родины сразу же и, прежде всего, вызывают в воображении точные картины дорогих палестин? Когда-то Достоевский сказал: " Красота спасёт мир ". Наша современная действительность нуждается в спасении: в трудных условиях материальной жизни человек должен найти точку опоры, чтобы не упасть духом, не скатиться в пропасть бытовых неурядиц, не замкнуться в самом себе. Поэт чутко понимает, что душу можно разбудить только тогда когда человек сможет радоваться каждому мигу жизни, сумеет найти поэзию в любом проявлении земных радостей. Музыка, природа, стихи - это радостно всем. В природе есть своё волшебство, своя чарующая прелесть, которая лечит душу приобщая её к прекрасному мигу осознания себя частицей всей Вселенной. Пушкин, Лермонтов, Тютчев и многие другие поэты оставили прекрасное наследие. Природа в картинах талантливых художников, поэтов, писателей открывает нам новый мир, волнует своей неповторимостью, своим напоминанием - не губите красоту вокруг себя. Сейчас, как никогда очень остро стоит вопрос экологии, вопрос - будет ли жизнь на земле, а если будет, то какая. Патриотизм всегда являлся национальной чертой русских поэтов, они могли в незаметной, внешне застенчивой русской природе находить смысл, природа всегда была для них источником вдохновения, источником живительной силы одаренной русской души. Пушкин в своих отступлениях в " Евгении Онегине " даёт чудесное описание природы, его стихи о природе полны любви, грусти об уходящем мгновении. Среди стихов Пушкина видное место принадлежит тем произведениям, где с изумительной силой он рисует картины природы. По мнению многих, литература - это слепок с жизни, но слепок более тонкий, более объективный. Одной из особенности поэта была разносторонность его дарования, хотя много творческих сил Пушкин отдал созданию реалистического пейзажа. Эта лирика была дорога поэту как возможность непосредственно высказать свои мысли, чувства, переживания. Поэтические страницы изображения природы в "Евгении Онегине" просто великолепны. " Как грустно мне твоё явление. Весна, весна Пора любви? Какое томное волнение в моей душе, в моей крови ", - пишет автор. Белинский очень точно заметил, что Пушкин, остро чувствует бег времени, выражает лучший тип русского национального характера своей эпохи. Его душа чужда кастовой изомерии и духовной ограниченности. Богатая духовная жизнь самого Пушкина позволяла ему открывать в природе таящуюся в ней красоту. Милые сердцу родные картины природы, нарисованные Пушкиным, не забываются никогда, как никогда нельзя забыть детство. Волнуют его строки из " Евгения Онегина ": " Люблю песчаный косогор, перед избушкой две рябины, калитку, сломанный забор, перед гумном соломы кучи, да пруд под сенью ив густых - раздолье уток молодых ". Из всех времён года Пушкин обожал осень. Он писал: " Из всех времён я рад лишь ей одной ". Несмотря на то, что Пушкин много писал об осени, чудесны его зарисовки в стихах: " Зимний вечер "," Зимнее утро ", " Зимняя дорога ", " И вновь я посетил ". В этих скромных внешних зарисовках каждому понятна и мила природа, с которой человек сталкивается на протяжении всей своей жизни. Его стихи " Кто знает край, где небо блещет ", " На холмах Грузии " стали шедеврами не только русской литературы, но и мировой. Ни один русский поэт не может сравниться с Пушкиным по прелести и лёгкости изображения молчаливой красоты природы. Я считаю, что картины природы в его лирике являлись превосходным средством воспитания любви к Родине. Можно любить только ту землю, ту красоту, среди которой родился и вопрос. И хотя на земле не мало экзотических стран с чудесными пальмами и морями, мы только восхищаемся этой природой, но она нам не очень близка. Недаром, когда поэты и писатели покидают Родину, то больше всего они тоскуют по русской природе. В последние годы жизни Пушкин создаёт произведения, наполненные безысходной тоской, глубоким сожалением о прошедших годах. В печальном голосе поэта постоянно присутствуют нотки скорби, разочарования, в его стихах природа грустит вместе с ним. Стихотворение " И вновь я посетил" очень личное. В каждой строчке пейзажа можно найти одиночество хмурого леса, там даётся трагический пейзаж с угрюмой картиной убогих избушек русской деревни, смерти детей. Настроение стихотворения перекликается с одиночеством самого поэта. В стихотворениях " Туча ", " Осень " та же тема безысходности. Недаром Пушкин любит это время умирания природы: " Октябрь уж поступил, уж рощи отряхают последние листы с нагих своих ветвей ". Кажется, что сама природа грустит вместе с поэтом. В каждой картине Пушкин запечатлевает своё особенное, неуловимое обычным глазом построение. Пейзаж у поэта не бесчувственный образ, он активен, имеет свой символ, свой смысл. В стихотворении " На холмах Грузии " печаль сквозит не только в пейзаже, но и в настроении поэта. Он пишет: " На холмах Грузии лежит ночная мгла". В этих строках передана романтическая мечта о волшебном крае. Пушкин изображает мир сильных страстей и чувств. В стихотворении " Деревня " на фоне поэтических зарисовок картин природы показана изнурительная рабская жизнь крепостных. Пушкин восклицает: " О, если б голос мой умел сердце тревожить! ". Он чувствовал себя одиноким парусом в жестокой жизненной буре, но голос его по-прежнему оставался вольным. Один из глубоких ценителей и поклонников творчества Пушкина - А. Горький говорил, что в томике стихов Пушкина он находит " большие мудрости и живой красоты, чем в холодном мерцании звёзд или в молчании пустыни ". В этих словах Горького прекрасно передано основное, что отличает лирику великого русского поэта,- и жизненность, её подлинная человечность. " Пушкин есть явление чрезвычайное, и может быть, единственное явление русского духа: это русский человек в его развитии, в каком он, может быть, явится чрез двести лет. В нём русская природа, русская душа, русский язык, русский характер отразились в такой же чистоте, в такой очищенной красоте, в какой отражается ландшафт на выпуклой поверхности оптического стекла ". Эти хорошо известные слова Гоголя хочется ещё раз повторить, ибо в них сказано всё главное - и о национальном своеобразии Пушкина, и о богатстве и силе его поэтического языка, и о высоком нравственном содержании его поэзии. Пушкин был больше, чем поэт. Это был историк, философ, политик, человек, являющий собой эпоху. Поэт был настоящим живописцем природы, он воспринимал её зорким взглядом художника и тонким слухом музыканта.

3_2 Природа в художественном миросозерцании А. С. Пушкина
ПРИРОДА В ХУДОЖЕСТВЕННОМ МИРОСОЗЕРЦАНИИ А. С. ПУШКИНА Но может быть, такого рода Картины вас не привлекут: Все это низкая природа; Изящного не много тут”. “Евгений Онегин” (5-я гл.) Описание природы встречается почти в каждом стихотворении А. С. Пушкина. Но было бы ошибочно видеть в нем только лишь приятную глазу и душе картинку. На самом деле оно многофункционально. Например, в “Евгении Онегине” через описание времен года показывается течение времени. Вместо фраз “прошел год”, “через два месяца” и т. п. Пушкин дает картину природы, соответствующую этому временному отрезку. Одновременно с этим описание природы соответствует и внутреннему состоянию автора. В “Бесах” Ф. М. Достоевского сомнения и страхи автора переходят на природу, и получается из простой метели какое-то жуткое хаотическое кружение, затягивающее внутрь себя все сущее, все живое. То же самое природное явление (метель, буран) может выполнять совсем другие функции: являться по сюжету началом драмы. Так происходит в повести “Метель”, где сюжетом движет не цепь поступков человека, а явление природы. Не случись метели, Владимир бы спокойно доехал и обвенчался с Машей. Так же и Маша из-за метели обвенчалась с каким-то неизвестным шутником-путником, опять же из-за метели сбившимся с дороги и впоследствии оказавшимся ее возлюбленным Бурминым. В “Медном всаднике” природа — это своевольная стихия, не смирившаяся и до конца не покорившаяся человеку. Здесь (как и в “Метели”) явление природы (наводнение) — завязка сюжета. Вернее, не сама природа, а ее конфликт с властью и человеком, попытавшимся ее покорить. Получается, что природа является как бы дополнительным по счету действующим лицом в этой поэме. В стихотворении “К морю” водная стихия (море) также является действующим лицом — собеседником поэта, к которому поэт обращается. Здесь сравниваются свободная стихия и внешняя несвобода поэта, а соответственно и всего мира, так как “судьба людей повсюду та же”. И даже если бы он был свободен, ему некуда уйти. У поэта остается только его внутренняя личная свобода. Наблюдается некая закономерность: в роли героя может выступать только свободная и свободолюбивая стихия, не покорившаяся человеку: метель (в “Бесах”, “Метели”) и вода (в “Медном всаднике”, “К морю”). Мне кажется, в этом вы ражается особая любовь поэта к ним, особенно к воде. Возможно, это связано с тем, что А. С. Пушкин, будучи свободолюбивым человеком, всю жизнь был вынужден подчиняться. И он понял со временем, что человек может быть полностью свободен только внутренне, в отличие от любимых им природных стихий. Помимо того, что описание природы выполняет разные функции, оно также изменяется во времени. В каждом периоде творчества поэта описание природы различно. Это очень хорошо видно на примере двух стихотворений, написанных в разное время (1819, 1835), но воспроизводящих одно и то же место. Я имею в виду “Деревню” и “...Вновь я посетил...”. В “Деревне” А. С. Пушкин соединил два начала: лирическое и гражданское. В первой части этого стихотворения он сталкивает развратный двор, от которого бежал, и мирную, вольную природу. Это весьма романтическое описание природы интересно сравнить с описанием той же природы, но уже в более позднем философском стихотворении “...Вновь я посетил...”. Присутствует уже совсем другое настроение — тоска. Если в “Деревне” А. С. Пушкин испытывает радость от свидания с природой, с родным уголком, то здесь вновь увиденное Михайловское таких бурных чувств не вызывает. В “Деревне”: “Парус рыбаря белеет иногда”, “Вдали рассыпанные хаты”, “Овины дымные и мельницы крылаты”. В стихотворении “...Вновь я посетил...”: Плывет рыбак и тянет за собой Убогий невод по брегам отлогим. Рассеяны деревни — там за ними Скривилась мельница, насилу крылья Ворочая при ветре... На примере этих стихотворений видно: поздний Пушкин склонен к более реалистическому описанию природы, к использованию обычной, неромантической лексики. Порой лексика, совершенно разная по стилю, при описании природы встречается и в пределах одного стихотворения, В “Зимнем утре” романтическая, “условная” лексика, идущая от В. Жуковского (“Аврора”, “негой взоры”), сменяется простонародной (“вечор”) и общеупотребительной лексикой. Этот переход, правда, органичен, столкновение стилей отсутствует. Для А. С. Пушкина также характерно присутствие некоего движения внутри стихотворения. Описываемая им картина никогда не бывает статичной. Поэт с легкостью переходит от одного времени года к другому (“Осень”), от сегодняшнего дня ко дню вчерашнему, от описания природы к описанию комнаты (“Зимнее утро”). Самое значительное стихотворение А. С. Пушкина, посвященное природе и взаимоотношению поэта и природы, — это “Осень”. Стихотворение, посвященное самому любимому А. С. Пушкиным времени года, разбито на фрагменты. Первый фрагмент посвящен осени. Второй, третий и четвертый — остальным временам года: весне, зиме и лету. Описание лета и весны, не любимых Пушкиным, занимает всего по две строчки, но в то же время у читателя создается достаточно широкая и объемная картина природы. Это достигается благодаря употреблению небольшого количества существительных, имеющих широкое значение и являющихся общими понятиями, неизбыточности уточняющих слов и оборотов (прилагательных, причастных и деепричастных). А если уточнения и используются, то они точно передают настроение и отношение поэта к описываемому. Вот описание лета: Ох, лето красное! Любил бы я тебя, — личное отношение, не описание, — Когда б не зной, да пыль, да комары, да мухи. Получается, что всего четырьмя существительными (“зной”, “пыль”, “комары”, “мухи”) А. С. Пушкин создает не только картину лета, но и передает свое отвращение к нему. Эпитет “красное” здесь имеет, по-моему, иронический смысл. Примечательно, что оба описания (лета и осени) Пушкин сводит к воспоминаниям о зиме — втором (после осени) любимом времени года. Зиму же Пушкин описывает по-другому, то есть манера описания такая же: “широкими мазками создать картину”, но настроение иное. Один Мазок — снега, другой — свет луны. И все, пейзаж готов. Несмотря на явное предпочтение зимы лету и весне, осень — еще более любимое время года, и ей посвящается все остальное стихотворение. Эта пора года — кульминация Красоты. Исключительность осени состоит в том, что она воплощает одновременно два мотива: красоты и смерти (осень — пора увяданья, умирания природы). А. С. Пушкин сравнивает ее с чахоточной девой, чей багровый румянец (цвет осеннего леса) на щеках является признаком смертельной болезни и в то же время напоминает щеки красивой, полной жизни девушки. В строчке “Унылая пора! очей очарованье!” наиболее ясно слышится сочетание, присутствие в осени мотивов смерти и красоты. Причем ощущение красоты усиливается и наиболее остро воспринимается именно от сознания ее недолговечности. А. С. Пушкин — совершенно земной и жизнедеятельный поэт, поэтому от описания красоты и природного великолепия он тут же переходит к бытовым деталям и прозаизмам: Чредой слетает сон, чредой находит голод... <...> Я снова жизни полон — таков мой организм (Извольте мне простить ненужный прозаизм). Процесс творчества, вдохновение, вызванное потрясающей красотой осени, оказываются связанными с прозаическими деталями. А. С. Пушкин никогда не отрывается от жизни, быта даже при описании своего любимого времени года, от этого красота осени, подчеркнутая близким ее концом, становится чем-то еще более реальным и действенным. Остается лишь добавить, что осень была самым благотворным периодом в творчестве А. С. Пушкина, ведь именно осенью были написаны многие из лучших пушкинских произведений, таких, как “Медный всадник”, маленькие трагедии и многие другие.  

3_3 А. С. Пушкин и С. А. Есенин — певцы русской природы
А. С. ПУШКИН И С. А. ЕСЕНИН — ПЕВЦЫ РУССКОЙ ПРИРОДЫ Конец XX века — это время жестоких испытаний для человека и человечества. Мы пленники современной цивилизации. Наша жизнь протекает в гигантских городах среди бетонных домов, асфальта и дыма. Мы засыпаем и просыпаемся под рев автомобилей. Современный ребенок с удивлением разглядывает птичку, а цветы видит лишь стоящими в праздничной вазе. Тем важнее для нас сегодня русская классическая поэзия. Она формирует в человеке любовь к родной природе, уважение к отчему дому. Русскими поэтами создано много шедевров пейзажной лирики, но для меня и, по-видимому, большинства живущих в России первые поэтические образы природы прежде всего связаны с именем А. С. Пушкина. Каждый ребенок в России со страхом и восторгом декламирует: Буря мглою небо кроет, Вихри снежные крутя; То, как зверь, она завоет, То заплачет, как дитя, То по кровле обветшалой Вдруг соломой зашумит, То, как путник запоздалый, К нам в окошко застучит. Поэт, используя очень простые, доступные образы, создает незабываемый эмоциональный настрой, который сохраняется на всю жизнь. А вот еще один замечательный поэтический образ зимней ночи: Сквозь волнистые туманы Пробивается луна, На печальные поляны Льет печально свет она. Возникает ощущение тихой грусти, одиночества. Ни огня, ни черной хаты... Глушь да снег... А вот совсем другое описание зимы, доброе и жизнеутверждающее: Под голубыми небесами Великолепными коврами, Блестя на солнце, снег лежит... Эти строки полны радости и оптимизма. На мой взгляд, вершина пушкинской пейзажной лирики — стихотворение “Осень”. Начало первой строфы, четыре строчки, всего четыре мазка, но сделанных рукой гения, — и в нашем воображении возникает точная, узнаваемая и выразительная картина осеннего дня. Октябрь уж наступил — уж роща отряхает Последние листы с нагих своих ветвей; Дохнул осенний хлад — дорога промерзает, Журча еще бежит за мельницу ручей... По-моему, самый прекрасный образ природы создан поэтом в знаменитых строчках: Унылая пора! очей очарованье! Приятна мне твоя прощальная краса — Люблю я пышное природы увяданье, В багрец и в золото одетые леса... Здесь в каждой строчке контраст и гармония, соединение, казалось бы, несоединимого. Эти строки хочется переложить на музыку и одновременно изображать красками на холсте Осень, любимая пора Пушкина, была для него и временем наибольшего творческого подъема. И с каждой осенью я расцветаю вновь... Так, знаменитой болдинской осенью Пушкин завершил свое величайшее творение — роман “Евгений Онегин”, написал маленькие трагедии, много других замечательных произведений. Описание природы у Пушкина не самоцель, а эмоциональный ключ, создающий определенный настрой, позволяющий лучше понять переживания человека, который остается главным действующим лицом пушкинской лирики. Так, в стихотворении “Бесы” картина вьюги — это сложная метафора, отражающая чувства самого Пушкина. Они раскрываются в последних строчках: Мчатся бесы рой за роем В беспредельной вышине, Визгом жалобным и воем Надрывая сердце мне... Поэт ищет в окружающей природе расшифровку своего внутреннего мира. С помощью образов природы Пушкин поднимается до больших обобщений, вопросов жизни и смерти. ...Вновь я посетил Тот уголок земли, где я провел Изгнанником два года незаметных... Вот холм лесистый, над которым часто Я сиживал недвижим и глядел На озеро, воспоминая с грустью Иные берега, иные волны... Здравствуй, племя Младое, незнакомое! не я Увижу твой могучий поздний возраст... “Младое, незнакомое” племя, появление которого приветствовал Пушкин, унаследовало от него восхищение красотой русской земли и любовь к русскому слову. К этому племени относятся такие замечательные поэты, как Тютчев, Кольцов, Лермонтов, Фет, Некрасов и совсем близкий к нам Есенин. С. А. Есенин унаследовал пушкинскую поэтическую культуру в реалистическом описании родной природы. Однако его пейзажная лирика по сути своей отличается от пушкинской. В ней намного сильнее влияние русского фольклора и языческой мифологии. В Родился я с 1000 песнями в травном одеяле, Зори меня вешние в радугу свивали. Вырос я до зрелости, внук купальской ночи, Сутемень колдовная счастье мне пророчит. Это напоминает народную песню-заклинание. В творчестве Есенина сильно ощущается древнее, языческое отношение к природе, полное признание ее самостоятельности, одушевленности: Схимник-ветер шагом осторожным Мнет листву по выступам дорожным И целует на рябиновом кусту Язвы красные незримому Христу. Есенин ощущает себя частью природы, ее учеником и собеседником. Позабыв людское горе, Сплю на вырубках сучья. Я молюсь на алы зори, Причащаюсь у ручья. Поэтому у него нет чисто пейзажных стихов. Природа и человек существуют рядом: Кого жалеть? Ведь каждый в мире странник — Пройдет, зайдет и вновь оставит дом. О всех ушедших грезит конопляник С широким месяцем над голубым прудом. Любовь к природе, к родным рязанским полям, к “стране березового ситца” делает лирику Есенина огромной поэмой о России. О Русь — малиновое поле И синь, упавшая в реку, — Люблю до радости и боли Твою озерную тоску. Мне кажется, так о России до него не писал никто. В этих стихах Русь живая, способная тосковать, испытывать боль: Есенин — сын России, сострадающий своей “стране березового ситца”. Но более всего Любовь к родному краю Меня томила, Мучила и жгла. Поэт понимает, что уход от природы, от родины, от своих корней трагичен. Однако трагизм судьбы Есенина в том и состоит, что, сознавая пагубность этого отрыва, он не смог противостоять ему. Не жалею, не зову, не плачу, Все пройдет, как с белых яблонь дым. Увяданья золотом охваченный, Я не буду больше молодым. Ты теперь не так уж будешь биться, Сердце, тронутое холодком, И страна березового ситца Не заманит шляться босиком. К Есенину приходит пушкинское ощущение вечного течения жизни, неизбежности смерти как непреложного закона жизни. Все мы, все мы в этом мире тленны, Тихо льется с кленов листьев медь... Будь же ты вовек благословенно, Что пришло процвесть и умереть. Я думаю, что творческое наследие С. А. Есенина очень близко нашим сегодняшним представлениям о мире, где человек — только частица живой природы, не противостоящая ей, а зависящая от нее. Чувство природы, ощущение единства с ней человека завещано нам гениальными русскими поэтами А. С. Пушкиным и С. А. Есениным. Благодаря Пушкину мы останавливаемся в волнении и замираем перед прекрасной картиной осеннего дня или перед сиянием зимней дороги. Проникнув в мир поэтических образов Есенина, мы начинаем ощущать себя братьями одинокой березы, старого клена, рябинового куста, разного “зверья”. Эти чувства должны помочь нам сохранить человечность, а значит, и человечество.

4_1 Генетические алгоритмы
Генетические алгоритмы (ГА) - это стохастические, эвристические оптимизационные методы, впервые предложенные Холландом (1975). Они основываются на идее эволюции с помощью естественного отбора, выдвинутой Дарвином (1857).
1. Введение в генетические алгоритмы
ГА работают с совокупностью "особей" - популяцией, каждая из которых представляет возможное решение данной проблемы. Каждая особь оценивается мерой ее "приспособленности" согласно тому, насколько "хорошо" соответствующее ей решение задачи. В природе это эквивалентно оценке того, насколько эффективен организм при конкуренции за ресурсы. Наиболее приспособленные особи получают возможность "воспроизводить" потомство с помощью "перекрестного скрещивания" с другими особями популяции. Это приводит к появлению новых особей, которые сочетают в себе некоторые характеристики, наследуемые ими от родителей. Наименее приспособленные особи с меньшей вероятностью смогут воспроизвести потомков, так что те свойства, которыми они обладали, будут постепенно исчезать из популяции в процессе эволюции. Иногда происходят мутации, или спонтанные изменения в генах. 
   Таким образом, из поколения в поколение, хорошие характеристики распространяются по всей популяции. Скрещивание наиболее приспособленных особей приводит к тому, что исследуются наиболее перспективные участки пространства поиска. В конечном итоге популяция будет сходиться к оптимальному решению задачи. Преимущество ГА состоит в том, что он находит приблизительные оптимальные решения за относительно короткое время.
ГА состоит из следующих компонент: 
- Хромосома. Решение рассматриваемой проблемы. Состоит из генов. 
- Начальная популяция хромосом. 
- Набор операторов для генерации новых решений из предыдущей популяции. 
- Целевая функция для оценки приспособленности (fitness) решений. 
Чтобы применять ГА к задаче, сначала выбирается метод кодирование решений в виде строки. Фиксированная длина (l-бит) двоичной кодировки означает, что любая из 2l возможных бинарных строк представляет возможное решение задачи.
По существу, такая кодировка соответствует разбиению пространства параметров на гиперкубы, которым соответствуют уникальные комбинации битов в строке - хромосоме. Для установления соответствия между гиперкубами разбиения области и бинарными строками, описывающими номера таких гиперкубов, кроме обычной двоичной кодировки использовался рефлексивный код Грея. Код Грея предпочтительнее обычного двоичного тем, что обладает свойством непрерывности бинарной комбинации: изменение кодируемого числа на единицу соответствует изменению кодовой комбинации только в одном разряде.

2. Операторы ГА
Стандартные операторы для всех типов генетических алгоритмов это: селекция, скрещивание и мутация.
2.1 Селекция
Оператор селекции (reproduction, selection) осуществляет отбор хромосом в соответствии со значениями их функции приспособленности. Существуют как минимум два популярных типа оператора селекции: рулетка и турнир. 
- Метод рулетки (roulette-wheel selection) - отбирает особей с помощью n "запусков" рулетки. Колесо рулетки содержит по одному сектору для каждого члена популяции. Размер i-ого сектора пропорционален соответствующей величине Psel(i) вычисляемой по формуле:

При таком отборе члены популяции с более высокой приспособленностью с большей вероятностью будут чаще выбираться, чем особи с низкой приспособленностью.
Оператор селекции типа колеса рулетки
с пропорциональными функции приспособленности секторами 
- Турнирный отбор (tournament selection) реализует n турниров, чтобы выбрать n особей. Каждый турнир построен на выборке k элементов из популяции, и выбора лучшей особи среди них. Наиболее распространен турнирный отбор с k=2. 
2.2. Скрещивание
Оператор скрещивание (crossover) осуществляет обмен частями хромосом между двумя (может быть и больше) хромосомами в популяции. Может быть одноточечным или многоточечным. Одноточечный кроссовер работает следующим образом. Сначала, случайным образом выбирается одна из l-1 точек разрыва. Точка разрыва - участок между соседними битами в строке. Обе родительские структуры разрываются на два сегмента по этой точке. Затем, соответствующие сегменты различных родителей склеиваются и получаются два генотипа потомков. 
Рис. 2. Одноточечный оператор скрещивания (точка разрыва равна трем) 
2.3. Мутация
Мутация (mutation) - стохастическое изменение части хромосом. Каждый ген строки, которая подвергается мутации, с вероятностью Pmut (обычно очень маленькой) меняется на другой ген.
Оператор мутации (четвертый ген мутировал) 
3. Алгоритм работы ГА
Работа ГА представляет собой итерационный процесс, который продолжается до тех пор, пока не выполнятся заданное число поколений или какой-либо иной критерий останова. На каждом поколении ГА реализуется отбор пропорционально приспособленности, кроссовер и мутация.
Алгоритм работы простого ГА выглядит следующим образом:

4_2 Генетические алгоритмы. Естественный отбор в природе 
Эволюционная теория утверждает, что каждый биологический вид целенаправленно развивается и изменяется для того, чтобы наилучшим образом приспособиться к окружающей среде. В процессе эволюции многие виды насекомых и рыб приобрели защитную окраску, еж стал неуязвимым благодаря иглам, человек стал обладателем сложнейшей нервной системы. Можно сказать, что эволюция - это процесс оптимизации всех живых организмов. Рассмотрим, какими же средствами природа решает эту задачу оптимизации. 
Основной механизм эволюции - это естественный отбор. Его суть состоит в том, что более приспособленные особи имеют больше возможностей для выживания и размножения и, следовательно, приносят больше потомства, чем плохо приспособленные особи. При этом благодаря передаче генетической информации (генетическому наследованию) потомки наследуют от родителей основные их качества. Таким образом, потомки сильных индивидуумов также будут относительно хорошо приспособленными, а их доля в общей массе особей будет возрастать. После смены нескольких десятков или сотен поколений средняя приспособленность особей данного вида заметно возрастает. 
Чтобы сделать понятными принципы работы генетических алгоритмов, поясним также, как устроены механизмы генетического наследования в природе. В каждой клетке любого животного содержится вся генетическая информация этой особи. Эта информация записана в виде набора очень длинных молекул ДНК (ДезоксирибоНуклеиновая Кислота). Каждая молекула ДНК - это цепочка, состоящая из молекул нуклеотидов четырех типов, обозначаемых А, T, C и G. Собственно, информацию несет порядок следования нуклеотидов в ДНК. Таким образом, генетический код индивидуума - это просто очень длинная строка символов, где используются всего 4 буквы. В животной клетке каждая молекула ДНК окружена оболочкой - такое образование называется хромосомой. 
    Каждое врожденное качество особи (цвет глаз, наследственные болезни, тип волос и т.д.) кодируется определенной частью хромосомы, которая называется геном этого свойства. Например, ген цвета глаз содержит информацию, кодирующую определенный цвет глаз. Различные значения гена называются его аллелями. 
При размножении животных происходит слияние двух родительских половых клеток и их ДНК взаимодействуют, образуя ДНК потомка. Основной способ взаимодействия - кроссовер (cross-over, скрещивание). При кроссовере ДНК предков делятся на две части, а затем обмениваются своими половинками. 
При наследовании возможны мутации из-за радиоактивности или других влияний, в результате которых могут измениться некоторые гены в половых клетках одного из родителей. Измененные гены передаются потомку и придают ему новые свойства. Если эти новые свойства полезны, они, скорее всего, сохранятся в данном виде - при этом произойдет скачкообразное повышение приспособленности вида. 
Что такое генетический алгоритм? Пусть дана некоторая сложная функция (целевая функция), зависящая от нескольких переменных, и требуется найти такие значения переменных, при которых значение функции максимально. Задачи такого рода называются задачами оптимизации и встречаются на практике очень часто. 
Один из наиболее наглядных примеров - задача распределения инвестиций, описанная ранее. В этой задаче переменными являются объемы инвестиций в каждый проект (10 переменных), а функцией, которую нужно максимизировать - суммарный доход инвестора. Также даны значения минимального и максимального объема вложения в каждый из проектов, которые задают область изменения каждой из переменных. 
Попытаемся решить эту задачу, применяя известные нам природные способы оптимизации. Будем рассматривать каждый вариант инвестирования (набор значений переменных) как индивидуума, а доходность этого варианта - как приспособленность этого индивидуума. Тогда в процессе эволюции (если мы сумеем его организовать) приспособленность индивидуумов будет возрастать, а значит, будут появляться все более и более доходные варианты инвестирования. Остановив эволюцию в некоторый момент и выбрав самого лучшего индивидуума, мы получим достаточно хорошее решение задачи. 
Генетический алгоритм - это простая модель эволюции в природе, реализованная в виде компьютерной программы. В нем используются как аналог механизма генетического наследования, так и аналог естественного отбора. При этом сохраняется биологическая терминология в упрощенном виде. 
Вот как моделируется генетическое наследование: 
Хромосома Вектор (последовательность) из нулей и единиц.
Каждая позиция (бит) называется геном. 
Индивидуум = генетический код Набор хромосом = вариант решения задачи. 
Кроссовер Операция, при которой две хромосомы обмениваются своими частями. 
Мутация Cлучайное изменение одной или нескольких позиций в хромосоме. 
Чтобы смоделировать эволюционный процесс, сгенерируем вначале случайную популяцию - несколько индивидуумов со случайным набором хромосом (числовых векторов). Генетический алгоритм имитирует эволюцию этой популяции как циклический процесс скрещивания индивидуумов и смены поколений.
Жизненный цикл популяции - это несколько случайных скрещиваний (посредством кроссовера) и мутаций, в результате которых к популяции добавляется какое-то количество новых индивидуумов. Отбор в генетическом алгоритме - это процесс формирования новой популяции из старой, после чего старая популяция погибает. После отбора к новой популяции опять применяются операции кроссовера и мутации, затем опять происходит отбор, и так далее.
Отбор в генетическом алгоритме тесно связан с принципами естественного отбора в природе следующим образом: 
Приспособленность индивидуума 	Значение целевой функции на этом индивидууме. 
Выживание наиболее приспособленных 	Популяция следующего поколения формируется в соответствии с целевой функцией. Чем приспособленнее индивидуум, тем больше вероятность его участия в кроссовере, т.е. размножении. 
Таким образом, модель отбора определяет, каким образом следует строить популяцию следующего поколения. Как правило, вероятность участия индивидуума в скрещивании берется пропорциональной его приспособленности. Часто используется так называемая стратегия элитизма, при которой несколько лучших индивидуумов переходят в следующее поколение без изменений, не участвуя в кроссовере и отборе. В любом случае каждое следующее поколение будет в среднем лучше предыдущего. Когда приспособленность индивидуумов перестает заметно увеличиваться, процесс останавливают и в качестве решения задачи оптимизации берут наилучшего из найденных индивидуумов. 
Возвращаясь к задаче оптимального распределения инвестиций, поясним особенности реализации генетического алгоритма в этом случае. 
- Индивидуум = вариант решения задачи = набор из 10 хромосом Хj 
- Хромосома Хj= объем вложения в проект j = 16-разрядная запись этого числа 
- Так как объемы вложений ограничены, не все значения хромосом являются допустимыми. Это учитывается при генерации популяций. 
- Так как суммарный объем инвестиций фиксирован, то реально варьируются только 9 хромосом, а значение 10-ой определяется по ним однозначно. 
Ниже приведены результаты работы генетического алгоритма для трех различных значений суммарного объема инвестиций K. 

Особенности генетических алгоритмов 
Генетический алгоритм - новейший, но не единственно возможный способ решения задач оптимизации. С давних пор известны два основных пути решения таких задач - переборный и локально-градиентный. У этих методов свои достоинства и недостатки, и в каждом конкретном случае следует подумать, какой из них выбрать. 
Рассмотрим достоинства и недостатки стандартных и генетических методов на примере классической задачи коммивояжера (TSP - travelling salesman problem). Суть задачи состоит в том, чтобы найти кратчайший замкнутый путь обхода нескольких городов, заданных своими координатами. Оказывается, что уже для 30 городов поиск оптимального пути представляет собой сложную задачу, побудившую развитие различных новых методов (в том числе нейросетей и генетических алгоритмов). 
Каждый вариант решения (для 30 городов) - это числовая строка, где на j-ом месте стоит номер j-ого по порядку обхода города. Таким образом, в этой задаче 30 параметров, причем не все комбинации значений допустимы. Естественно, первой идеей является полный перебор всех вариантов обхода. 
Переборный метод наиболее прост по своей сути и тривиален в программировании. Для поиска оптимального решения (точки максимума целевой функции) требуется последовательно вычислить значения целевой функции во всех возможных точках, запоминая максимальное из них. Недостатком этого метода является большая вычислительная стоимость. В частности, в задаче коммивояжера потребуется просчитать длины более 1030 вариантов путей, что совершенно нереально. Однако, если перебор всех вариантов за разумное время возможен, то можно быть абсолютно уверенным в том, что найденное решение действительно оптимально. 
Второй популярный способ основан на методе градиентного спуска. При этом вначале выбираются некоторые случайные значения параметров, а затем эти значения постепенно изменяют, добиваясь наибольшей скорости роста целевой функции. Достигнув локального максимума, такой алгоритм останавливается, поэтому для поиска глобального оптимума потребуются дополнительные усилия. 
Градиентные методы работают очень быстро, но не гарантируют оптимальности найденного решения. Они идеальны для применения в так называемых унимодальных задачах, где целевая функция имеет единственный локальный максимум (он же - глобальный). Легко видеть, что задача коммивояжера унимодальной не является. 
Типичная практическая задача, как правило, мультимодальна  и многомерна, то есть содержит много параметров. Для таких задач не существует ни одного универсального метода, который позволял бы достаточно быстро найти абсолютно точное решение. 

Однако, комбинируя переборный и градиентный методы, можно надеяться получить хотя бы приближенное решение, точность которого будет возрастать при увеличении времени расчета. 
Генетический алгоритм представляет собой именно такой комбинированный метод. Механизмы скрещивания и мутации в каком-то смысле реализуют переборную часть метода, а отбор лучших решений - градиентный спуск. На рисунке показано, что такая комбинация позволяет обеспечить устойчиво хорошую эффективность генетического поиска для любых типов задач. 
Итак, если на некотором множестве задана сложная функция от нескольких переменных, то генетический алгоритм - это программа, которая за разумное время находит точку, где значение функции достаточно близко к максимально возможному. Выбирая приемлемое время расчета, мы получим одно из лучших решений, которые вообще возможно получить за это время. 
Компанией Ward Systems Group подготовлен наглядный пример решения задачи коммивояжера с помощью генетического алгоритма. Для этого была использована библиотека функций продукта GeneHunter. Города можно располагать на карте с помощью мыши, а поиск кратчайшего пути занимает не более минуты.

4_3 Системы обучения, основанные на генетических алгоритмах 
 Тезисы: В данной работе исследуется применение эволюционных методов обучения для классификации. Большое внимание уделяется особенностям методов распределения кредитов и применению генетических алгоритмов применительно к задачам классификации. Все утверждения базируются на данных, полученных в процессе решения конкретной задачи . классификации грибов семейств lepiota и agaricus на съедобные и ядовитые. Для реализации системы было разработано специальное программное обеспечение на языке С++. В результате была построена система, способная распознавать примерно 90% предложенных разновидностей грибов. После некоторой модификации алгоритма и оптимизации многочисленных параметров система выдаёт около 93%  правильных ответов. 
Ключевые слова: системы классификаторов, генетические алгоритмы, crowding, алгоритм пожарников, задача классификации 
1. Введение 
Необходимость анализа и формализации  задач,  связанных  со  сравнением  и классификацией  объектов  сознавали  ещё  далёкого  в  прошлом.  Для  этих  целей использовались различные методы распознавания образов «с учителем», «без учителя» и «c поощрением». 
Это  и  известные  статистические  методы [1],  индуктивные  методы,  эволюционные методы, нейронные сети. 
В данной работе были изучены принципы построения классифицирующей системы на основе  эволюционных  методов,  которыми  являются  генетические  алгоритмы. Возможности  данного  метода  классификации  исследуются  на  конкретном  примере решается задача классификации грибов. 
Для описания принципов обучающих систем, основанных на генетических алгоритмах вводится понятие системы классификаторов, основанных на правилах и сообщениях. 
Системы классификаторов . это обучающие системы, которые обучают синтаксически простые строки правил (т.н. классификаторы) управлять представлением в произвольной 
среде. 
Системы классификаторов состоят из трёх основных компонентов: 
: Система правил и сообщений; 
; Пропорциональное распределение системы кредитов; 
; Генетический алгоритм. 
Интерпретация системы классификаторов 
Система правил и сообщений в системе классификаторов, это своего рода система продукций [7]. Сообщения приходят из внешней среды или от классификаторов системы. 
Они сравниваются с правилами  классификаторов  на  совпадение.  Сообщение  в  системе классификаторов -  это  всего  лишь  строка  определённой  длины,  состоящая  из  символов определённого алфавита. Чем чаще сообщение совпадает c условной частью правила,  тем выше ценность правила, с которым оно совпало. Ценность правил необходимо выяснить в процессе работы путём соревнования, используя методы распределения кредитов.
Обмен и накопление внутренней валюты обеспечивает естественный критерий для применения  генетических  алгоритмов.  Используя  баланс  классификатора  как  fitness-
функцию,  классификаторы  могут  быть  воспроизведены,  подвергнуться  скрещиванию  и мутации.  Таким  образом,  системы  могут  учиться,  не  только    ранжируя  существующие правила,  но  и  могут  открывать  новые,  возможно  лучшие  правила,  как  новаторские комбинации  старых  правил.  Генерируется  новое  поколение,  обращая большое  внимание на то, которое заменяем. 
Распределение  кредитов  путём  соревнования  и  обнаружение  новых  правил, используя  генетические  алгоритмы,  формируют  разумную  основу  для  создания обучающих систем [2]. 
2. Алгоритм пожарников 
Существуют  различные  методы  ранжирования  отдельных  классификаторов  в соответствии  с  их  ролью  в  получении  вознаграждения  от  среды.  Наиболее распространённым  является  метод,  который Holland [2]  назвал  The  Bucket  Brigade Algorithm (алгоритм пожарников). 
Этот  алгоритм  просто  интерпретируется  в  экономических  терминах,  где  права торговли  продаются  и  покупаются  классификаторами.  Классификаторы  формируют цепочку посредников от отправителя информации (среды) к получателю (эффектору). 
При  получении  сообщения  совпавшие  классификаторы  учавствуют  в  аукционе,  где величина  ставки  пропорциональна  силе  и  специфичности  рассматриваемого  классификатора: 
Победивший на аукционе классификатор платит ставку, которая является источником дохода для того, кто послал это сообщение и получает право послать новое сообщение в список сообщений. Каждый классификатор также облагается налогом на жизнь, чтобы не участвующие в цепочках правила постепенно теряли свою силу. Экономическая природа соревнования  обеспечивает,  что  хорошие  правила  получают  доход,  а  плохие  несут убытки. Таким образом, вычисление силы классификатора на следующем временном шаге можно определить по следующей формуле: 
3.  Упрощённые системы классификаторов 
Некоторые упрощения для рассматриваемой системы классификаторов, а особенно это касается  метода  распределения  кредитов [2].  Такие  системы  отличаются  тем,  что  не имеют списка сообщений. В них классификаторы не образуют никаких цепочек, а первый и  единственный  классификатор,  который  «победил»  в  соревновании  делает  ставку  и получает  вознаграждение  от  среды  за  правильное  действие.  Остальные  совпавшие классификаторы облагаются определённым налогом за ставку, значительно меньшим, чем ставка. Здесь ставка для участников соревнования рассчитывается, как и раньше по формулам(1),(2): 
Новые значения силы для классификаторов рассчитываются следующим образом: 
4.  Генетические алгоритмы в системах классификаторов 
Как  уже  было  отмечено,  для  получения  нового  поколения  в  системах классификаторов, применяются генетические алгоритмы. 
Генетические алгоритмы применяются после достижения стационарного состояния системы. Это происходит, когда состояние стабилизируется и не происходит улучшения качества  системы.  Именно  в  такой  момент  необходимо  внедрение  новых классификаторов.
